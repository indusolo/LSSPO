{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "561039f5-e670-489b-bd80-02ebe28ad1a0",
    "_uuid": "5b829f06-ec7b-4654-a9ab-4c22a5fb03cd",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:27.543015Z",
     "iopub.status.busy": "2021-09-11T07:57:27.542712Z",
     "iopub.status.idle": "2021-09-11T07:57:27.555034Z",
     "shell.execute_reply": "2021-09-11T07:57:27.553987Z",
     "shell.execute_reply.started": "2021-09-11T07:57:27.542983Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91948\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras.models import load_model\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import csv\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Layer\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten \n",
    "from tensorflow.keras import backend as K\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import random\n",
    "random.seed(3)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d5bc6e18-d881-48e5-8daa-ef8448ba3948",
    "_uuid": "6f208a14-1edd-49f1-ac96-23f09ef5344e",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:27.556969Z",
     "iopub.status.busy": "2021-09-11T07:57:27.556707Z",
     "iopub.status.idle": "2021-09-11T07:57:28.326258Z",
     "shell.execute_reply": "2021-09-11T07:57:28.325413Z",
     "shell.execute_reply.started": "2021-09-11T07:57:27.556942Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size (1567, 590)\n",
      "Labels size (1567,)\n",
      "Minority class count = 104\n",
      "       0        1          2          3       4    5         6       7    \\\n",
      "0  3030.93     2564  2187.7333  1411.1265  1.3602  100   97.6133  0.1242   \n",
      "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  100  102.3433  0.1247   \n",
      "2  2932.61  2559.94  2186.4111  1698.0172  1.5102  100   95.4878  0.1241   \n",
      "3  2988.72   2479.9  2199.0333   909.7926  1.3204  100  104.2367  0.1217   \n",
      "4  3032.24  2502.87  2233.3667    1326.52  1.5334  100  100.3967  0.1235   \n",
      "\n",
      "      8        9    ...     580       581     582     583     584      585  \\\n",
      "0  1.5005   0.0162  ...     NaN       NaN  0.5005  0.0118  0.0035    2.363   \n",
      "1  1.4966  -0.0005  ...   0.006  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
      "2  1.4436   0.0041  ...  0.0148   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
      "3  1.4882  -0.0124  ...  0.0044   73.8432   0.499  0.0103  0.0025   2.0544   \n",
      "4  1.5031  -0.0031  ...     NaN       NaN    0.48  0.4766  0.1045  99.3032   \n",
      "\n",
      "      586     587     588       589  \n",
      "0     NaN     NaN     NaN       NaN  \n",
      "1  0.0096  0.0201   0.006  208.2045  \n",
      "2  0.0584  0.0484  0.0148   82.8602  \n",
      "3  0.0202  0.0149  0.0044   73.8432  \n",
      "4  0.0202  0.0149  0.0044   73.8432  \n",
      "\n",
      "[5 rows x 590 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Columns: 590 entries, 0 to 589\n",
      "dtypes: object(590)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Read the Secom dataset\n",
    "reader = csv.reader(open(\"SECOM/SECOM.TXT\"), delimiter=\" \")\n",
    "Data = pd.DataFrame(reader)\n",
    "labels = csv.reader(open(\"SECOM/SECOM_labels.TXT\"), delimiter=\" \")\n",
    "secom_labels = pd.DataFrame(labels)\n",
    "y = secom_labels[0].astype('int8')\n",
    "print(\"Data size\",Data.shape)\n",
    "print('Labels size',y.shape)\n",
    "print(\"Minority class count =\", np.sum(y==1))\n",
    "print(Data.head())\n",
    "Data.info()\n",
    "#Data = Data.astype('float')\n",
    "Target = pd.DataFrame()\n",
    "Target['tar'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "d58e56bc-eca4-4791-af43-c1f10b4401e6",
    "_uuid": "4d24b0e4-d705-474d-8838-352a902401c0",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:28.327783Z",
     "iopub.status.busy": "2021-09-11T07:57:28.327552Z",
     "iopub.status.idle": "2021-09-11T07:57:28.336492Z",
     "shell.execute_reply": "2021-09-11T07:57:28.335621Z",
     "shell.execute_reply.started": "2021-09-11T07:57:28.327756Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 590)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "18477219-9c78-46c1-9439-90fff769ef8e",
    "_uuid": "c2168746-b294-487b-bd0d-e8f02e2b701c",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:28.338917Z",
     "iopub.status.busy": "2021-09-11T07:57:28.338686Z",
     "iopub.status.idle": "2021-09-11T07:57:30.694768Z",
     "shell.execute_reply": "2021-09-11T07:57:30.693624Z",
     "shell.execute_reply.started": "2021-09-11T07:57:28.33889Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20d934eb708>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Handling missing data\n",
    "missdata_Columns = []\n",
    "for i in Data.columns:\n",
    "    if np.sum(Data[i][:] == 'NaN') >0:\n",
    "        missdata_Columns.append([i,np.sum(Data[i][:] == 'NaN')])\n",
    "        #print( i, ':',np.sum(Data[i][:] == 'NaN') )\n",
    "        \n",
    "missdata_df = pd.DataFrame(missdata_Columns)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(missdata_df[0],missdata_df[1],color='red')\n",
    "plt.legend('Missing')\n",
    "#plt.savefig('SecomDatamissing.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "c1908ee7-0ff1-41be-a711-08e2ddb27407",
    "_uuid": "ac654f1b-c593-481b-8f43-6b45f66045ee",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:30.69615Z",
     "iopub.status.busy": "2021-09-11T07:57:30.695928Z",
     "iopub.status.idle": "2021-09-11T07:57:31.123292Z",
     "shell.execute_reply": "2021-09-11T07:57:31.122608Z",
     "shell.execute_reply.started": "2021-09-11T07:57:30.696124Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Replace NaN in missing values with -1.0\n",
    "Data = Data.replace(to_replace = 'NaN', value = '-1.0')\n",
    "Datafloat = Data.copy()\n",
    "#Convert to float datatype\n",
    "Datafloat = Datafloat.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c5cf2b11-d1f2-4254-80e5-6e97610e46a1",
    "_uuid": "d86198c1-4395-4205-8273-32c1a0ceecda",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:31.12477Z",
     "iopub.status.busy": "2021-09-11T07:57:31.124316Z",
     "iopub.status.idle": "2021-09-11T07:57:31.129984Z",
     "shell.execute_reply": "2021-09-11T07:57:31.129142Z",
     "shell.execute_reply.started": "2021-09-11T07:57:31.124738Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Impute Missing Values\n",
    "def impute(df, cols,strat):\n",
    "    imputer = Imputer(missing_values = -1.0,strategy=strat)\n",
    "    df_impute = df[cols]\n",
    "    df[cols] = imputer.fit_transform(df_impute.values.reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "fdebd961-3efa-45f6-b279-b2f4c4c4fae3",
    "_uuid": "7b55ad7f-bde4-4b86-ae01-5b30e9570f31",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:31.131367Z",
     "iopub.status.busy": "2021-09-11T07:57:31.131136Z",
     "iopub.status.idle": "2021-09-11T07:57:32.131654Z",
     "shell.execute_reply": "2021-09-11T07:57:32.130925Z",
     "shell.execute_reply.started": "2021-09-11T07:57:31.13134Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Imputing strategy mean, nearest and linear interpolation\n",
    "for i in Datafloat.columns:\n",
    "    if np.abs(np.sum(Datafloat[i][:] == -1.0)) >= 700:\n",
    "        \n",
    "        Datafloat.drop([i],inplace = True,axis =1)\n",
    "    elif np.abs(np.sum(Datafloat[i][:] == -1.0)) <=30:\n",
    "    #    print(i)\n",
    "        600 #and np.abs(np.sum(Data[i][:] == -1.0)) <=780:\n",
    "        Datafloat = impute(Datafloat,i,'mean')\n",
    "    elif np.abs(np.sum(Datafloat[i][:] == -1.0))  > 30 and np.abs(np.sum(Datafloat[i][:] == -1))  <=200:\n",
    "        Datafloat[i].replace(to_replace = -1.0, value = None)\n",
    "        Datafloat[i].interpolate(method ='nearest', limit_direction ='forward')\n",
    "    elif np.abs(np.sum(Datafloat[i][:] == -1.0))  > 200 and np.abs(np.sum(Datafloat[i][:] == -1))  <=300:\n",
    "        Datafloat[i].replace(to_replace = -1.0, value = None)\n",
    "        Datafloat[i].interpolate(method ='linear', limit_direction ='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "105ba3bc-6084-42ca-b6c5-b4272873309e",
    "_uuid": "6ab3feb6-dadc-4036-8d61-8d237bfb106c",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.133241Z",
     "iopub.status.busy": "2021-09-11T07:57:32.132921Z",
     "iopub.status.idle": "2021-09-11T07:57:32.139107Z",
     "shell.execute_reply": "2021-09-11T07:57:32.138277Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.133191Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Get the unique value columns\n",
    "def uniq_cols_fn(data):\n",
    "    uniq_col_list = []\n",
    "    for column in data.columns:\n",
    "        if data[column].nunique() == 1:\n",
    "            uniq_col_list.append(column)\n",
    "    return uniq_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c8311aff-fb00-48bc-a9f2-60f915989022",
    "_uuid": "26261c54-1f37-4ce5-8cc9-89907337b256",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.140333Z",
     "iopub.status.busy": "2021-09-11T07:57:32.140119Z",
     "iopub.status.idle": "2021-09-11T07:57:32.233313Z",
     "shell.execute_reply": "2021-09-11T07:57:32.232627Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.14029Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniq_cols_fn(Datafloat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b560dd76-e761-4de3-99cb-15f183173acc",
    "_uuid": "0444e978-cd90-43d5-9f3c-abdb9f4332de",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.235962Z",
     "iopub.status.busy": "2021-09-11T07:57:32.23575Z",
     "iopub.status.idle": "2021-09-11T07:57:32.29819Z",
     "shell.execute_reply": "2021-09-11T07:57:32.297514Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.235938Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 442)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datafloat = Datafloat.drop(axis=1, columns=uniq_cols_fn(Datafloat))\n",
    "Datafloat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "77dd5ef4-d05b-42d2-bacd-dd11796fd044",
    "_uuid": "fac8ce16-7314-4f86-9475-99c3c123ea47",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.300021Z",
     "iopub.status.busy": "2021-09-11T07:57:32.299574Z",
     "iopub.status.idle": "2021-09-11T07:57:32.306044Z",
     "shell.execute_reply": "2021-09-11T07:57:32.305199Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.299977Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1463"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y==-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "786cfa89-2ffa-4169-9113-0831cd18adba",
    "_uuid": "c365ec92-1a3d-453c-bbe6-d8ca20a9b983",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.307303Z",
     "iopub.status.busy": "2021-09-11T07:57:32.307108Z",
     "iopub.status.idle": "2021-09-11T07:57:32.333859Z",
     "shell.execute_reply": "2021-09-11T07:57:32.33301Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.30728Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Normalize the data between +1 and -1\n",
    "mmscaler    = MinMaxScaler(feature_range=(-1,1))\n",
    "Datascaled   = mmscaler.fit_transform(Datafloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "5298632e-abf0-4f86-84f7-d4f309b6f8f3",
    "_uuid": "f20b0dcc-2d42-4042-bb1d-36da215d52ec",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.335886Z",
     "iopub.status.busy": "2021-09-11T07:57:32.335561Z",
     "iopub.status.idle": "2021-09-11T07:57:32.340214Z",
     "shell.execute_reply": "2021-09-11T07:57:32.339381Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.335847Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "TrainDatascaled = Datascaled\n",
    "y_trn = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "48950b32-e932-44da-a62d-22db9fe2600b",
    "_uuid": "7d42ca26-4282-4e4b-b9f9-67077e90f3bc",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.341746Z",
     "iopub.status.busy": "2021-09-11T07:57:32.341427Z",
     "iopub.status.idle": "2021-09-11T07:57:32.352935Z",
     "shell.execute_reply": "2021-09-11T07:57:32.352143Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.341708Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 442)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainDatascaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_aa_gm(ypred, ytrue):\n",
    "    cm = confusion_matrix(ytrue, ypred)\n",
    "    sum_classes = np.sum(cm, axis=1)\n",
    "    true_pred = np.diagonal(cm)\n",
    "    tp_rate = true_pred/sum_classes\n",
    "    ACSA = np.mean(tp_rate)\n",
    "    GM = np.sqrt(np.prod(tp_rate))\n",
    "    return ACSA, GM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "01431385-e9b2-469d-9b14-7b42def64678",
    "_uuid": "c9b420b3-07ef-43ac-abb8-c5e84479894b"
   },
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e022e2a-6381-409b-95ea-9a44e57d151e",
    "_uuid": "623d73bb-fb6e-4543-81dc-f25470464f91"
   },
   "source": [
    "#### VAE code is adopted and modified from the following reference.\n",
    "#### https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/blob/master/chapter8-vae/vae-mlp-mnist-8.1.1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "ae2c9c08-2e68-44d8-b466-40fa86d16dec",
    "_uuid": "856a2863-72b9-4e31-9244-f1f63934b9d3",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.354427Z",
     "iopub.status.busy": "2021-09-11T07:57:32.354175Z",
     "iopub.status.idle": "2021-09-11T07:57:32.364033Z",
     "shell.execute_reply": "2021-09-11T07:57:32.363266Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.354394Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "start_dimension = Datafloat.shape[1]\n",
    "input_shape = (Datafloat.shape[1], )\n",
    "intermediate_dim = 220 \n",
    "batch_size = 24\n",
    "latent_dim = 7\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1e86b9f9-6c65-4291-bce4-bb92075d0170",
    "_uuid": "4239fd37-7841-413a-a623-ce49cef19174"
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "d35b8442-e517-474b-b16f-d415eebecea5",
    "_uuid": "f79acdab-151d-486c-83cc-33365956e060",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.365714Z",
     "iopub.status.busy": "2021-09-11T07:57:32.365289Z",
     "iopub.status.idle": "2021-09-11T07:57:32.373745Z",
     "shell.execute_reply": "2021-09-11T07:57:32.373046Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.365675Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9f853abf-cf0c-46ce-a761-64753bd5b938",
    "_uuid": "1b23319b-c08f-44e7-9125-5736b5ae051d"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "0626ec4d-b538-43f0-b2e2-590ae50ee5d5",
    "_uuid": "e6c5611a-fe42-4f46-ab2b-bbe9d36062ae",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.376857Z",
     "iopub.status.busy": "2021-09-11T07:57:32.376638Z",
     "iopub.status.idle": "2021-09-11T07:57:32.485983Z",
     "shell.execute_reply": "2021-09-11T07:57:32.484641Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.376832Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 442)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 220)          97460       encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 7)            1547        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 7)            1547        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 7)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 100,554\n",
      "Trainable params: 100,554\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder model\n",
    "inputs = keras.Input(shape=input_shape, name='encoder_input')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "z = Lambda(sampling,\n",
    "           output_shape=(latent_dim,), \n",
    "           name='z')([z_mean, z_log_var])\n",
    "\n",
    "\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "649393b6-2452-487d-8f18-71f12154ae6d",
    "_uuid": "23ab95cf-8375-4b7d-a746-f026aeafff04"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "251bd022-12c5-4664-b145-7ee8abcffdb5",
    "_uuid": "ba874b52-fecf-44a7-8695-05bdcb85b777",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.487572Z",
     "iopub.status.busy": "2021-09-11T07:57:32.487242Z",
     "iopub.status.idle": "2021-09-11T07:57:32.519766Z",
     "shell.execute_reply": "2021-09-11T07:57:32.518956Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.487534Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 220)               1760      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 442)               97682     \n",
      "=================================================================\n",
      "Total params: 99,442\n",
      "Trainable params: 99,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder model\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(start_dimension, activation='tanh')(x)\n",
    "\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "5913a00a-4a0b-487b-bab6-2992d1df603b",
    "_uuid": "92d0ca22-07e1-47b5-b2f2-f0a02620f342",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.521197Z",
     "iopub.status.busy": "2021-09-11T07:57:32.520891Z",
     "iopub.status.idle": "2021-09-11T07:57:32.55819Z",
     "shell.execute_reply": "2021-09-11T07:57:32.557312Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.521165Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "06890c70-8cef-402e-9a17-41fd49521b90",
    "_uuid": "198c73aa-bfe2-424e-9830-17ba3429ec52",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.559487Z",
     "iopub.status.busy": "2021-09-11T07:57:32.559264Z",
     "iopub.status.idle": "2021-09-11T07:57:32.575156Z",
     "shell.execute_reply": "2021-09-11T07:57:32.574192Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.559449Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_trainvae, X_valvae, y_trvae, y_valvae = train_test_split(TrainDatascaled, TrainDatascaled, \n",
    "                                                    test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "1df6e665-6b77-4b6f-b7dc-6235dc5b4bf7",
    "_uuid": "e5d83773-87ea-41bc-900a-ba39561e6151",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.576635Z",
     "iopub.status.busy": "2021-09-11T07:57:32.576375Z",
     "iopub.status.idle": "2021-09-11T07:57:32.581337Z",
     "shell.execute_reply": "2021-09-11T07:57:32.580207Z",
     "shell.execute_reply.started": "2021-09-11T07:57:32.576608Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "7b4a49d0-a7fb-4cf5-95df-3d5555e9111b",
    "_uuid": "25e719d5-6d86-4894-9120-dea0cd65bbb6",
    "execution": {
     "iopub.execute_input": "2021-09-11T07:57:32.582914Z",
     "iopub.status.busy": "2021-09-11T07:57:32.582534Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_mlp\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 442)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 7), (None, 7 100554      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 442)          99442       encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 220)          97460       encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 7)            1547        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 7)            1547        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 7)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square (TFOpLambda)     (None, 7)            0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (None, 442)          0           decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 442)          0           encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 7)            0           tf.__operators__.add[0][0]       \n",
      "                                                                 tf.math.square[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 7)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.squared_difference (TFO (None, 442)          0           tf.convert_to_tensor[0][0]       \n",
      "                                                                 tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 7)            0           tf.math.subtract[0][0]           \n",
      "                                                                 tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None,)              0           tf.math.squared_difference[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None,)              0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None,)              0           tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None,)              0           tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None,)              0           tf.math.multiply[0][0]           \n",
      "                                                                 tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb ()                   0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf.math.reduce_mean_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 199,996\n",
      "Trainable params: 199,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "56/56 [==============================] - 2s 7ms/step - loss: 66.6230 - val_loss: 34.4882\n",
      "Epoch 2/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 33.5224 - val_loss: 31.4618\n",
      "Epoch 3/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 31.3876 - val_loss: 29.7340\n",
      "Epoch 4/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 29.8674 - val_loss: 28.9927\n",
      "Epoch 5/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 28.9018 - val_loss: 27.9205\n",
      "Epoch 6/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 28.6512 - val_loss: 27.2684\n",
      "Epoch 7/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 27.6238 - val_loss: 26.7709\n",
      "Epoch 8/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 26.8382 - val_loss: 26.2389\n",
      "Epoch 9/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 26.2466 - val_loss: 25.6899\n",
      "Epoch 10/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 25.8894 - val_loss: 25.6073\n",
      "Epoch 11/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 25.7151 - val_loss: 25.5485\n",
      "Epoch 12/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 25.5116 - val_loss: 25.3163\n",
      "Epoch 13/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 25.4150 - val_loss: 25.5329\n",
      "Epoch 14/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 25.3707 - val_loss: 25.3077\n",
      "Epoch 15/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 25.2695 - val_loss: 25.2835\n",
      "Epoch 16/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 25.1521 - val_loss: 24.8376\n",
      "Epoch 17/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 25.0943 - val_loss: 25.0276\n",
      "Epoch 18/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 25.0635 - val_loss: 25.2575\n",
      "Epoch 19/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.9824 - val_loss: 24.8777\n",
      "Epoch 20/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.9810 - val_loss: 24.7580\n",
      "Epoch 21/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.9225 - val_loss: 24.7890\n",
      "Epoch 22/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.7867 - val_loss: 24.9042\n",
      "Epoch 23/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.8519 - val_loss: 24.8224\n",
      "Epoch 24/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.8179 - val_loss: 24.8097\n",
      "Epoch 25/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.6715 - val_loss: 24.6468\n",
      "Epoch 26/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.6114 - val_loss: 24.6863\n",
      "Epoch 27/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.7084 - val_loss: 24.5537\n",
      "Epoch 28/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.7127 - val_loss: 24.4340\n",
      "Epoch 29/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.6996 - val_loss: 24.4867\n",
      "Epoch 30/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.5721 - val_loss: 24.5162\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 4ms/step - loss: 24.6196 - val_loss: 24.6211\n",
      "Epoch 32/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.7074 - val_loss: 24.6088\n",
      "Epoch 33/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.5794 - val_loss: 24.5902\n",
      "Epoch 34/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.5385 - val_loss: 24.5204\n",
      "Epoch 35/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.5379 - val_loss: 24.7281\n",
      "Epoch 36/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.3862 - val_loss: 24.3475\n",
      "Epoch 37/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.5271 - val_loss: 24.5268\n",
      "Epoch 38/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.4479 - val_loss: 24.5690\n",
      "Epoch 39/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.4818 - val_loss: 24.5661\n",
      "Epoch 40/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.4283 - val_loss: 24.5087\n",
      "Epoch 41/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.2948 - val_loss: 24.2945\n",
      "Epoch 42/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.4258 - val_loss: 24.3739\n",
      "Epoch 43/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.3869 - val_loss: 24.6131\n",
      "Epoch 44/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.3543 - val_loss: 24.4898\n",
      "Epoch 45/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.3236 - val_loss: 24.4355\n",
      "Epoch 46/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.2715 - val_loss: 24.2288\n",
      "Epoch 47/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.2128 - val_loss: 24.2685\n",
      "Epoch 48/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.2182 - val_loss: 24.3293\n",
      "Epoch 49/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.2831 - val_loss: 24.4223\n",
      "Epoch 50/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.2749 - val_loss: 24.2555\n",
      "Epoch 51/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.1502 - val_loss: 24.2235\n",
      "Epoch 52/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.1136 - val_loss: 24.4511\n",
      "Epoch 53/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.1833 - val_loss: 24.4228\n",
      "Epoch 54/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0459 - val_loss: 24.0443\n",
      "Epoch 55/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.0598 - val_loss: 24.1911\n",
      "Epoch 56/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.1123 - val_loss: 24.3242\n",
      "Epoch 57/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0591 - val_loss: 23.9224\n",
      "Epoch 58/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.0918 - val_loss: 24.5387\n",
      "Epoch 59/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.1820 - val_loss: 24.5866\n",
      "Epoch 60/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0497 - val_loss: 24.1520\n",
      "Epoch 61/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0649 - val_loss: 24.3301\n",
      "Epoch 62/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0331 - val_loss: 24.0517\n",
      "Epoch 63/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.0097 - val_loss: 24.1712\n",
      "Epoch 64/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0685 - val_loss: 24.4297\n",
      "Epoch 65/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0807 - val_loss: 24.1837\n",
      "Epoch 66/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0983 - val_loss: 24.2418\n",
      "Epoch 67/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.9738 - val_loss: 24.1607\n",
      "Epoch 68/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 24.0045 - val_loss: 24.3358\n",
      "Epoch 69/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.9902 - val_loss: 24.1969\n",
      "Epoch 70/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.1177 - val_loss: 24.1794\n",
      "Epoch 71/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.1299 - val_loss: 24.2088\n",
      "Epoch 72/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.9802 - val_loss: 24.1095\n",
      "Epoch 73/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.9121 - val_loss: 24.0406\n",
      "Epoch 74/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 24.0069 - val_loss: 23.8223\n",
      "Epoch 75/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8995 - val_loss: 23.9023\n",
      "Epoch 76/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8868 - val_loss: 24.3553\n",
      "Epoch 77/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.9102 - val_loss: 24.1904\n",
      "Epoch 78/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.9074 - val_loss: 24.1444\n",
      "Epoch 79/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8803 - val_loss: 23.9296\n",
      "Epoch 80/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8831 - val_loss: 23.9181\n",
      "Epoch 81/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8878 - val_loss: 24.0016\n",
      "Epoch 82/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8856 - val_loss: 23.8989\n",
      "Epoch 83/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8582 - val_loss: 24.0375\n",
      "Epoch 84/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.9070 - val_loss: 23.9087\n",
      "Epoch 85/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8356 - val_loss: 24.0632\n",
      "Epoch 86/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8235 - val_loss: 24.1313\n",
      "Epoch 87/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8177 - val_loss: 23.9526\n",
      "Epoch 88/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8653 - val_loss: 24.1349\n",
      "Epoch 89/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.9162 - val_loss: 23.8919\n",
      "Epoch 90/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.9027 - val_loss: 24.1750\n",
      "Epoch 91/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7812 - val_loss: 23.9136\n",
      "Epoch 92/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8320 - val_loss: 24.0665\n",
      "Epoch 93/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8321 - val_loss: 24.2155\n",
      "Epoch 94/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7176 - val_loss: 24.3890\n",
      "Epoch 95/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8684 - val_loss: 24.2701\n",
      "Epoch 96/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7896 - val_loss: 23.7305\n",
      "Epoch 97/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8343 - val_loss: 23.8608\n",
      "Epoch 98/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7757 - val_loss: 23.8863\n",
      "Epoch 99/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8346 - val_loss: 23.9382\n",
      "Epoch 100/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7888 - val_loss: 23.9491\n",
      "Epoch 101/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7594 - val_loss: 23.8808\n",
      "Epoch 102/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7494 - val_loss: 24.0091\n",
      "Epoch 103/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.6513 - val_loss: 23.9176\n",
      "Epoch 104/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6805 - val_loss: 23.9338\n",
      "Epoch 105/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.7805 - val_loss: 23.7315\n",
      "Epoch 106/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8207 - val_loss: 24.0679\n",
      "Epoch 107/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7387 - val_loss: 24.5269\n",
      "Epoch 108/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8656 - val_loss: 23.8368\n",
      "Epoch 109/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7200 - val_loss: 24.0559\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7710 - val_loss: 23.7530\n",
      "Epoch 111/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7167 - val_loss: 23.9689\n",
      "Epoch 112/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8189 - val_loss: 23.9674\n",
      "Epoch 113/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7984 - val_loss: 24.1702\n",
      "Epoch 114/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6773 - val_loss: 24.1842\n",
      "Epoch 115/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6483 - val_loss: 23.8910\n",
      "Epoch 116/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.8029 - val_loss: 23.9708\n",
      "Epoch 117/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6173 - val_loss: 24.2559\n",
      "Epoch 118/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6963 - val_loss: 23.9044\n",
      "Epoch 119/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6655 - val_loss: 23.9984\n",
      "Epoch 120/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7319 - val_loss: 23.7992\n",
      "Epoch 121/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5719 - val_loss: 23.7647\n",
      "Epoch 122/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6028 - val_loss: 24.1558\n",
      "Epoch 123/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6153 - val_loss: 23.7528\n",
      "Epoch 124/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6282 - val_loss: 24.2118\n",
      "Epoch 125/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5374 - val_loss: 24.0161\n",
      "Epoch 126/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6581 - val_loss: 24.0490\n",
      "Epoch 127/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5770 - val_loss: 23.9394\n",
      "Epoch 128/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5940 - val_loss: 23.9075\n",
      "Epoch 129/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6583 - val_loss: 24.0955\n",
      "Epoch 130/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.6538 - val_loss: 24.1070\n",
      "Epoch 131/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5990 - val_loss: 24.0265\n",
      "Epoch 132/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.7652 - val_loss: 24.2402\n",
      "Epoch 133/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6320 - val_loss: 23.8879\n",
      "Epoch 134/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5227 - val_loss: 24.0724\n",
      "Epoch 135/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6086 - val_loss: 23.8140\n",
      "Epoch 136/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4862 - val_loss: 24.0181\n",
      "Epoch 137/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4996 - val_loss: 24.0614\n",
      "Epoch 138/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5327 - val_loss: 23.9233\n",
      "Epoch 139/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5135 - val_loss: 24.0201\n",
      "Epoch 140/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3950 - val_loss: 23.8890\n",
      "Epoch 141/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5924 - val_loss: 23.9547\n",
      "Epoch 142/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5063 - val_loss: 24.1956\n",
      "Epoch 143/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5971 - val_loss: 23.8120\n",
      "Epoch 144/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5140 - val_loss: 23.8552\n",
      "Epoch 145/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5476 - val_loss: 23.8948\n",
      "Epoch 146/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4874 - val_loss: 23.6388\n",
      "Epoch 147/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.5077 - val_loss: 24.1190\n",
      "Epoch 148/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4367 - val_loss: 24.0059\n",
      "Epoch 149/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6411 - val_loss: 24.1625\n",
      "Epoch 150/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4095 - val_loss: 24.0208\n",
      "Epoch 151/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4906 - val_loss: 23.7047\n",
      "Epoch 152/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4328 - val_loss: 24.3177\n",
      "Epoch 153/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4797 - val_loss: 24.0031\n",
      "Epoch 154/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4410 - val_loss: 24.1638\n",
      "Epoch 155/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4756 - val_loss: 24.1367\n",
      "Epoch 156/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5266 - val_loss: 23.9003\n",
      "Epoch 157/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5046 - val_loss: 23.8446\n",
      "Epoch 158/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.4815 - val_loss: 23.9954\n",
      "Epoch 159/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4598 - val_loss: 23.9086\n",
      "Epoch 160/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5290 - val_loss: 24.0299\n",
      "Epoch 161/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4193 - val_loss: 24.0574\n",
      "Epoch 162/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4068 - val_loss: 23.9169\n",
      "Epoch 163/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5631 - val_loss: 24.0074\n",
      "Epoch 164/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4048 - val_loss: 23.8979\n",
      "Epoch 165/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.6393 - val_loss: 23.8398\n",
      "Epoch 166/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5234 - val_loss: 23.7727\n",
      "Epoch 167/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3586 - val_loss: 24.0205\n",
      "Epoch 168/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4009 - val_loss: 24.1610\n",
      "Epoch 169/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4129 - val_loss: 24.2227\n",
      "Epoch 170/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4542 - val_loss: 23.9537\n",
      "Epoch 171/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3396 - val_loss: 23.6224\n",
      "Epoch 172/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5969 - val_loss: 23.9700\n",
      "Epoch 173/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4428 - val_loss: 23.9171\n",
      "Epoch 174/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4259 - val_loss: 24.0424\n",
      "Epoch 175/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3919 - val_loss: 23.8392\n",
      "Epoch 176/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3537 - val_loss: 23.9239\n",
      "Epoch 177/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3981 - val_loss: 24.0974\n",
      "Epoch 178/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4109 - val_loss: 24.0651\n",
      "Epoch 179/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3736 - val_loss: 23.8353\n",
      "Epoch 180/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4233 - val_loss: 23.9768\n",
      "Epoch 181/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.5033 - val_loss: 23.8200\n",
      "Epoch 182/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3588 - val_loss: 24.1005\n",
      "Epoch 183/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3314 - val_loss: 24.0097\n",
      "Epoch 184/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4493 - val_loss: 23.7938\n",
      "Epoch 185/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3813 - val_loss: 24.0901\n",
      "Epoch 186/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3798 - val_loss: 24.0258\n",
      "Epoch 187/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.4902 - val_loss: 23.9198\n",
      "Epoch 188/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4639 - val_loss: 23.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.5153 - val_loss: 23.9965\n",
      "Epoch 190/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 23.3536 - val_loss: 24.1062\n",
      "Epoch 191/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4291 - val_loss: 23.8901\n",
      "Epoch 192/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3376 - val_loss: 23.9946\n",
      "Epoch 193/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4226 - val_loss: 24.1102\n",
      "Epoch 194/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2950 - val_loss: 23.8182\n",
      "Epoch 195/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3910 - val_loss: 23.7294\n",
      "Epoch 196/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3008 - val_loss: 23.9697\n",
      "Epoch 197/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3485 - val_loss: 24.1245\n",
      "Epoch 198/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3476 - val_loss: 23.9875\n",
      "Epoch 199/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3012 - val_loss: 24.1629\n",
      "Epoch 200/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3968 - val_loss: 23.8404\n",
      "Epoch 201/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2742 - val_loss: 24.1518\n",
      "Epoch 202/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3413 - val_loss: 23.8750\n",
      "Epoch 203/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.4451 - val_loss: 23.9417\n",
      "Epoch 204/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.4105 - val_loss: 23.9219\n",
      "Epoch 205/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3109 - val_loss: 23.9511\n",
      "Epoch 206/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2618 - val_loss: 23.9433\n",
      "Epoch 207/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2304 - val_loss: 24.1597\n",
      "Epoch 208/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2450 - val_loss: 23.7976\n",
      "Epoch 209/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3243 - val_loss: 23.7507\n",
      "Epoch 210/1000\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 23.3421 - val_loss: 24.1744\n",
      "Epoch 211/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2487 - val_loss: 23.8520\n",
      "Epoch 212/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3223 - val_loss: 23.6988\n",
      "Epoch 213/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1604 - val_loss: 24.0599\n",
      "Epoch 214/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4568 - val_loss: 23.9151\n",
      "Epoch 215/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2706 - val_loss: 23.8370\n",
      "Epoch 216/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2992 - val_loss: 23.8831\n",
      "Epoch 217/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2689 - val_loss: 24.0233\n",
      "Epoch 218/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.2641 - val_loss: 23.9138\n",
      "Epoch 219/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3079 - val_loss: 23.9593\n",
      "Epoch 220/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2405 - val_loss: 23.9861\n",
      "Epoch 221/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4227 - val_loss: 23.8621\n",
      "Epoch 222/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.2893 - val_loss: 24.0685\n",
      "Epoch 223/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.3576 - val_loss: 23.9925\n",
      "Epoch 224/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3009 - val_loss: 23.9668\n",
      "Epoch 225/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1898 - val_loss: 23.9168\n",
      "Epoch 226/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3008 - val_loss: 23.9345\n",
      "Epoch 227/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.2641 - val_loss: 23.7975\n",
      "Epoch 228/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.3374 - val_loss: 23.7264\n",
      "Epoch 229/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 23.2664 - val_loss: 24.1477\n",
      "Epoch 230/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4125 - val_loss: 23.9249\n",
      "Epoch 231/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1500 - val_loss: 24.0143\n",
      "Epoch 232/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3258 - val_loss: 24.1206\n",
      "Epoch 233/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2905 - val_loss: 23.9525\n",
      "Epoch 234/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2990 - val_loss: 23.9211\n",
      "Epoch 235/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2972 - val_loss: 23.8334\n",
      "Epoch 236/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2294 - val_loss: 24.0061\n",
      "Epoch 237/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3277 - val_loss: 23.8032\n",
      "Epoch 238/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.4280 - val_loss: 23.9152\n",
      "Epoch 239/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2758 - val_loss: 23.6822\n",
      "Epoch 240/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1886 - val_loss: 23.8843\n",
      "Epoch 241/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.3055 - val_loss: 23.8869\n",
      "Epoch 242/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.2112 - val_loss: 23.6631\n",
      "Epoch 243/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2692 - val_loss: 23.8707\n",
      "Epoch 244/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.2280 - val_loss: 23.9206\n",
      "Epoch 245/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.2792 - val_loss: 23.8030\n",
      "Epoch 246/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2442 - val_loss: 23.8464\n",
      "Epoch 247/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2109 - val_loss: 23.7897\n",
      "Epoch 248/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2101 - val_loss: 23.8162\n",
      "Epoch 249/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1741 - val_loss: 23.8830\n",
      "Epoch 250/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2104 - val_loss: 24.0630\n",
      "Epoch 251/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2085 - val_loss: 23.8061\n",
      "Epoch 252/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1321 - val_loss: 23.8575\n",
      "Epoch 253/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1514 - val_loss: 23.8260\n",
      "Epoch 254/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1087 - val_loss: 24.0036\n",
      "Epoch 255/1000\n",
      "56/56 [==============================] - 0s 2ms/step - loss: 23.2103 - val_loss: 23.9107\n",
      "Epoch 256/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2018 - val_loss: 23.7944\n",
      "Epoch 257/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1635 - val_loss: 23.8587\n",
      "Epoch 258/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1474 - val_loss: 23.7640\n",
      "Epoch 259/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2597 - val_loss: 24.2733\n",
      "Epoch 260/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1425 - val_loss: 24.0078\n",
      "Epoch 261/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1048 - val_loss: 23.9752\n",
      "Epoch 262/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2432 - val_loss: 24.1291\n",
      "Epoch 263/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1108 - val_loss: 23.9765\n",
      "Epoch 264/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1266 - val_loss: 23.8789\n",
      "Epoch 265/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0278 - val_loss: 23.9158\n",
      "Epoch 266/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2440 - val_loss: 23.8211\n",
      "Epoch 267/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1593 - val_loss: 23.8001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1520 - val_loss: 24.0143\n",
      "Epoch 269/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1358 - val_loss: 24.0226\n",
      "Epoch 270/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1289 - val_loss: 23.9019\n",
      "Epoch 271/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1600 - val_loss: 24.0499\n",
      "Epoch 272/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.3148 - val_loss: 24.0363\n",
      "Epoch 273/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0233 - val_loss: 23.8974\n",
      "Epoch 274/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1231 - val_loss: 24.1254\n",
      "Epoch 275/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1184 - val_loss: 23.6292\n",
      "Epoch 276/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1400 - val_loss: 23.6531\n",
      "Epoch 277/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1616 - val_loss: 23.7472\n",
      "Epoch 278/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0601 - val_loss: 23.9243\n",
      "Epoch 279/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 23.0855 - val_loss: 23.8449\n",
      "Epoch 280/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 23.0392 - val_loss: 23.7006\n",
      "Epoch 281/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 23.0394 - val_loss: 23.8276\n",
      "Epoch 282/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 23.1325 - val_loss: 23.9532\n",
      "Epoch 283/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1888 - val_loss: 23.8290\n",
      "Epoch 284/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.0841 - val_loss: 24.0281\n",
      "Epoch 285/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1061 - val_loss: 23.7060\n",
      "Epoch 286/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1600 - val_loss: 23.7533\n",
      "Epoch 287/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1216 - val_loss: 23.7760\n",
      "Epoch 288/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1119 - val_loss: 23.9403\n",
      "Epoch 289/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0773 - val_loss: 23.9048\n",
      "Epoch 290/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0577 - val_loss: 23.8714\n",
      "Epoch 291/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0399 - val_loss: 23.9336\n",
      "Epoch 292/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1116 - val_loss: 24.1383\n",
      "Epoch 293/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1868 - val_loss: 23.9938\n",
      "Epoch 294/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1037 - val_loss: 23.9168\n",
      "Epoch 295/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0692 - val_loss: 24.0135\n",
      "Epoch 296/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0297 - val_loss: 23.7552\n",
      "Epoch 297/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0614 - val_loss: 23.9213\n",
      "Epoch 298/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0461 - val_loss: 23.9628\n",
      "Epoch 299/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2283 - val_loss: 23.8525\n",
      "Epoch 300/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.2021 - val_loss: 24.1075\n",
      "Epoch 301/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.0800 - val_loss: 23.8924\n",
      "Epoch 302/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1179 - val_loss: 23.9069\n",
      "Epoch 303/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.0470 - val_loss: 23.8309\n",
      "Epoch 304/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0840 - val_loss: 23.8777\n",
      "Epoch 305/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.0490 - val_loss: 23.8453\n",
      "Epoch 306/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0102 - val_loss: 23.7486\n",
      "Epoch 307/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1106 - val_loss: 23.9609\n",
      "Epoch 308/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.0837 - val_loss: 23.9385\n",
      "Epoch 309/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9820 - val_loss: 23.7318\n",
      "Epoch 310/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0867 - val_loss: 23.9744\n",
      "Epoch 311/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0641 - val_loss: 24.1516\n",
      "Epoch 312/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1019 - val_loss: 24.0397\n",
      "Epoch 313/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.1198 - val_loss: 24.0168\n",
      "Epoch 314/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0685 - val_loss: 24.0350\n",
      "Epoch 315/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9683 - val_loss: 23.9940\n",
      "Epoch 316/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0653 - val_loss: 23.9179\n",
      "Epoch 317/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9452 - val_loss: 24.1383\n",
      "Epoch 318/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0398 - val_loss: 23.8819\n",
      "Epoch 319/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9788 - val_loss: 24.0077\n",
      "Epoch 320/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9870 - val_loss: 23.8377\n",
      "Epoch 321/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0083 - val_loss: 23.7624\n",
      "Epoch 322/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9796 - val_loss: 23.8216\n",
      "Epoch 323/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0157 - val_loss: 23.8263\n",
      "Epoch 324/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9520 - val_loss: 24.0901\n",
      "Epoch 325/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9312 - val_loss: 24.0860\n",
      "Epoch 326/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0257 - val_loss: 24.0706\n",
      "Epoch 327/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0269 - val_loss: 24.0176\n",
      "Epoch 328/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0045 - val_loss: 24.0890\n",
      "Epoch 329/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.9856 - val_loss: 23.7132\n",
      "Epoch 330/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9727 - val_loss: 23.8449\n",
      "Epoch 331/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0200 - val_loss: 24.1207\n",
      "Epoch 332/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0958 - val_loss: 23.7101\n",
      "Epoch 333/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0499 - val_loss: 23.8722\n",
      "Epoch 334/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9071 - val_loss: 23.8247\n",
      "Epoch 335/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9687 - val_loss: 23.8213\n",
      "Epoch 336/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9459 - val_loss: 23.9528\n",
      "Epoch 337/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9441 - val_loss: 23.8143\n",
      "Epoch 338/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9197 - val_loss: 23.6700\n",
      "Epoch 339/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0477 - val_loss: 23.9958\n",
      "Epoch 340/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.0142 - val_loss: 24.0163\n",
      "Epoch 341/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9178 - val_loss: 23.9944\n",
      "Epoch 342/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.9747 - val_loss: 23.8484\n",
      "Epoch 343/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.9927 - val_loss: 24.0550\n",
      "Epoch 344/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.0679 - val_loss: 24.1769\n",
      "Epoch 345/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.9140 - val_loss: 24.0280\n",
      "Epoch 346/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 23.0087 - val_loss: 23.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 23.0213 - val_loss: 23.8254\n",
      "Epoch 348/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.9830 - val_loss: 23.9988\n",
      "Epoch 349/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.9632 - val_loss: 23.9624\n",
      "Epoch 350/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.9570 - val_loss: 24.3475\n",
      "Epoch 351/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0243 - val_loss: 24.0872\n",
      "Epoch 352/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0175 - val_loss: 24.0881\n",
      "Epoch 353/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9041 - val_loss: 23.9957\n",
      "Epoch 354/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0031 - val_loss: 24.1144\n",
      "Epoch 355/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9417 - val_loss: 23.8926\n",
      "Epoch 356/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0245 - val_loss: 23.9587\n",
      "Epoch 357/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 23.1919 - val_loss: 23.9605\n",
      "Epoch 358/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0540 - val_loss: 23.9051\n",
      "Epoch 359/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0481 - val_loss: 23.7529\n",
      "Epoch 360/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8927 - val_loss: 23.9054\n",
      "Epoch 361/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0597 - val_loss: 23.8808\n",
      "Epoch 362/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.9415 - val_loss: 24.0409\n",
      "Epoch 363/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9234 - val_loss: 23.7424\n",
      "Epoch 364/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8791 - val_loss: 23.9420\n",
      "Epoch 365/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0114 - val_loss: 23.7736\n",
      "Epoch 366/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0431 - val_loss: 23.7733\n",
      "Epoch 367/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9055 - val_loss: 24.0274\n",
      "Epoch 368/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0237 - val_loss: 23.9972\n",
      "Epoch 369/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9956 - val_loss: 24.1775\n",
      "Epoch 370/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0418 - val_loss: 23.9445\n",
      "Epoch 371/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9254 - val_loss: 24.0181\n",
      "Epoch 372/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9103 - val_loss: 24.1398\n",
      "Epoch 373/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9646 - val_loss: 23.9530\n",
      "Epoch 374/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0004 - val_loss: 24.2679\n",
      "Epoch 375/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8376 - val_loss: 24.0774\n",
      "Epoch 376/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9233 - val_loss: 24.0003\n",
      "Epoch 377/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8667 - val_loss: 23.6863\n",
      "Epoch 378/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9439 - val_loss: 23.9370\n",
      "Epoch 379/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9473 - val_loss: 24.0631\n",
      "Epoch 380/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8790 - val_loss: 24.0574\n",
      "Epoch 381/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9072 - val_loss: 24.0246\n",
      "Epoch 382/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8542 - val_loss: 23.8441\n",
      "Epoch 383/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9390 - val_loss: 23.8904\n",
      "Epoch 384/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7775 - val_loss: 23.9386\n",
      "Epoch 385/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9278 - val_loss: 23.8451\n",
      "Epoch 386/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9251 - val_loss: 24.2209\n",
      "Epoch 387/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8794 - val_loss: 24.0779\n",
      "Epoch 388/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7895 - val_loss: 23.7171\n",
      "Epoch 389/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8470 - val_loss: 24.1738\n",
      "Epoch 390/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0054 - val_loss: 23.9698\n",
      "Epoch 391/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9184 - val_loss: 23.9650\n",
      "Epoch 392/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9840 - val_loss: 23.9891\n",
      "Epoch 393/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9950 - val_loss: 23.9777\n",
      "Epoch 394/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8690 - val_loss: 23.7851\n",
      "Epoch 395/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8457 - val_loss: 23.9358\n",
      "Epoch 396/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0103 - val_loss: 24.0456\n",
      "Epoch 397/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9638 - val_loss: 23.6538\n",
      "Epoch 398/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8660 - val_loss: 23.6467\n",
      "Epoch 399/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8868 - val_loss: 24.0904\n",
      "Epoch 400/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9242 - val_loss: 23.9688\n",
      "Epoch 401/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8945 - val_loss: 23.8962\n",
      "Epoch 402/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8926 - val_loss: 24.0732\n",
      "Epoch 403/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8508 - val_loss: 23.7650\n",
      "Epoch 404/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8078 - val_loss: 23.9895\n",
      "Epoch 405/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8941 - val_loss: 24.0705\n",
      "Epoch 406/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 23.0191 - val_loss: 23.7903\n",
      "Epoch 407/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8952 - val_loss: 23.9023\n",
      "Epoch 408/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7325 - val_loss: 23.7224\n",
      "Epoch 409/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8791 - val_loss: 24.0497\n",
      "Epoch 410/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6829 - val_loss: 23.9351\n",
      "Epoch 411/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7166 - val_loss: 23.9919\n",
      "Epoch 412/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8713 - val_loss: 24.0560\n",
      "Epoch 413/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9009 - val_loss: 24.0115\n",
      "Epoch 414/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8739 - val_loss: 23.8500\n",
      "Epoch 415/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9148 - val_loss: 23.8076\n",
      "Epoch 416/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9521 - val_loss: 24.0868\n",
      "Epoch 417/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7594 - val_loss: 24.1302\n",
      "Epoch 418/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8851 - val_loss: 24.0272\n",
      "Epoch 419/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7791 - val_loss: 23.8919\n",
      "Epoch 420/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8796 - val_loss: 24.0492\n",
      "Epoch 421/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7485 - val_loss: 23.9418\n",
      "Epoch 422/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9279 - val_loss: 24.0648\n",
      "Epoch 423/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9954 - val_loss: 23.9578\n",
      "Epoch 424/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8567 - val_loss: 23.9837\n",
      "Epoch 425/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7857 - val_loss: 23.7796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9575 - val_loss: 23.9127\n",
      "Epoch 427/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8309 - val_loss: 24.2349\n",
      "Epoch 428/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8156 - val_loss: 23.9899\n",
      "Epoch 429/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8974 - val_loss: 23.9464\n",
      "Epoch 430/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7961 - val_loss: 24.0339\n",
      "Epoch 431/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8505 - val_loss: 24.0624\n",
      "Epoch 432/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7406 - val_loss: 23.7565\n",
      "Epoch 433/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8569 - val_loss: 23.9443\n",
      "Epoch 434/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7664 - val_loss: 24.0118\n",
      "Epoch 435/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8907 - val_loss: 23.9808\n",
      "Epoch 436/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9075 - val_loss: 23.8926\n",
      "Epoch 437/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8676 - val_loss: 24.1610\n",
      "Epoch 438/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8553 - val_loss: 24.1044\n",
      "Epoch 439/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8567 - val_loss: 24.0054\n",
      "Epoch 440/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8995 - val_loss: 24.0281\n",
      "Epoch 441/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8200 - val_loss: 24.0664\n",
      "Epoch 442/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8163 - val_loss: 23.9766\n",
      "Epoch 443/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9389 - val_loss: 23.7961\n",
      "Epoch 444/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8293 - val_loss: 23.8744\n",
      "Epoch 445/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8761 - val_loss: 24.0210\n",
      "Epoch 446/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7946 - val_loss: 24.1281\n",
      "Epoch 447/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7206 - val_loss: 23.7889\n",
      "Epoch 448/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7884 - val_loss: 23.9363\n",
      "Epoch 449/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7920 - val_loss: 24.0715\n",
      "Epoch 450/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6945 - val_loss: 23.9718\n",
      "Epoch 451/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9036 - val_loss: 24.1345\n",
      "Epoch 452/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8957 - val_loss: 23.9705\n",
      "Epoch 453/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7726 - val_loss: 24.0605\n",
      "Epoch 454/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8700 - val_loss: 24.1815\n",
      "Epoch 455/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.8939 - val_loss: 23.7536\n",
      "Epoch 456/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7624 - val_loss: 23.9315\n",
      "Epoch 457/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.7382 - val_loss: 24.2195\n",
      "Epoch 458/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8036 - val_loss: 23.8433\n",
      "Epoch 459/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7454 - val_loss: 23.9626\n",
      "Epoch 460/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6907 - val_loss: 24.0942\n",
      "Epoch 461/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.8142 - val_loss: 24.0951\n",
      "Epoch 462/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8585 - val_loss: 23.9745\n",
      "Epoch 463/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7876 - val_loss: 23.8452\n",
      "Epoch 464/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7733 - val_loss: 24.1572\n",
      "Epoch 465/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.8042 - val_loss: 23.9485\n",
      "Epoch 466/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7621 - val_loss: 24.1359\n",
      "Epoch 467/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7951 - val_loss: 23.7694\n",
      "Epoch 468/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7696 - val_loss: 24.1557\n",
      "Epoch 469/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7594 - val_loss: 23.8854\n",
      "Epoch 470/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6988 - val_loss: 24.0564\n",
      "Epoch 471/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.9338 - val_loss: 23.9921\n",
      "Epoch 472/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7947 - val_loss: 23.9164\n",
      "Epoch 473/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8275 - val_loss: 23.7984\n",
      "Epoch 474/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8346 - val_loss: 24.1665\n",
      "Epoch 475/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7402 - val_loss: 24.1587\n",
      "Epoch 476/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8057 - val_loss: 24.0589\n",
      "Epoch 477/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7480 - val_loss: 23.9036\n",
      "Epoch 478/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7062 - val_loss: 23.9212\n",
      "Epoch 479/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6844 - val_loss: 24.0337\n",
      "Epoch 480/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7486 - val_loss: 23.9300\n",
      "Epoch 481/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6784 - val_loss: 24.0282\n",
      "Epoch 482/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8584 - val_loss: 23.8655\n",
      "Epoch 483/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7370 - val_loss: 24.0549\n",
      "Epoch 484/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8217 - val_loss: 23.9652\n",
      "Epoch 485/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6767 - val_loss: 23.9710\n",
      "Epoch 486/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7778 - val_loss: 24.1340\n",
      "Epoch 487/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7061 - val_loss: 23.8641\n",
      "Epoch 488/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8976 - val_loss: 23.9823\n",
      "Epoch 489/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7336 - val_loss: 23.8966\n",
      "Epoch 490/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7619 - val_loss: 24.0949\n",
      "Epoch 491/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7693 - val_loss: 23.9729\n",
      "Epoch 492/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7384 - val_loss: 24.2216\n",
      "Epoch 493/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7902 - val_loss: 23.6918\n",
      "Epoch 494/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7166 - val_loss: 23.9908\n",
      "Epoch 495/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.8044 - val_loss: 23.9978\n",
      "Epoch 496/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.8118 - val_loss: 23.9806\n",
      "Epoch 497/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.6625 - val_loss: 24.2289\n",
      "Epoch 498/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.6920 - val_loss: 23.9310\n",
      "Epoch 499/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.5767 - val_loss: 24.0493\n",
      "Epoch 500/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.7021 - val_loss: 23.9115\n",
      "Epoch 501/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.7365 - val_loss: 23.6287\n",
      "Epoch 502/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6636 - val_loss: 23.9703\n",
      "Epoch 503/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.7294 - val_loss: 23.7246\n",
      "Epoch 504/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.6239 - val_loss: 24.0382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.7884 - val_loss: 23.9514\n",
      "Epoch 506/1000\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 22.7492 - val_loss: 23.6697\n",
      "Epoch 507/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.7807 - val_loss: 24.0131\n",
      "Epoch 508/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6534 - val_loss: 24.0088\n",
      "Epoch 509/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8557 - val_loss: 24.0642\n",
      "Epoch 510/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7736 - val_loss: 24.0809\n",
      "Epoch 511/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7998 - val_loss: 23.8342\n",
      "Epoch 512/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7879 - val_loss: 24.1537\n",
      "Epoch 513/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7836 - val_loss: 24.0890\n",
      "Epoch 514/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7787 - val_loss: 23.9526\n",
      "Epoch 515/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7456 - val_loss: 24.0027\n",
      "Epoch 516/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6771 - val_loss: 24.0076\n",
      "Epoch 517/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7157 - val_loss: 24.0074\n",
      "Epoch 518/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6692 - val_loss: 24.0662\n",
      "Epoch 519/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6947 - val_loss: 23.8526\n",
      "Epoch 520/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6591 - val_loss: 24.1748\n",
      "Epoch 521/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7455 - val_loss: 24.0901\n",
      "Epoch 522/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6869 - val_loss: 23.9792\n",
      "Epoch 523/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6611 - val_loss: 24.2720\n",
      "Epoch 524/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7219 - val_loss: 23.8541\n",
      "Epoch 525/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6876 - val_loss: 24.1534\n",
      "Epoch 526/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7404 - val_loss: 24.1431\n",
      "Epoch 527/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6637 - val_loss: 24.0876\n",
      "Epoch 528/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7323 - val_loss: 24.1995\n",
      "Epoch 529/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7466 - val_loss: 24.0125\n",
      "Epoch 530/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6919 - val_loss: 24.1415\n",
      "Epoch 531/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6785 - val_loss: 24.1293\n",
      "Epoch 532/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7665 - val_loss: 24.1326\n",
      "Epoch 533/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7412 - val_loss: 24.0790\n",
      "Epoch 534/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7068 - val_loss: 24.0749\n",
      "Epoch 535/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7470 - val_loss: 23.8910\n",
      "Epoch 536/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6487 - val_loss: 24.0037\n",
      "Epoch 537/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7258 - val_loss: 24.3278\n",
      "Epoch 538/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8172 - val_loss: 23.8366\n",
      "Epoch 539/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7512 - val_loss: 24.1001\n",
      "Epoch 540/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6193 - val_loss: 24.2214\n",
      "Epoch 541/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7469 - val_loss: 24.0965\n",
      "Epoch 542/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7512 - val_loss: 23.9981\n",
      "Epoch 543/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.6408 - val_loss: 24.2492\n",
      "Epoch 544/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6924 - val_loss: 23.9729\n",
      "Epoch 545/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6742 - val_loss: 23.8733\n",
      "Epoch 546/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.7034 - val_loss: 23.8332\n",
      "Epoch 547/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.5490 - val_loss: 23.9877\n",
      "Epoch 548/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6470 - val_loss: 24.3126\n",
      "Epoch 549/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6677 - val_loss: 24.1861\n",
      "Epoch 550/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6603 - val_loss: 23.7544\n",
      "Epoch 551/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.8063 - val_loss: 24.0876\n",
      "Epoch 552/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7185 - val_loss: 24.0428\n",
      "Epoch 553/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5952 - val_loss: 23.8704\n",
      "Epoch 554/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6458 - val_loss: 24.0678\n",
      "Epoch 555/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6657 - val_loss: 23.9751\n",
      "Epoch 556/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.6299 - val_loss: 23.9765\n",
      "Epoch 557/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.7039 - val_loss: 24.0117\n",
      "Epoch 558/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6120 - val_loss: 24.0605\n",
      "Epoch 559/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7308 - val_loss: 24.0752\n",
      "Epoch 560/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.7101 - val_loss: 24.1739\n",
      "Epoch 561/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7533 - val_loss: 23.9571\n",
      "Epoch 562/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6673 - val_loss: 23.8641\n",
      "Epoch 563/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6588 - val_loss: 23.8914\n",
      "Epoch 564/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.7172 - val_loss: 23.8692\n",
      "Epoch 565/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6570 - val_loss: 24.2001\n",
      "Epoch 566/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7080 - val_loss: 24.1431\n",
      "Epoch 567/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6491 - val_loss: 24.0760\n",
      "Epoch 568/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7087 - val_loss: 23.8955\n",
      "Epoch 569/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6539 - val_loss: 24.0500\n",
      "Epoch 570/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6690 - val_loss: 23.9532\n",
      "Epoch 571/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6431 - val_loss: 24.2644\n",
      "Epoch 572/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7427 - val_loss: 24.0666\n",
      "Epoch 573/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6914 - val_loss: 24.0266\n",
      "Epoch 574/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6865 - val_loss: 24.0406\n",
      "Epoch 575/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6974 - val_loss: 24.0568\n",
      "Epoch 576/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6271 - val_loss: 23.8662\n",
      "Epoch 577/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6024 - val_loss: 23.8033\n",
      "Epoch 578/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6703 - val_loss: 24.1839\n",
      "Epoch 579/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6391 - val_loss: 24.0885\n",
      "Epoch 580/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6968 - val_loss: 23.9330\n",
      "Epoch 581/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7358 - val_loss: 24.0508\n",
      "Epoch 582/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6726 - val_loss: 24.0019\n",
      "Epoch 583/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6310 - val_loss: 24.1793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6768 - val_loss: 24.1745\n",
      "Epoch 585/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6132 - val_loss: 24.0557\n",
      "Epoch 586/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.6290 - val_loss: 24.0420\n",
      "Epoch 587/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7444 - val_loss: 23.9183\n",
      "Epoch 588/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6105 - val_loss: 23.8702\n",
      "Epoch 589/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5661 - val_loss: 24.0982\n",
      "Epoch 590/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5795 - val_loss: 24.0533\n",
      "Epoch 591/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6309 - val_loss: 24.0906\n",
      "Epoch 592/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6220 - val_loss: 24.0415\n",
      "Epoch 593/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5751 - val_loss: 23.8801\n",
      "Epoch 594/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6341 - val_loss: 24.0542\n",
      "Epoch 595/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6978 - val_loss: 23.9923\n",
      "Epoch 596/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6327 - val_loss: 24.0324\n",
      "Epoch 597/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6374 - val_loss: 24.1796\n",
      "Epoch 598/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.7091 - val_loss: 24.0304\n",
      "Epoch 599/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6581 - val_loss: 24.1227\n",
      "Epoch 600/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6371 - val_loss: 24.1997\n",
      "Epoch 601/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4801 - val_loss: 23.8669\n",
      "Epoch 602/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5679 - val_loss: 23.9332\n",
      "Epoch 603/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6302 - val_loss: 24.0992\n",
      "Epoch 604/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6860 - val_loss: 23.8250\n",
      "Epoch 605/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5825 - val_loss: 24.0998\n",
      "Epoch 606/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6856 - val_loss: 23.9826\n",
      "Epoch 607/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5378 - val_loss: 23.8806\n",
      "Epoch 608/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5178 - val_loss: 24.3355\n",
      "Epoch 609/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6787 - val_loss: 23.9960\n",
      "Epoch 610/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7461 - val_loss: 23.9551\n",
      "Epoch 611/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6777 - val_loss: 23.9844\n",
      "Epoch 612/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5921 - val_loss: 23.8905\n",
      "Epoch 613/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5945 - val_loss: 24.0614\n",
      "Epoch 614/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6541 - val_loss: 24.0268\n",
      "Epoch 615/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6002 - val_loss: 23.9716\n",
      "Epoch 616/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5218 - val_loss: 24.2030\n",
      "Epoch 617/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6079 - val_loss: 23.8629\n",
      "Epoch 618/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5236 - val_loss: 23.9045\n",
      "Epoch 619/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5764 - val_loss: 24.1852\n",
      "Epoch 620/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5830 - val_loss: 23.7289\n",
      "Epoch 621/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6210 - val_loss: 24.2168\n",
      "Epoch 622/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5133 - val_loss: 23.8538\n",
      "Epoch 623/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5884 - val_loss: 24.0936\n",
      "Epoch 624/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6667 - val_loss: 23.9198\n",
      "Epoch 625/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.7235 - val_loss: 24.2314\n",
      "Epoch 626/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5663 - val_loss: 23.9318\n",
      "Epoch 627/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5930 - val_loss: 24.1971\n",
      "Epoch 628/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6218 - val_loss: 24.1609\n",
      "Epoch 629/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5849 - val_loss: 23.8199\n",
      "Epoch 630/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5427 - val_loss: 24.0416\n",
      "Epoch 631/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5776 - val_loss: 24.2381\n",
      "Epoch 632/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5791 - val_loss: 24.0859\n",
      "Epoch 633/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5989 - val_loss: 23.9047\n",
      "Epoch 634/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6105 - val_loss: 23.8524\n",
      "Epoch 635/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6111 - val_loss: 24.3010\n",
      "Epoch 636/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5886 - val_loss: 24.1039\n",
      "Epoch 637/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6272 - val_loss: 23.8915\n",
      "Epoch 638/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5321 - val_loss: 24.0697\n",
      "Epoch 639/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.6052 - val_loss: 23.8968\n",
      "Epoch 640/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.5695 - val_loss: 24.3091\n",
      "Epoch 641/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.5125 - val_loss: 24.0045\n",
      "Epoch 642/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.5860 - val_loss: 23.9996\n",
      "Epoch 643/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.5551 - val_loss: 24.0689\n",
      "Epoch 644/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4996 - val_loss: 24.2879\n",
      "Epoch 645/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6369 - val_loss: 24.1657\n",
      "Epoch 646/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5403 - val_loss: 24.1817\n",
      "Epoch 647/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5526 - val_loss: 23.9485\n",
      "Epoch 648/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5481 - val_loss: 24.1222\n",
      "Epoch 649/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5929 - val_loss: 24.0703\n",
      "Epoch 650/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5680 - val_loss: 24.1484\n",
      "Epoch 651/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5996 - val_loss: 23.9671\n",
      "Epoch 652/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5656 - val_loss: 24.3128\n",
      "Epoch 653/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5671 - val_loss: 24.1655\n",
      "Epoch 654/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5621 - val_loss: 24.0937\n",
      "Epoch 655/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5541 - val_loss: 23.8800\n",
      "Epoch 656/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5391 - val_loss: 23.9538\n",
      "Epoch 657/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6649 - val_loss: 24.1724\n",
      "Epoch 658/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6073 - val_loss: 23.9868\n",
      "Epoch 659/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5285 - val_loss: 24.0857\n",
      "Epoch 660/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6019 - val_loss: 24.3094\n",
      "Epoch 661/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5437 - val_loss: 24.0689\n",
      "Epoch 662/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5764 - val_loss: 24.0426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5324 - val_loss: 24.2032\n",
      "Epoch 664/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4790 - val_loss: 24.0049\n",
      "Epoch 665/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6073 - val_loss: 24.3253\n",
      "Epoch 666/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5296 - val_loss: 23.9411\n",
      "Epoch 667/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5232 - val_loss: 23.9452\n",
      "Epoch 668/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5372 - val_loss: 24.0515\n",
      "Epoch 669/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5725 - val_loss: 24.1424\n",
      "Epoch 670/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6112 - val_loss: 24.1303\n",
      "Epoch 671/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5964 - val_loss: 24.3413\n",
      "Epoch 672/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4924 - val_loss: 24.3818\n",
      "Epoch 673/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5282 - val_loss: 24.3010\n",
      "Epoch 674/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4432 - val_loss: 23.8490\n",
      "Epoch 675/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4859 - val_loss: 24.2818\n",
      "Epoch 676/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5018 - val_loss: 24.1392\n",
      "Epoch 677/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5703 - val_loss: 24.1642\n",
      "Epoch 678/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6522 - val_loss: 24.1687\n",
      "Epoch 679/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5140 - val_loss: 24.1707\n",
      "Epoch 680/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5303 - val_loss: 24.0970\n",
      "Epoch 681/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4938 - val_loss: 24.3126\n",
      "Epoch 682/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5300 - val_loss: 24.1003\n",
      "Epoch 683/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5824 - val_loss: 24.0600\n",
      "Epoch 684/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4737 - val_loss: 24.0553\n",
      "Epoch 685/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5392 - val_loss: 24.2064\n",
      "Epoch 686/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6032 - val_loss: 23.9726\n",
      "Epoch 687/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4760 - val_loss: 24.0777\n",
      "Epoch 688/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5429 - val_loss: 23.9057\n",
      "Epoch 689/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4878 - val_loss: 23.9878\n",
      "Epoch 690/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.5706 - val_loss: 24.1138\n",
      "Epoch 691/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4020 - val_loss: 24.0636\n",
      "Epoch 692/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4603 - val_loss: 24.1155\n",
      "Epoch 693/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5623 - val_loss: 24.1684\n",
      "Epoch 694/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5143 - val_loss: 24.1785\n",
      "Epoch 695/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4596 - val_loss: 24.1475\n",
      "Epoch 696/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4794 - val_loss: 24.1019\n",
      "Epoch 697/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5971 - val_loss: 24.2891\n",
      "Epoch 698/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5690 - val_loss: 24.0412\n",
      "Epoch 699/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5634 - val_loss: 24.2613\n",
      "Epoch 700/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5122 - val_loss: 24.3588\n",
      "Epoch 701/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5014 - val_loss: 23.9447\n",
      "Epoch 702/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5860 - val_loss: 24.2422\n",
      "Epoch 703/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5629 - val_loss: 24.0306\n",
      "Epoch 704/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4546 - val_loss: 24.4261\n",
      "Epoch 705/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4827 - val_loss: 24.0479\n",
      "Epoch 706/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4588 - val_loss: 23.9242\n",
      "Epoch 707/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5702 - val_loss: 24.3253\n",
      "Epoch 708/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6091 - val_loss: 24.2299\n",
      "Epoch 709/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5363 - val_loss: 24.0677\n",
      "Epoch 710/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4029 - val_loss: 24.1400\n",
      "Epoch 711/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5802 - val_loss: 24.1624\n",
      "Epoch 712/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6085 - val_loss: 23.9727\n",
      "Epoch 713/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4488 - val_loss: 24.0510\n",
      "Epoch 714/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5727 - val_loss: 24.2718\n",
      "Epoch 715/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5114 - val_loss: 24.0239\n",
      "Epoch 716/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.6423 - val_loss: 24.1257\n",
      "Epoch 717/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4589 - val_loss: 24.1942\n",
      "Epoch 718/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4763 - val_loss: 24.0323\n",
      "Epoch 719/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5396 - val_loss: 24.1342\n",
      "Epoch 720/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5347 - val_loss: 24.0177\n",
      "Epoch 721/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4482 - val_loss: 24.0860\n",
      "Epoch 722/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3798 - val_loss: 23.9738\n",
      "Epoch 723/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5131 - val_loss: 24.3328\n",
      "Epoch 724/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2826 - val_loss: 24.2049\n",
      "Epoch 725/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3949 - val_loss: 24.0455\n",
      "Epoch 726/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3671 - val_loss: 24.1755\n",
      "Epoch 727/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.4920 - val_loss: 24.4268\n",
      "Epoch 728/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.5514 - val_loss: 24.1181\n",
      "Epoch 729/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.4615 - val_loss: 24.4281\n",
      "Epoch 730/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.5425 - val_loss: 24.0005\n",
      "Epoch 731/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.5815 - val_loss: 24.1246\n",
      "Epoch 732/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4414 - val_loss: 24.1056\n",
      "Epoch 733/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4469 - val_loss: 24.1903\n",
      "Epoch 734/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.5246 - val_loss: 24.1385\n",
      "Epoch 735/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.5641 - val_loss: 24.0444\n",
      "Epoch 736/1000\n",
      "56/56 [==============================] - 1s 11ms/step - loss: 22.4373 - val_loss: 24.2712\n",
      "Epoch 737/1000\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 22.4564 - val_loss: 23.8845\n",
      "Epoch 738/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 22.5035 - val_loss: 24.2315\n",
      "Epoch 739/1000\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 22.4816 - val_loss: 23.9852\n",
      "Epoch 740/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.5326 - val_loss: 24.0499\n",
      "Epoch 741/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 7ms/step - loss: 22.4244 - val_loss: 24.3323\n",
      "Epoch 742/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3346 - val_loss: 24.1804\n",
      "Epoch 743/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.4827 - val_loss: 24.0770\n",
      "Epoch 744/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.4458 - val_loss: 24.3413\n",
      "Epoch 745/1000\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 22.4642 - val_loss: 24.0164\n",
      "Epoch 746/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3826 - val_loss: 23.9579\n",
      "Epoch 747/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4282 - val_loss: 24.5393\n",
      "Epoch 748/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.6654 - val_loss: 24.0189\n",
      "Epoch 749/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4299 - val_loss: 24.0849\n",
      "Epoch 750/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4106 - val_loss: 24.1430\n",
      "Epoch 751/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.4200 - val_loss: 24.1674\n",
      "Epoch 752/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5149 - val_loss: 23.9565\n",
      "Epoch 753/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5255 - val_loss: 24.0940\n",
      "Epoch 754/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4242 - val_loss: 24.2933\n",
      "Epoch 755/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2918 - val_loss: 23.9328\n",
      "Epoch 756/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4145 - val_loss: 24.3420\n",
      "Epoch 757/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4943 - val_loss: 24.0043\n",
      "Epoch 758/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3550 - val_loss: 24.0234\n",
      "Epoch 759/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3868 - val_loss: 23.8386\n",
      "Epoch 760/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4148 - val_loss: 24.2040\n",
      "Epoch 761/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4539 - val_loss: 24.1406\n",
      "Epoch 762/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4763 - val_loss: 24.2550\n",
      "Epoch 763/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4499 - val_loss: 24.1799\n",
      "Epoch 764/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4947 - val_loss: 23.9657\n",
      "Epoch 765/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3867 - val_loss: 24.0839\n",
      "Epoch 766/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3712 - val_loss: 23.8835\n",
      "Epoch 767/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3256 - val_loss: 24.0676\n",
      "Epoch 768/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4112 - val_loss: 24.1733\n",
      "Epoch 769/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5227 - val_loss: 24.1176\n",
      "Epoch 770/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5041 - val_loss: 24.1910\n",
      "Epoch 771/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4186 - val_loss: 24.0535\n",
      "Epoch 772/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3536 - val_loss: 23.9088\n",
      "Epoch 773/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.5077 - val_loss: 23.9990\n",
      "Epoch 774/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3763 - val_loss: 24.0135\n",
      "Epoch 775/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5219 - val_loss: 24.0013\n",
      "Epoch 776/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5322 - val_loss: 24.1952\n",
      "Epoch 777/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3271 - val_loss: 23.9387\n",
      "Epoch 778/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3712 - val_loss: 23.8949\n",
      "Epoch 779/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4959 - val_loss: 24.2246\n",
      "Epoch 780/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3773 - val_loss: 24.1593\n",
      "Epoch 781/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5058 - val_loss: 24.0862\n",
      "Epoch 782/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4925 - val_loss: 24.2834\n",
      "Epoch 783/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3620 - val_loss: 23.9509\n",
      "Epoch 784/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4233 - val_loss: 24.1916\n",
      "Epoch 785/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5382 - val_loss: 24.3431\n",
      "Epoch 786/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4842 - val_loss: 24.2142\n",
      "Epoch 787/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4318 - val_loss: 24.0520\n",
      "Epoch 788/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4484 - val_loss: 24.2089\n",
      "Epoch 789/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4041 - val_loss: 24.1888\n",
      "Epoch 790/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4167 - val_loss: 24.1042\n",
      "Epoch 791/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3834 - val_loss: 23.9235\n",
      "Epoch 792/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4895 - val_loss: 24.1687\n",
      "Epoch 793/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4456 - val_loss: 24.0362\n",
      "Epoch 794/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3533 - val_loss: 23.9802\n",
      "Epoch 795/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3747 - val_loss: 24.1136\n",
      "Epoch 796/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2786 - val_loss: 23.9239\n",
      "Epoch 797/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3815 - val_loss: 24.1113\n",
      "Epoch 798/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4637 - val_loss: 24.0942\n",
      "Epoch 799/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4318 - val_loss: 23.9846\n",
      "Epoch 800/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4574 - val_loss: 24.0510\n",
      "Epoch 801/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4494 - val_loss: 24.1006\n",
      "Epoch 802/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4768 - val_loss: 24.0551\n",
      "Epoch 803/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3562 - val_loss: 24.1173\n",
      "Epoch 804/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3135 - val_loss: 23.8834\n",
      "Epoch 805/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3947 - val_loss: 24.0057\n",
      "Epoch 806/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4044 - val_loss: 23.9024\n",
      "Epoch 807/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4040 - val_loss: 23.9378\n",
      "Epoch 808/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3304 - val_loss: 24.2038\n",
      "Epoch 809/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4378 - val_loss: 24.1253\n",
      "Epoch 810/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4676 - val_loss: 24.0888\n",
      "Epoch 811/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4068 - val_loss: 24.1691\n",
      "Epoch 812/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4884 - val_loss: 24.3646\n",
      "Epoch 813/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3187 - val_loss: 24.3026\n",
      "Epoch 814/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5634 - val_loss: 24.4466\n",
      "Epoch 815/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3961 - val_loss: 24.0619\n",
      "Epoch 816/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4026 - val_loss: 24.1590\n",
      "Epoch 817/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4416 - val_loss: 24.1188\n",
      "Epoch 818/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3580 - val_loss: 24.0325\n",
      "Epoch 819/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3141 - val_loss: 24.1323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3702 - val_loss: 24.3554\n",
      "Epoch 821/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2960 - val_loss: 24.0911\n",
      "Epoch 822/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3785 - val_loss: 24.2181\n",
      "Epoch 823/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3762 - val_loss: 24.0938\n",
      "Epoch 824/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3665 - val_loss: 24.2354\n",
      "Epoch 825/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3769 - val_loss: 24.2391\n",
      "Epoch 826/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4339 - val_loss: 24.2487\n",
      "Epoch 827/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3037 - val_loss: 23.9516\n",
      "Epoch 828/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.4602 - val_loss: 24.1019\n",
      "Epoch 829/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.3534 - val_loss: 24.1981\n",
      "Epoch 830/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3133 - val_loss: 24.2116\n",
      "Epoch 831/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5157 - val_loss: 24.0275\n",
      "Epoch 832/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3045 - val_loss: 23.8206\n",
      "Epoch 833/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2984 - val_loss: 24.2561\n",
      "Epoch 834/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5290 - val_loss: 24.5283\n",
      "Epoch 835/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3489 - val_loss: 24.2371\n",
      "Epoch 836/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5192 - val_loss: 24.2371\n",
      "Epoch 837/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4504 - val_loss: 23.9896\n",
      "Epoch 838/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3015 - val_loss: 24.1796\n",
      "Epoch 839/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3498 - val_loss: 24.2082\n",
      "Epoch 840/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3879 - val_loss: 24.1404\n",
      "Epoch 841/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4866 - val_loss: 23.8919\n",
      "Epoch 842/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4348 - val_loss: 24.0619\n",
      "Epoch 843/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3700 - val_loss: 24.2986\n",
      "Epoch 844/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5855 - val_loss: 24.1944\n",
      "Epoch 845/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3756 - val_loss: 23.9197\n",
      "Epoch 846/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3535 - val_loss: 23.9632\n",
      "Epoch 847/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3347 - val_loss: 23.9845\n",
      "Epoch 848/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2854 - val_loss: 23.9483\n",
      "Epoch 849/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4422 - val_loss: 24.2523\n",
      "Epoch 850/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3671 - val_loss: 24.4598\n",
      "Epoch 851/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2778 - val_loss: 23.8856\n",
      "Epoch 852/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4276 - val_loss: 24.3993\n",
      "Epoch 853/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3851 - val_loss: 24.5284\n",
      "Epoch 854/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4142 - val_loss: 24.0279\n",
      "Epoch 855/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3212 - val_loss: 24.0460\n",
      "Epoch 856/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3440 - val_loss: 24.1702\n",
      "Epoch 857/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3934 - val_loss: 24.3308\n",
      "Epoch 858/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3632 - val_loss: 24.2301\n",
      "Epoch 859/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2823 - val_loss: 24.1850\n",
      "Epoch 860/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3616 - val_loss: 23.9396\n",
      "Epoch 861/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2152 - val_loss: 24.3230\n",
      "Epoch 862/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2369 - val_loss: 24.1133\n",
      "Epoch 863/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2995 - val_loss: 24.1329\n",
      "Epoch 864/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4655 - val_loss: 24.2306\n",
      "Epoch 865/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3923 - val_loss: 24.1770\n",
      "Epoch 866/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3891 - val_loss: 24.1363\n",
      "Epoch 867/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4513 - val_loss: 24.0335\n",
      "Epoch 868/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3277 - val_loss: 24.1515\n",
      "Epoch 869/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3175 - val_loss: 23.9939\n",
      "Epoch 870/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2633 - val_loss: 24.0116\n",
      "Epoch 871/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4624 - val_loss: 24.2799\n",
      "Epoch 872/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2876 - val_loss: 24.2108\n",
      "Epoch 873/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4540 - val_loss: 24.5810\n",
      "Epoch 874/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3049 - val_loss: 24.0998\n",
      "Epoch 875/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4223 - val_loss: 24.4074\n",
      "Epoch 876/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3476 - val_loss: 24.1996\n",
      "Epoch 877/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3842 - val_loss: 24.1482\n",
      "Epoch 878/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4585 - val_loss: 23.9776\n",
      "Epoch 879/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2804 - val_loss: 24.2935\n",
      "Epoch 880/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3183 - val_loss: 24.0376\n",
      "Epoch 881/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3515 - val_loss: 24.2485\n",
      "Epoch 882/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4236 - val_loss: 23.9531\n",
      "Epoch 883/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3161 - val_loss: 24.1508\n",
      "Epoch 884/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3236 - val_loss: 24.0642\n",
      "Epoch 885/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2599 - val_loss: 24.1785\n",
      "Epoch 886/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4257 - val_loss: 23.7872\n",
      "Epoch 887/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4087 - val_loss: 24.2539\n",
      "Epoch 888/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3453 - val_loss: 24.3929\n",
      "Epoch 889/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2933 - val_loss: 24.3021\n",
      "Epoch 890/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3525 - val_loss: 24.1352\n",
      "Epoch 891/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2986 - val_loss: 24.2804\n",
      "Epoch 892/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3954 - val_loss: 24.1135\n",
      "Epoch 893/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.5081 - val_loss: 24.2074\n",
      "Epoch 894/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2618 - val_loss: 24.1587\n",
      "Epoch 895/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3293 - val_loss: 23.9587\n",
      "Epoch 896/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3430 - val_loss: 24.2881\n",
      "Epoch 897/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4073 - val_loss: 24.0206\n",
      "Epoch 898/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3624 - val_loss: 24.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3404 - val_loss: 24.3729\n",
      "Epoch 900/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3251 - val_loss: 24.1274\n",
      "Epoch 901/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4366 - val_loss: 24.3127\n",
      "Epoch 902/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2748 - val_loss: 24.3062\n",
      "Epoch 903/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3428 - val_loss: 24.1221\n",
      "Epoch 904/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2690 - val_loss: 24.2309\n",
      "Epoch 905/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3271 - val_loss: 23.9697\n",
      "Epoch 906/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4222 - val_loss: 24.2449\n",
      "Epoch 907/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3056 - val_loss: 24.2196\n",
      "Epoch 908/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3958 - val_loss: 24.3531\n",
      "Epoch 909/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2903 - val_loss: 24.1898\n",
      "Epoch 910/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4610 - val_loss: 24.3885\n",
      "Epoch 911/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4283 - val_loss: 24.4409\n",
      "Epoch 912/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3627 - val_loss: 24.3584\n",
      "Epoch 913/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3908 - val_loss: 24.3975\n",
      "Epoch 914/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4447 - val_loss: 24.0637\n",
      "Epoch 915/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3795 - val_loss: 24.4449\n",
      "Epoch 916/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3502 - val_loss: 24.1733\n",
      "Epoch 917/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.2951 - val_loss: 24.3319\n",
      "Epoch 918/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3463 - val_loss: 24.2217\n",
      "Epoch 919/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2973 - val_loss: 24.4265\n",
      "Epoch 920/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3792 - val_loss: 24.3709\n",
      "Epoch 921/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3746 - val_loss: 24.1518\n",
      "Epoch 922/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.2320 - val_loss: 24.4337\n",
      "Epoch 923/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2643 - val_loss: 24.2770\n",
      "Epoch 924/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3239 - val_loss: 24.2709\n",
      "Epoch 925/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4075 - val_loss: 24.0909\n",
      "Epoch 926/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3469 - val_loss: 23.9936\n",
      "Epoch 927/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4755 - val_loss: 24.1531\n",
      "Epoch 928/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3344 - val_loss: 24.4756\n",
      "Epoch 929/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3519 - val_loss: 24.0689\n",
      "Epoch 930/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2668 - val_loss: 24.0590\n",
      "Epoch 931/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3476 - val_loss: 24.3752\n",
      "Epoch 932/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4225 - val_loss: 23.9227\n",
      "Epoch 933/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4581 - val_loss: 24.1504\n",
      "Epoch 934/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2481 - val_loss: 24.1213\n",
      "Epoch 935/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3131 - val_loss: 24.2050\n",
      "Epoch 936/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2073 - val_loss: 24.1387\n",
      "Epoch 937/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3545 - val_loss: 24.2394\n",
      "Epoch 938/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3390 - val_loss: 24.3262\n",
      "Epoch 939/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3636 - val_loss: 24.3125\n",
      "Epoch 940/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.4056 - val_loss: 24.1709\n",
      "Epoch 941/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.3185 - val_loss: 24.3286\n",
      "Epoch 942/1000\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 22.3399 - val_loss: 24.2357\n",
      "Epoch 943/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 22.3264 - val_loss: 24.0719\n",
      "Epoch 944/1000\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 22.2389 - val_loss: 24.0753\n",
      "Epoch 945/1000\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 22.2897 - val_loss: 24.2563\n",
      "Epoch 946/1000\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 22.2898 - val_loss: 24.3603\n",
      "Epoch 947/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3279 - val_loss: 24.2731\n",
      "Epoch 948/1000\n",
      "56/56 [==============================] - 1s 14ms/step - loss: 22.3407 - val_loss: 24.2442\n",
      "Epoch 949/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 22.3060 - val_loss: 24.3461\n",
      "Epoch 950/1000\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 22.3582 - val_loss: 24.2023\n",
      "Epoch 951/1000\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 22.2474 - val_loss: 24.3562\n",
      "Epoch 952/1000\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 22.3671 - val_loss: 24.2626\n",
      "Epoch 953/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3756 - val_loss: 24.3364\n",
      "Epoch 954/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.2944 - val_loss: 23.9858\n",
      "Epoch 955/1000\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 22.3806 - val_loss: 24.1952\n",
      "Epoch 956/1000\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 22.4259 - val_loss: 24.0338\n",
      "Epoch 957/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.2248 - val_loss: 24.0216\n",
      "Epoch 958/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3312 - val_loss: 24.3746\n",
      "Epoch 959/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2814 - val_loss: 24.1116\n",
      "Epoch 960/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2551 - val_loss: 24.3232\n",
      "Epoch 961/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2908 - val_loss: 24.1237\n",
      "Epoch 962/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3341 - val_loss: 24.1082\n",
      "Epoch 963/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2485 - val_loss: 24.2386\n",
      "Epoch 964/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3528 - val_loss: 24.1537\n",
      "Epoch 965/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.1871 - val_loss: 24.0284\n",
      "Epoch 966/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3264 - val_loss: 24.2096\n",
      "Epoch 967/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.2564 - val_loss: 24.2381\n",
      "Epoch 968/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.3327 - val_loss: 24.0683\n",
      "Epoch 969/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.2982 - val_loss: 24.3173\n",
      "Epoch 970/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3402 - val_loss: 24.0012\n",
      "Epoch 971/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3462 - val_loss: 24.0591\n",
      "Epoch 972/1000\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 22.3547 - val_loss: 24.4170\n",
      "Epoch 973/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2529 - val_loss: 23.9762\n",
      "Epoch 974/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2046 - val_loss: 24.1461\n",
      "Epoch 975/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3028 - val_loss: 24.1428\n",
      "Epoch 976/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2964 - val_loss: 23.8839\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3079 - val_loss: 24.4934\n",
      "Epoch 978/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2601 - val_loss: 24.2704\n",
      "Epoch 979/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2612 - val_loss: 24.1815\n",
      "Epoch 980/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3452 - val_loss: 24.3528\n",
      "Epoch 981/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.4190 - val_loss: 24.3452\n",
      "Epoch 982/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2996 - val_loss: 24.4690\n",
      "Epoch 983/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4392 - val_loss: 24.5998\n",
      "Epoch 984/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3246 - val_loss: 24.0831\n",
      "Epoch 985/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.3126 - val_loss: 24.0797\n",
      "Epoch 986/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.1804 - val_loss: 24.0972\n",
      "Epoch 987/1000\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 22.2355 - val_loss: 24.1359\n",
      "Epoch 988/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2637 - val_loss: 24.2040\n",
      "Epoch 989/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2907 - val_loss: 24.4937\n",
      "Epoch 990/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.4208 - val_loss: 24.4732\n",
      "Epoch 991/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.1473 - val_loss: 24.3744\n",
      "Epoch 992/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2789 - val_loss: 24.1357\n",
      "Epoch 993/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2510 - val_loss: 24.1818\n",
      "Epoch 994/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3227 - val_loss: 24.1869\n",
      "Epoch 995/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.3046 - val_loss: 24.1973\n",
      "Epoch 996/1000\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 22.2018 - val_loss: 24.2960\n",
      "Epoch 997/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2329 - val_loss: 24.2828\n",
      "Epoch 998/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2906 - val_loss: 24.1497\n",
      "Epoch 999/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.2122 - val_loss: 24.5919\n",
      "Epoch 1000/1000\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 22.3118 - val_loss: 24.3487\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    loss = 'mse'\n",
    "    models = (encoder, decoder)\n",
    "    \n",
    "    if loss == 'bce':\n",
    "        reconstruction_loss = binary_crossentropy(inputs,\n",
    "                                                  outputs)\n",
    "    else:\n",
    "        reconstruction_loss = mse(inputs, outputs)\n",
    "        \n",
    "    reconstruction_loss *= start_dimension\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    vae.summary()\n",
    "    vae.fit(X_trainvae,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_valvae, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "88912bd0-ba12-43e5-8318-ebbfa4153787",
    "_uuid": "d4ae1a8a-0465-49fd-84bf-225dfb80bc79",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def latent_space_data(vae, data, labels):\n",
    "    encoder, decoder = vae\n",
    "    z_mean, _, _ = encoder.predict(data)\n",
    "    return z_mean\n",
    "latent_space_train = latent_space_data(models, TrainDatascaled, y_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3270f75-99b9-4225-9a03-8239dfaabe11",
    "_uuid": "8b8f70b7-ca77-412a-be32-aaf263a3afd2"
   },
   "source": [
    "### Train test split for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "902998dc-4b4f-481f-9774-846638544bb9",
    "_uuid": "022c3696-66d6-43d6-bffb-05d837d58775",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_mlp = latent_space_train\n",
    "y_mlp = y_trn\n",
    "X_trainmlp, X_valmlp, y_trmlp, y_valmlp = train_test_split(X_mlp,y_mlp, \n",
    "                                                    test_size=0.3, random_state=1, stratify = y_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "010339c6-cb7f-465e-9177-ccad2b5f9837",
    "_uuid": "31d75f2f-2642-4c6b-a141-39ae1f2c7ddc"
   },
   "source": [
    "### MSPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "60c93f16-4f4b-4dd7-8eb9-f95c43dad1db",
    "_uuid": "5381aa7f-d714-4ef3-bd41-f5089b1edbf7",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "    #def SPOfn(latent_space_im,mino,majo,y_d):\n",
    "       \n",
    "    latent_space_im = X_trainmlp\n",
    "    mino = 1\n",
    "    majo = -1\n",
    "    y_d = y_trmlp\n",
    "    \n",
    "    nTarget = np.sum(y_d == majo)\n",
    "\n",
    "\n",
    "    posy = y_d == mino\n",
    "    negy = y_d != mino\n",
    "    P = latent_space_im[np.where(posy == True)[0],:]\n",
    "    N = latent_space_im[np.where(negy == True)[0],:]\n",
    "\n",
    "    #print(len(P),len(N))\n",
    "\n",
    "    poscnt = P.shape[0]\n",
    "    NumToGen = nTarget - poscnt\n",
    "    Me  = np.mean((P),axis = 0)\n",
    "    PCov = np.cov(P.T)\n",
    "    [D,V] = np.linalg.eig(PCov)\n",
    "    #d = [D[x,x] for x in range(D.shape[0])]\n",
    "    d = D\n",
    "    #d = d.astype(np.float32)\n",
    "    n = P.shape[1] #Feature dimension\n",
    "    idx = d.argsort()[::-1]   \n",
    "    d = d[idx]\n",
    "    V = V[:,idx]\n",
    "    #d = d[0:n+1]\n",
    "    #v = V[:,n::-1]\n",
    "    \n",
    "    \n",
    "\n",
    "    Ind = (d<= 5e-04)\n",
    "\n",
    "    if np.sum(Ind) != 0:\n",
    "        M = (list(Ind).index(True)+1)\n",
    "    else:\n",
    "        M = n\n",
    "        \n",
    "    #print(Ind,M)\n",
    "\n",
    "    PN = np.concatenate((P,N),axis=0)\n",
    "    TCov = np.cov(PN.T)\n",
    "    dT    = np.dot(V.T,np.dot(TCov, V))\n",
    "    dT = [dT[x,x] for x in range(dT.shape[0])]\n",
    "    \n",
    "\n",
    "    #Modify the Eigen spectrum according to a 1-Parameter Model\n",
    "    dMod  = np.zeros((n,1))\n",
    "    Alpha = d[0]* d[M-1]*(M-1) /(d[0] - d[M-1]) #d[0]* d[M-1]*(M-1) /(d[0] - d[M-1])\n",
    "    Beta  = ((M)*d[M-1] - d[0])/(d[0] - d[M-1])\n",
    "       \n",
    " \n",
    "    for i in range(n):\n",
    "        if i<M-1:\n",
    "\n",
    "            dMod[i] = d[i]\n",
    "        else:\n",
    "            dMod[i] = Alpha/(i+1+Beta)\n",
    "            if dMod[i] > dT[i]:\n",
    "                dMod[i] = dT[i]\n",
    "\n",
    "    R = 1\n",
    "    d = dMod\n",
    "            \n",
    "    ########################################\n",
    "    \n",
    "    #OUTPUT:\n",
    "    #The oversampled dataset\n",
    "    import scipy\n",
    "    from scipy.stats import multivariate_normal\n",
    "    Rn = M\n",
    "    Un = len(Me) - M\n",
    "    Ptemp = P\n",
    "\n",
    "    MuR = np.zeros((Rn,1)) #mlayer#\n",
    "    SigmaR = np.identity((Rn)) #v_mat #\n",
    "\n",
    "    MuU = np.zeros((Un,1))\n",
    "    SigmaU = np.identity((Un))\n",
    "\n",
    "    SampGen = np.zeros((int(NumToGen*R), len(Me)))\n",
    "    SampSel = np.zeros((int(NumToGen), len(Me)))\n",
    "    Prob    = np.zeros((int(NumToGen*R),1))\n",
    "\n",
    "    cnt = 0\n",
    "    DD = np.sqrt(d)\n",
    "    MuR = MuR.reshape(MuR.shape[0],)\n",
    "    #MuU = MuU.reshape(MuU.shape[0],)\n",
    "    \n",
    "    while cnt < int(R*NumToGen):\n",
    "        \n",
    "        \n",
    "        aR =  np.random.multivariate_normal(MuR.T, SigmaR, 1)\n",
    "        tp = multivariate_normal.pdf(aR, MuR, SigmaR) #aR.pdf(1)\n",
    "        #print(tp)\n",
    "\n",
    "        if Un > 0:\n",
    "            aU = np.random.multivariate_normal(MuU.T, SigmaU, 1)\n",
    "            #scipy.stats.multivariate_normal(MuU, SigmaU, 1)\n",
    "            a = np.multiply(np.concatenate((aR,aU),axis=0),DD)   #The vector in Eigen transformed domain;\n",
    "        else:\n",
    "            a = np.multiply(aR.T,DD)\n",
    "           \n",
    "        x = np.dot(a.T,V.T)+ Me\n",
    "        #print(x)\n",
    "        #pdb.set_trace()\n",
    "        PDist = np.sqrt(np.sum(np.square((x-P)),axis=1))\n",
    "        NDist = np.sqrt(np.sum(np.square((x-N)),axis=1))\n",
    "\n",
    "        [tmp,ind]  = [np.min(NDist),np.argmin(NDist)]\n",
    "\n",
    "        if np.min(PDist) < tmp:\n",
    "            PPDist = np.sqrt(np.sum(np.square((N[ind,:]-P)),axis=1))\n",
    "            if tmp >= np.min(PPDist) and tmp <= np.max(PPDist):\n",
    "                SampGen[cnt,:] = x\n",
    "                Prob[cnt,0] = tp  \n",
    "                cnt+=1\n",
    "                Ptemp = np.concatenate((Ptemp,SampGen),axis =0)\n",
    "\n",
    "    for i in range (int(R*NumToGen)):\n",
    "        [tmp,ind]  = [np.min(Prob),np.argmin(Prob)]\n",
    "        Prob[ind] =  np.inf\n",
    "        SampSel[i,:] = SampGen[ind,:]\n",
    "\n",
    "    Ynew = SampSel #np.concatenate((SampSel,P),axis = 0)\n",
    "   \n",
    "    #return Ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "3c1a9fa4-5391-4e78-b37b-c961b99c431c",
    "_uuid": "3860b1a3-f636-4459-965f-aa7cf92e1fa3",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples generated: 950\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples generated:\",cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "e26052fd-e89b-42b6-9dbd-a07dc82a3bec",
    "_uuid": "00178e06-9838-44a8-8a8c-e9e4c724a073",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Datanew = np.concatenate((SampSel,P),axis = 0)\n",
    "Total = np.concatenate((Datanew,N),axis = 0)\n",
    "label = np.zeros((Total.shape[0],))\n",
    "label[0:Datanew.shape[0]] = 1\n",
    "label[Datanew.shape[0]:Total.shape[0]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for MSPO oversampled data:\n",
      "0.0355620725176149\n"
     ]
    }
   ],
   "source": [
    "score_mspo = silhouette_score(Total, label, metric='l2')\n",
    "print(\"Silhouette score for MSPO oversampled data:\")\n",
    "print(score_mspo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84122c9f-413c-454f-a1f5-53a8461d1e66",
    "_uuid": "fe61b435-266f-4d89-aa2b-5288c199814e"
   },
   "source": [
    "### MLP on SPO Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "df6dc321-4c2e-416b-8b7b-bdc99bed9b4a",
    "_uuid": "74f20f83-48e3-46f3-aec3-a8a881fa6543",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "2dc243f3-ac44-45b6-b3f7-54ab5ce731ff",
    "_uuid": "05edbc66-9a17-49a9-b6e8-1e0ede40101e",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nshuffled_indices = np.random.permutation((Total.shape[0])) #return a permutation of the indices\\n\\n#print(f\"shuffled indices: {shuffled_indices}\")\\n\\nTotal = Total[shuffled_indices]\\n\\nlabel = label[shuffled_indices]\\n#label = label.astype(\\'int8\\')\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "shuffled_indices = np.random.permutation((Total.shape[0])) #return a permutation of the indices\n",
    "\n",
    "#print(f\"shuffled indices: {shuffled_indices}\")\n",
    "\n",
    "Total = Total[shuffled_indices]\n",
    "\n",
    "label = label[shuffled_indices]\n",
    "#label = label.astype('int8')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7112526539278131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    class -1       0.97      0.72      0.82       440\n",
      "     class 1       0.14      0.65      0.23        31\n",
      "\n",
      "    accuracy                           0.71       471\n",
      "   macro avg       0.55      0.68      0.52       471\n",
      "weighted avg       0.91      0.71      0.78       471\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = (Total)\n",
    "y_train = (label)\n",
    "X_test = (X_valmlp)\n",
    "y_test = (y_valmlp)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_im,random_state=1, test_size=0.1)\n",
    "sc_X = StandardScaler()\n",
    "mm_X = MinMaxScaler(feature_range=(-2.85,2.85))\n",
    "\n",
    "X_trainscaled= mm_X.fit_transform(X_train)\n",
    "X_testscaled= mm_X.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(batch_size =250,solver='adam',hidden_layer_sizes=(9,16, 8,6,),\n",
    "                    activation=\"tanh\",learning_rate_init = 0.15,random_state=1,shuffle = True,\n",
    "                    max_iter = 5000,learning_rate = 'constant',beta_1=0.9,beta_2=0.999,\n",
    "                   alpha=0.009,warm_start = False)\n",
    "#learning_rate_init = 0.0000595\n",
    "clf.fit(X_trainscaled, y_train)\n",
    "y_pred=clf.predict(X_testscaled)\n",
    "print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"-1\",'1'])\n",
    "fig.figure_.suptitle(\"Confusion Matrix for Original Latent space\")\n",
    "target_names = ['class -1', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b994119c-5cd9-471d-9620-8d28590e1c63",
    "_uuid": "b76cd7b1-97dc-4201-99a8-ef9d1ca90e20"
   },
   "source": [
    "#### Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "6a63f9c6-49b0-4ab2-a8b2-f419cfe5a4b1",
    "_uuid": "cf0d8064-41a2-44e1-bfcf-759456092926",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def metrics_aa_gm(ypred, ytrue):\n",
    "    cm = confusion_matrix(ytrue, ypred)\n",
    "    sum_classes = np.sum(cm, axis=1)\n",
    "    true_pred = np.diagonal(cm)\n",
    "    tp_rate = true_pred/sum_classes\n",
    "    ACSA = np.mean(tp_rate)\n",
    "    GM = np.sqrt(np.prod(tp_rate))\n",
    "    return ACSA, GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "b9239cba-34c4-4259-ae1d-c8ea53abaa6b",
    "_uuid": "f781f587-e8d6-414e-9e4b-f8e086fde23b",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6805351906158358 0.6796152093976229\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "acsa, gm = metrics_aa_gm(y_pred, y_test) \n",
    "print (acsa, gm,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "4fc394b4-0554-40a0-9aac-4cc408ea9e11",
    "_uuid": "e9c09384-22e6-4840-a22c-baab55cc2f17",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 200.4611210823059\n"
     ]
    }
   ],
   "source": [
    "print('Time taken:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "9088c02a-bc46-47ad-a148-e066798372b0",
    "_uuid": "73035f86-86a2-4037-9c3a-1ac0b72609be",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for MSPO oversampled data:\n",
      "0.0355620725176149\n"
     ]
    }
   ],
   "source": [
    "score_mspo = silhouette_score(Total, label, metric='l2')\n",
    "print(\"Silhouette score for MSPO oversampled data:\")\n",
    "print(score_mspo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
