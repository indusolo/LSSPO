{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-31T04:47:40.49833Z",
     "iopub.status.busy": "2021-08-31T04:47:40.49767Z",
     "iopub.status.idle": "2021-08-31T04:47:40.52182Z",
     "shell.execute_reply": "2021-08-31T04:47:40.520682Z",
     "shell.execute_reply.started": "2021-08-31T04:47:40.498229Z"
    },
    "id": "VxXnucnKsVvm"
   },
   "source": [
    "### Wafer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:34.450797Z",
     "iopub.status.busy": "2021-09-10T18:20:34.450359Z",
     "iopub.status.idle": "2021-09-10T18:20:36.843022Z",
     "shell.execute_reply": "2021-09-10T18:20:36.842074Z",
     "shell.execute_reply.started": "2021-09-10T18:20:34.450708Z"
    },
    "id": "yOcrNFFOsVvu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "#from pymfe.mfe import MFE\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "import random\n",
    "random.seed(1)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:36.844761Z",
     "iopub.status.busy": "2021-09-10T18:20:36.844351Z",
     "iopub.status.idle": "2021-09-10T18:20:37.080272Z",
     "shell.execute_reply": "2021-09-10T18:20:37.079363Z",
     "shell.execute_reply.started": "2021-09-10T18:20:36.844729Z"
    },
    "id": "bVKDPfbAsVv5"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Layer\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten \n",
    "from tensorflow.keras import backend as K\n",
    "import scipy\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:37.082223Z",
     "iopub.status.busy": "2021-09-10T18:20:37.081773Z",
     "iopub.status.idle": "2021-09-10T18:20:38.335088Z",
     "shell.execute_reply": "2021-09-10T18:20:38.334026Z",
     "shell.execute_reply.started": "2021-09-10T18:20:37.082179Z"
    },
    "id": "F8FEcxsLsVv9",
    "outputId": "a0b71e6a-2eab-48e6-bec2-6d5d50b17893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 153 entries, att1 to target\n",
      "dtypes: float64(152), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f9d50a71-7b6a-4998-9805-a2aefea71e04\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>att11</th>\n",
       "      <th>att12</th>\n",
       "      <th>att13</th>\n",
       "      <th>att14</th>\n",
       "      <th>att15</th>\n",
       "      <th>att16</th>\n",
       "      <th>att17</th>\n",
       "      <th>att18</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>att22</th>\n",
       "      <th>att23</th>\n",
       "      <th>att24</th>\n",
       "      <th>att25</th>\n",
       "      <th>att26</th>\n",
       "      <th>att27</th>\n",
       "      <th>att28</th>\n",
       "      <th>att29</th>\n",
       "      <th>att30</th>\n",
       "      <th>att31</th>\n",
       "      <th>att32</th>\n",
       "      <th>att33</th>\n",
       "      <th>att34</th>\n",
       "      <th>att35</th>\n",
       "      <th>att36</th>\n",
       "      <th>att37</th>\n",
       "      <th>att38</th>\n",
       "      <th>att39</th>\n",
       "      <th>att40</th>\n",
       "      <th>...</th>\n",
       "      <th>att114</th>\n",
       "      <th>att115</th>\n",
       "      <th>att116</th>\n",
       "      <th>att117</th>\n",
       "      <th>att118</th>\n",
       "      <th>att119</th>\n",
       "      <th>att120</th>\n",
       "      <th>att121</th>\n",
       "      <th>att122</th>\n",
       "      <th>att123</th>\n",
       "      <th>att124</th>\n",
       "      <th>att125</th>\n",
       "      <th>att126</th>\n",
       "      <th>att127</th>\n",
       "      <th>att128</th>\n",
       "      <th>att129</th>\n",
       "      <th>att130</th>\n",
       "      <th>att131</th>\n",
       "      <th>att132</th>\n",
       "      <th>att133</th>\n",
       "      <th>att134</th>\n",
       "      <th>att135</th>\n",
       "      <th>att136</th>\n",
       "      <th>att137</th>\n",
       "      <th>att138</th>\n",
       "      <th>att139</th>\n",
       "      <th>att140</th>\n",
       "      <th>att141</th>\n",
       "      <th>att142</th>\n",
       "      <th>att143</th>\n",
       "      <th>att144</th>\n",
       "      <th>att145</th>\n",
       "      <th>att146</th>\n",
       "      <th>att147</th>\n",
       "      <th>att148</th>\n",
       "      <th>att149</th>\n",
       "      <th>att150</th>\n",
       "      <th>att151</th>\n",
       "      <th>att152</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.602294</td>\n",
       "      <td>-1.670823</td>\n",
       "      <td>-1.693666</td>\n",
       "      <td>-1.699377</td>\n",
       "      <td>-1.699377</td>\n",
       "      <td>-1.703660</td>\n",
       "      <td>-1.703660</td>\n",
       "      <td>-1.703660</td>\n",
       "      <td>-1.703660</td>\n",
       "      <td>-1.703660</td>\n",
       "      <td>-0.734257</td>\n",
       "      <td>-0.976964</td>\n",
       "      <td>0.462150</td>\n",
       "      <td>0.946137</td>\n",
       "      <td>1.444402</td>\n",
       "      <td>1.527208</td>\n",
       "      <td>1.622864</td>\n",
       "      <td>1.668550</td>\n",
       "      <td>1.704242</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>1.787048</td>\n",
       "      <td>1.741362</td>\n",
       "      <td>1.727085</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>1.714236</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>1.714236</td>\n",
       "      <td>1.722802</td>\n",
       "      <td>1.722802</td>\n",
       "      <td>1.722802</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>1.600021</td>\n",
       "      <td>-1.346737</td>\n",
       "      <td>-1.589444</td>\n",
       "      <td>-1.639414</td>\n",
       "      <td>-1.666540</td>\n",
       "      <td>-1.676534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.279405</td>\n",
       "      <td>0.279405</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.279405</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.279405</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>0.275122</td>\n",
       "      <td>-1.014084</td>\n",
       "      <td>-1.132583</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>-1.145432</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>-0.593106</td>\n",
       "      <td>-0.207429</td>\n",
       "      <td>0.101114</td>\n",
       "      <td>0.197533</td>\n",
       "      <td>0.255385</td>\n",
       "      <td>0.293952</td>\n",
       "      <td>0.332520</td>\n",
       "      <td>0.351804</td>\n",
       "      <td>0.371088</td>\n",
       "      <td>0.390372</td>\n",
       "      <td>0.390372</td>\n",
       "      <td>0.409656</td>\n",
       "      <td>0.409656</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978784</td>\n",
       "      <td>-0.978784</td>\n",
       "      <td>-0.959500</td>\n",
       "      <td>-0.978784</td>\n",
       "      <td>-0.959500</td>\n",
       "      <td>-0.959500</td>\n",
       "      <td>-0.959500</td>\n",
       "      <td>-0.978784</td>\n",
       "      <td>0.949604</td>\n",
       "      <td>1.046024</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.084591</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>1.065308</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.852721</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.433614</td>\n",
       "      <td>-0.433614</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.341733</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.341733</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.372360</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>-0.402987</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.362689</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>0.393316</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>0.707507</td>\n",
       "      <td>1.078513</td>\n",
       "      <td>0.992386</td>\n",
       "      <td>0.767133</td>\n",
       "      <td>0.608130</td>\n",
       "      <td>0.453544</td>\n",
       "      <td>0.360793</td>\n",
       "      <td>0.287916</td>\n",
       "      <td>0.208415</td>\n",
       "      <td>0.157622</td>\n",
       "      <td>0.106830</td>\n",
       "      <td>0.078121</td>\n",
       "      <td>0.051621</td>\n",
       "      <td>-0.937729</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016679</td>\n",
       "      <td>1.014470</td>\n",
       "      <td>1.010053</td>\n",
       "      <td>1.003428</td>\n",
       "      <td>1.001220</td>\n",
       "      <td>1.001220</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.990178</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>-0.796394</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.094523</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>-1.096732</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.105914</td>\n",
       "      <td>-1.105914</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.105914</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.105914</td>\n",
       "      <td>0.775413</td>\n",
       "      <td>1.005735</td>\n",
       "      <td>0.740972</td>\n",
       "      <td>0.512802</td>\n",
       "      <td>0.304005</td>\n",
       "      <td>0.183462</td>\n",
       "      <td>0.077987</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>-0.033945</td>\n",
       "      <td>-0.083454</td>\n",
       "      <td>-0.115742</td>\n",
       "      <td>-0.150183</td>\n",
       "      <td>-0.171708</td>\n",
       "      <td>-0.976761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999278</td>\n",
       "      <td>0.997125</td>\n",
       "      <td>0.994972</td>\n",
       "      <td>0.997125</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.986362</td>\n",
       "      <td>0.992820</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.988515</td>\n",
       "      <td>0.986362</td>\n",
       "      <td>0.986362</td>\n",
       "      <td>0.986362</td>\n",
       "      <td>-1.069320</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>-1.103761</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 153 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9d50a71-7b6a-4998-9805-a2aefea71e04')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f9d50a71-7b6a-4998-9805-a2aefea71e04 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f9d50a71-7b6a-4998-9805-a2aefea71e04');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       att1      att2      att3      att4  ...    att150    att151    att152  target\n",
       "0 -1.602294 -1.670823 -1.693666 -1.699377  ... -1.145432 -1.145432 -1.145432    b'1'\n",
       "1  1.084591  1.084591  1.084591  1.065308  ...  1.065308  1.065308  1.065308    b'1'\n",
       "2  0.362689  0.362689  0.362689  0.393316  ...  0.393316  0.393316  0.393316    b'1'\n",
       "3 -1.094523 -1.094523 -1.094523 -1.096732  ... -1.096732 -1.096732 -1.096732    b'1'\n",
       "4 -1.103761 -1.103761 -1.103761 -1.103761  ... -1.103761 -1.103761 -1.103761    b'1'\n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Traindata, Trainmeta = arff.loadarff('Wafer_TRAIN.arff')\n",
    "Testdata, Testmeta = arff.loadarff('Wafer_TEST.arff')\n",
    "df_Train = pd.DataFrame(Traindata)\n",
    "df_Test =  pd.DataFrame(Testdata)\n",
    "df_Train.info()\n",
    "df_Train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.337116Z",
     "iopub.status.busy": "2021-09-10T18:20:38.336798Z",
     "iopub.status.idle": "2021-09-10T18:20:38.343362Z",
     "shell.execute_reply": "2021-09-10T18:20:38.342083Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.337083Z"
    },
    "id": "Vu1N3FOusVwA",
    "outputId": "744376a9-3a86-44f9-fe58-936874ba4df7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6164, 153)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.344873Z",
     "iopub.status.busy": "2021-09-10T18:20:38.344584Z",
     "iopub.status.idle": "2021-09-10T18:20:38.669483Z",
     "shell.execute_reply": "2021-09-10T18:20:38.668384Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.344844Z"
    },
    "id": "Lk6GF6YTsVwE",
    "outputId": "0140336f-ce6d-4443-eaa0-19d7e986d038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target    object\n",
      "dtype: object\n",
      "target    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXWUlEQVR4nO3de5RlZX3m8e8DiAS5NdIidIPNaM8oaiDaAvEWLxGBUWGMGLzRKglhBhNdM9HBxAwqkpjEhIjX1TOgoCaIRgLeBntAJbrk0ijKfdEiCC3YDd1cDQjymz/OW+ZQVPVbNHWquqnvZ62zau93v/vdv31ozlP73eecSlUhSdL6bDbbBUiSNn6GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLbTKSfCvJH8xyDS9KcuMsHv+9ST7blndPcleSzadp7E8m+Yu2PK3nmeQFSa6ervE08wwLbZD2IjX2eCDJvw2tv2EDxpvWIEhyXZLfna7xNkZV9dOq2qaqfrW+fknenOQ7UxjvqKo6bjpqS1JJnjI09r9W1X+ajrE1O7aY7QK0aaqqbcaWk1wH/EFV/b/Zq0iPRJLNe6Gjuc0rC02rJJslOSbJj5PcmuT0JDu2bVsl+Wxrvy3JRUl2TnI88ALgo+3K5KOt/8uSXJXk9taWoeM8Ocm5baxbknwuyQ5t22eA3YEvt/He1dq/kOTmNt55SZ6+nvPYMcmnkvwsybok/zJJv7FzvTPJFUn+y9C2pyT5djveLUk+39qT5IQkq5PckeTSJM+YZPw92hh3JlkO7DS0bVH7DX6Ltv7mJNe2vj9J8oYkTwM+Cfx2ey5ua30/neQTSb6W5G7gxa3tA+OO/2et9uuGrxjHXwkOX70kOa81/7Ad8/fHT2sleVob47Yklyd51dC2Tyf5WJKvtnO5IMmTJ/tvpZlhWGi6/TFwCPA7wK7AOuBjbdtSYHtgN+DxwFHAv1XVnwP/CrytTau8LclOwJeA9zB4gfwx8Lyh4wT4q3aMp7Ux3wtQVW8Cfgq8so33N22frwOLgScA3wc+t57z+AywNfD01v+ESfr9mEHQbQ+8D/hskl3atuOAbwDzgIXAR1r7/sALgf/Y9nstcOsk4/8jcHF7Do5j8Bw+RJLHAScCB1bVtsBzgUuq6koGz/P32nOxw9BurweOB7YFJpqmemI77oJ23GVJulNJVfXCtrhXO+bnx9X6GODLDJ6bJzD4N/O5cWMfxuD5nAesbHVqFhkWmm5HAX9eVTdW1b0MXsBf0377vY9BSDylqn5VVRdX1R2TjHMQcHlVfbGq7gP+Abh5bGNVrayq5VV1b1WtAf6eQUBNqqpOrqo7h+raK8n24/u1F/sDgaOqal1V3VdV355kzC9U1c+q6oH2ongNsE/bfB/wJGDXqrqnqr4z1L4t8FQgVXVlVd00QR27A88B/qKd53kMXmQn8wDwjCS/UVU3VdXl63s+gDOr6rut9nsm6TN27G8DX2UQbI/UfsA2wAer6pdVdS7wFeB1Q33OqKoLq+p+BqG+9zQcV4+AYaHp9iTgjDa9cBtwJfArYGcGv62fDZzWpnf+pv2WOZFdgRvGVmrwjZe/Xm/TV6clWZXkDuCzDE3RjJdk8yQfbFNGdwDXtU0T7bMbsLaq1vVONsnhSS4ZOt9nDI35LgZXQBe2qZa3tnM5F/gogyuu1UmWJdlukudgXVXdPdR2/UR1tD6/zyCsb2pTOE/tlH9DZ/tEx961s89U7ArcUFUPjBt7wdD6zUPLv2AQLppFhoWm2w0MpkJ2GHpsVVWr2m/o76uqPRlMk7wCOLztN/7rj29i8KINDOb5h9eBv2z7PLOqtgPeyNA9jQnGez1wMPC7DKZ+Fo0NPck57Dh2D2QySZ4E/G/gbcDj2xTPZWNjVtXNVfWHVbUr8EfAx9PeIVRVJ1bVs4E9GUxHvXOCQ9wEzGtTTGN2n6yeqjq7ql4G7AJc1WqDhz4XdNrHTHTsn7XluxlM0415YmesYT8Ddksy/PqzO7DqYYyhGWZYaLp9Eji+vZCSZH6Sg9vyi5M8M4PPBdzBYDpm7LfLnwP/YWicrwJPT/LqNoX1Jzz4BWlb4C7g9iQLeOiL7fjxtgXuZXBvYGsGYTOhNiX0dQYv7vOSPCbJCyfo+jgGL7hr2vm9hcGVBW390CQL2+q61veBJM9Jsm+7qrobuGfoeRiu43pgBfC+JFsmeT7wyolqbldaB7cX93vbczP83C5MsuVk57weY8d+AYNw/0JrvwR4dZKtWwAeMW6/8c//sAsYXC28qz23L2rnddoG1KcZYlhoun0YOAv4RpI7gfOBfdu2JwJfZBAUVwLfZjA1NbbfazJ459GJVXULcCjwQQYv8IuB7w4d533As4DbGQTLl8bV8VfAe9r00J8CpzKY6lgFXNHqWp83MQizq4DVwDvGd6iqK4C/A77H4MXxmeNqfA5wQZK72nPy9qq6FtiOwW/961pNtwJ/O0kdr2fw/K0Fjm3nMZHNgP/O4Lf2tQzu3/zXtu1c4HLg5iS3dM572M2txp8xuG9wVFVd1badAPySwXmfwkPfLPBe4JT2/D/oPkdV/ZJBOBwI3AJ8HDh8aGxthOIfP5Ik9XhlIUnqMiwkSV2GhSSpy7CQJHU9Kr9IcKeddqpFixbNdhmStEm5+OKLb6mq+RNte1SGxaJFi1ixYsVslyFJm5QkE35DADgNJUmaAsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK5H5Se4pUezn77/mbNdgjZCu/+vS0c6vlcWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldIw2LJNcluTTJJUlWtLYdkyxPck37Oa+1J8mJSVYm+VGSZw2Ns7T1vybJ0lHWLEl6qJm4snhxVe1dVUva+jHAOVW1GDinrQMcCCxujyOBT8AgXIBjgX2BfYBjxwJGkjQzZmMa6mDglLZ8CnDIUPupNXA+sEOSXYCXA8uram1VrQOWAwfMdNGSNJeNOiwK+EaSi5Mc2dp2rqqb2vLNwM5teQFww9C+N7a2ydolSTNk1H9W9flVtSrJE4DlSa4a3lhVlaSm40AtjI4E2H333adjSElSM9Iri6pa1X6uBs5gcM/h5216ifZzdeu+CthtaPeFrW2y9vHHWlZVS6pqyfz586f7VCRpThtZWCR5XJJtx5aB/YHLgLOAsXc0LQXObMtnAYe3d0XtB9zepqvOBvZPMq/d2N6/tUmSZsgop6F2Bs5IMnacf6yq/5vkIuD0JEcA1wOvbf2/BhwErAR+AbwFoKrWJjkOuKj1e39VrR1h3ZKkcUYWFlV1LbDXBO23Ai+doL2AoycZ62Tg5OmuUZI0NX6CW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXSMPiySbJ/lBkq+09T2SXJBkZZLPJ9mytT+2ra9s2xcNjfHu1n51kpePumZJ0oPNxJXF24Erh9b/Gjihqp4CrAOOaO1HAOta+wmtH0n2BA4Dng4cAHw8yeYzULckqRlpWCRZCPxn4P+09QAvAb7YupwCHNKWD27rtO0vbf0PBk6rqnur6ifASmCfUdYtSXqwUV9Z/APwLuCBtv544Laqur+t3wgsaMsLgBsA2vbbW/9ft0+wz68lOTLJiiQr1qxZM93nIUlz2sjCIskrgNVVdfGojjGsqpZV1ZKqWjJ//vyZOKQkzRlbjHDs5wGvSnIQsBWwHfBhYIckW7Srh4XAqtZ/FbAbcGOSLYDtgVuH2scM7yNJmgEju7KoqndX1cKqWsTgBvW5VfUG4JvAa1q3pcCZbfmstk7bfm5VVWs/rL1bag9gMXDhqOqWJD3UKK8sJvM/gdOSfAD4AXBSaz8J+EySlcBaBgFDVV2e5HTgCuB+4Oiq+tXMly1Jc9eMhEVVfQv4Vlu+lgnezVRV9wCHTrL/8cDxo6tQkrQ+foJbktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktQ1pbBIcs5U2iRJj05brG9jkq2ArYGdkswD0jZtBywYcW2SpI3EesMC+CPgHcCuwMX8e1jcAXx0hHVJkjYi6w2Lqvow8OEkf1xVH5mhmiRJG5kp3bOoqo8keW6S1yc5fOyxvn2SbJXkwiQ/THJ5kve19j2SXJBkZZLPJ9mytT+2ra9s2xcNjfXu1n51kpdv+OlKkjbEVG9wfwb4EPB84DntsaSz273AS6pqL2Bv4IAk+wF/DZxQVU8B1gFHtP5HAOta+wmtH0n2BA4Dng4cAHw8yeZTPkNJ0iPWu2cxZgmwZ1XVVAdufe9qq49pjwJeAry+tZ8CvBf4BHBwWwb4IvDRJGntp1XVvcBPkqwE9gG+N9VaJEmPzFQ/Z3EZ8MSHO3iSzZNcAqwGlgM/Bm6rqvtblxv593dVLQBuAGjbbwceP9w+wT7DxzoyyYokK9asWfNwS5UkrcdUryx2Aq5IciGD6SUAqupV69upqn4F7J1kB+AM4KkbWmhPVS0DlgEsWbJkyldAkqS+qYbFex/JQarqtiTfBH4b2CHJFu3qYSGwqnVbBewG3JhkC2B74Nah9jHD+0iSZsBU3w317Yke69snyfx2RUGS3wBeBlwJfBN4Teu2FDizLZ/V1mnbz233Pc4CDmvvltoDWAxcOPVTlCQ9UlO6skhyJ4Ob0wBbMrhZfXdVbbee3XYBTmnvXNoMOL2qvpLkCuC0JB8AfgCc1PqfBHym3cBey+AdUFTV5UlOB64A7geObtNbkqQZMqWwqKptx5aH3qG0X2efHwG/NUH7tQzezTS+/R7g0EnGOh44fiq1SpKm38P+1tka+BfAD8dJ0hwx1WmoVw+tbsbgcxf3jKQiSdJGZ6rvhnrl0PL9wHUMpqIkSXPAVO9ZvGXUhUiSNl5T/W6ohUnOSLK6Pf45ycJRFydJ2jhM9Qb3pxh83mHX9vhya5MkzQFTDYv5VfWpqrq/PT4NzB9hXZKkjchUw+LWJG9sXwy4eZI3MvgqDknSHDDVsHgr8FrgZuAmBl/H8eYR1SRJ2shM9a2z7weWVtU6gCQ7MvhjSG8dVWGSpI3HVK8sfnMsKACqai0TfJWHJOnRaaphsVmSeWMr7cpiqlclkqRN3FRf8P8O+F6SL7T1Q/GL/SRpzpjqJ7hPTbKCwd/PBnh1VV0xurIkSRuTKU8ltXAwICRpDnrYX1EuSZp7DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqWtkYZFktyTfTHJFksuTvL2175hkeZJr2s95rT1JTkyyMsmPkjxraKylrf81SZaOqmZJ0sRGeWVxP/A/qmpPYD/g6CR7AscA51TVYuCctg5wILC4PY4EPgG//qt8xwL7AvsAxw7/1T5J0uiNLCyq6qaq+n5bvhO4ElgAHAyc0rqdAhzSlg8GTq2B84EdkuwCvBxYXlVr298BXw4cMKq6JUkPNSP3LJIsAn4LuADYuapuaptuBnZuywuAG4Z2u7G1TdY+/hhHJlmRZMWaNWumtX5JmutGHhZJtgH+GXhHVd0xvK2qCqjpOE5VLauqJVW1ZP78+dMxpCSpGWlYJHkMg6D4XFV9qTX/vE0v0X6ubu2rgN2Gdl/Y2iZrlyTNkFG+GyrAScCVVfX3Q5vOAsbe0bQUOHOo/fD2rqj9gNvbdNXZwP5J5rUb2/u3NknSDNlihGM/D3gTcGmSS1rbnwEfBE5PcgRwPfDatu1rwEHASuAXwFsAqmptkuOAi1q/91fV2hHWLUkaZ2RhUVXfATLJ5pdO0L+AoycZ62Tg5OmrTpL0cPgJbklSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdY0sLJKcnGR1ksuG2nZMsjzJNe3nvNaeJCcmWZnkR0meNbTP0tb/miRLR1WvJGlyo7yy+DRwwLi2Y4BzqmoxcE5bBzgQWNweRwKfgEG4AMcC+wL7AMeOBYwkaeaMLCyq6jxg7bjmg4FT2vIpwCFD7afWwPnADkl2AV4OLK+qtVW1DljOQwNIkjRiM33PYuequqkt3wzs3JYXADcM9buxtU3W/hBJjkyyIsmKNWvWTG/VkjTHzdoN7qoqoKZxvGVVtaSqlsyfP3+6hpUkMfNh8fM2vUT7ubq1rwJ2G+q3sLVN1i5JmkEzHRZnAWPvaFoKnDnUfnh7V9R+wO1tuupsYP8k89qN7f1bmyRpBm0xqoGT/BPwImCnJDcyeFfTB4HTkxwBXA+8tnX/GnAQsBL4BfAWgKpam+Q44KLW7/1VNf6muSRpxEYWFlX1ukk2vXSCvgUcPck4JwMnT2NpkqSHyU9wS5K6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrpF9zmJT9+x3njrbJWgjdPHfHj7bJUizwisLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHVtMmGR5IAkVydZmeSY2a5HkuaSTSIskmwOfAw4ENgTeF2SPWe3KkmaOzaJsAD2AVZW1bVV9UvgNODgWa5JkuaMLWa7gClaANwwtH4jsO9whyRHAke21buSXD1Dtc0FOwG3zHYRG4N8aOlsl6AH89/mmGMzHaM8abINm0pYdFXVMmDZbNfxaJRkRVUtme06pPH8tzlzNpVpqFXAbkPrC1ubJGkGbCphcRGwOMkeSbYEDgPOmuWaJGnO2CSmoarq/iRvA84GNgdOrqrLZ7msucTpPW2s/Lc5Q1JVs12DJGkjt6lMQ0mSZpFhIUnqMiy0XkmemuR7Se5N8qezXY8EkOTkJKuTXDbbtcwVhoV61gJ/AnxotguRhnwaOGC2i5hLDAutV1WtrqqLgPtmuxZpTFWdx+AXGc0Qw0KS1GVYSJK6DAs9RJKjk1zSHrvOdj2SZt8m8Qluzayq+hiDvx8iSYCf4FZHkicCK4DtgAeAu4A9q+qOWS1Mc1qSfwJexOAryn8OHFtVJ81qUY9yhoUkqct7FpKkLsNCktRlWEiSugwLSVKXYSFJ6jIspA2QZIck/20GjnNIkj1HfRypx7CQNswOwJTDIgMb8v/bIYBhoVnn5yykDZDkNOBg4Grgm8BvAvOAxwDvqaozkyxi8HfjLwCeDRwEHA68EVgD3ABcXFUfSvJkBp+anw/8AvhDYEfgK8Dt7fF7VfXjGTpF6UH8ug9pwxwDPKOq9k6yBbB1Vd2RZCfg/CRntX6LgaVVdX6S5wC/B+zFIFS+D1zc+i0Djqqqa5LsC3y8ql7SxvlKVX1xJk9OGs+wkB65AH+Z5IUMvhJlAbBz23Z9VZ3flp8HnFlV9wD3JPkyQJJtgOcCX0gyNuZjZ6p4aSoMC+mRewOD6aNnV9V9Sa4Dtmrb7p7C/psBt1XV3iOqT3rEvMEtbZg7gW3b8vbA6hYULwaeNMk+3wVemWSrdjXxCoD2pYw/SXIo/Ppm+F4THEeaNYaFtAGq6lbgu0kuA/YGliS5lMEN7Ksm2eci4CzgR8DXgUsZ3LiGwdXJEUl+CFzO4OY5wGnAO5P8oN0El2aF74aSZlCSbarqriRbA+cBR1bV92e7LqnHexbSzFrWPmS3FXCKQaFNhVcWkqQu71lIkroMC0lSl2EhSeoyLCRJXYaFJKnr/wN9ntH74k4lHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Non-numerical datatype in the train and test set\n",
    "print(df_Train.dtypes[df_Train.dtypes == object])\n",
    "print(df_Test.dtypes[df_Test.dtypes == object])\n",
    "#Convert the target attribute to integer\n",
    "Train_target = pd.DataFrame()\n",
    "Test_target = pd.DataFrame()\n",
    "Train_target['target'] = df_Train['target'].astype(np.int8).copy()\n",
    "Test_target['target'] = df_Test['target'].astype(np.int8).copy()\n",
    "#np.sum(Train_target == -1)\n",
    "ax = plt.figure()\n",
    "ax = sns.countplot(x='target',data=Train_target).set_title('Traindata class distribution')\n",
    "plt.savefig('Traindataimbalance.png')\n",
    "ax1 = plt.figure()\n",
    "ax1 = sns.countplot(x='target',data=Test_target).set_title('Testdata class distribution')\n",
    "plt.savefig('Testdataimbalance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.671111Z",
     "iopub.status.busy": "2021-09-10T18:20:38.670819Z",
     "iopub.status.idle": "2021-09-10T18:20:38.679849Z",
     "shell.execute_reply": "2021-09-10T18:20:38.678633Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.671082Z"
    },
    "id": "mi6oI-DFsVwH",
    "outputId": "a45d1615-edb2-44df-c2f5-6bd01593c8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class = 903\n",
      "Minority class = 97\n"
     ]
    }
   ],
   "source": [
    "#Training Datast\n",
    "y_train = np.array(Train_target)\n",
    "df_Train['target'] =y_train\n",
    "y_train = np.array(df_Train['target']) #np.array(df_Test_z['target'])\n",
    "#TrainData = np.array(df_Train.drop('target', axis=1)) #np.array(df_Test_z.drop('target', axis=1))\n",
    "print(\"Majority class =\",np.sum(y_train==1))\n",
    "print(\"Minority class =\",np.sum(y_train==-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.681545Z",
     "iopub.status.busy": "2021-09-10T18:20:38.681168Z",
     "iopub.status.idle": "2021-09-10T18:20:38.693871Z",
     "shell.execute_reply": "2021-09-10T18:20:38.692684Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.681511Z"
    },
    "id": "AlwpsUFIsVwJ",
    "outputId": "35f9c49f-dc29-4d30-acec-d13f648071e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class = 5499\n",
      "Minority class = 665\n"
     ]
    }
   ],
   "source": [
    "#Test data preparation\n",
    "y_test = np.array(Test_target)\n",
    "df_Test['target'] =y_test\n",
    "y_test = np.array(df_Test['target']) #np.array(df_Test_z['target'])\n",
    "#TestData = np.array(df_Test.drop('target', axis=1)) #np.array(df_Test_z.drop('target', axis=1))\n",
    "print(\"Majority class =\",np.sum(y_test==1))\n",
    "print(\"Minority class =\",np.sum(y_test==-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtSeJ9u3sVwN"
   },
   "source": [
    "#### Training and Test dataset preparation for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.695734Z",
     "iopub.status.busy": "2021-09-10T18:20:38.695418Z",
     "iopub.status.idle": "2021-09-10T18:20:38.722085Z",
     "shell.execute_reply": "2021-09-10T18:20:38.721037Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.695698Z"
    },
    "id": "-cF5EsUrsVwQ"
   },
   "outputs": [],
   "source": [
    "Datanew = pd.concat([df_Train,df_Test])\n",
    "y = Datanew.target\n",
    "Datanew = np.array(Datanew.drop('target', axis=1))\n",
    "Datanew.shape\n",
    "Trn_imb_set = (50,3000)\n",
    "imb_index = np.insert(np.cumsum(Trn_imb_set), 0, 0)\n",
    "classes = np.array([-1,1])\n",
    "TrainData = np.zeros((np.sum(Trn_imb_set),Datanew.shape[1]))\n",
    "Tst_imb_set = (712,3402)\n",
    "Tstimb_index = np.insert(np.cumsum(Tst_imb_set), 0, 0)\n",
    "TestData = np.zeros((np.sum(Tst_imb_set),Datanew.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.726811Z",
     "iopub.status.busy": "2021-09-10T18:20:38.726377Z",
     "iopub.status.idle": "2021-09-10T18:20:38.758297Z",
     "shell.execute_reply": "2021-09-10T18:20:38.757233Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.726773Z"
    },
    "id": "Dzg44wqUsVwU"
   },
   "outputs": [],
   "source": [
    "for i in range(classes.shape[0]):\n",
    "    yind = np.where(y == classes[i])\n",
    "    sel = np.random.choice(yind[0], Trn_imb_set[i], replace=False)\n",
    "    TrainData[imb_index[i]:imb_index[i+1],:] = Datanew[sel]\n",
    "    nsel = np.setdiff1d(yind,sel)\n",
    "    TestData[Tstimb_index[i]:Tstimb_index[i+1],:] = Datanew[nsel]#np.delete(Datanew,sel,axis =0)\n",
    "        \n",
    "y_train = np.hstack([np.ones((50,))*-1,np.ones((3000,))])\n",
    "y_train = y_train.astype('int8')\n",
    "y_test = np.hstack([np.ones((712,))*-1,np.ones((3402,))])\n",
    "y_test = y_test.astype('int8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.761320Z",
     "iopub.status.busy": "2021-09-10T18:20:38.760816Z",
     "iopub.status.idle": "2021-09-10T18:20:38.768034Z",
     "shell.execute_reply": "2021-09-10T18:20:38.767024Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.761265Z"
    },
    "id": "8maMLz4osVwX",
    "outputId": "8a1eb8d1-976b-4648-e3df-2969e9336883"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4114, 152)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.769895Z",
     "iopub.status.busy": "2021-09-10T18:20:38.769521Z",
     "iopub.status.idle": "2021-09-10T18:20:38.783998Z",
     "shell.execute_reply": "2021-09-10T18:20:38.782838Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.769863Z"
    },
    "id": "hAzECkcwsVwZ"
   },
   "outputs": [],
   "source": [
    "#Normalize the data between +1 and -1\n",
    "mmscaler    = MinMaxScaler(feature_range=(-1,1))\n",
    "TrainData   = mmscaler.fit_transform(TrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.786650Z",
     "iopub.status.busy": "2021-09-10T18:20:38.785881Z",
     "iopub.status.idle": "2021-09-10T18:20:38.796825Z",
     "shell.execute_reply": "2021-09-10T18:20:38.795613Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.786598Z"
    },
    "id": "Jg_Xe9OmsVwc"
   },
   "outputs": [],
   "source": [
    "TestData   = mmscaler.transform(TestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.798872Z",
     "iopub.status.busy": "2021-09-10T18:20:38.798406Z",
     "iopub.status.idle": "2021-09-10T18:20:38.804266Z",
     "shell.execute_reply": "2021-09-10T18:20:38.803303Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.798837Z"
    },
    "id": "vOKM5WAcsVwe"
   },
   "outputs": [],
   "source": [
    "y_trn = y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaW7st0asVwf"
   },
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfIxPqxLsVwi"
   },
   "source": [
    "#### VAE code is adopted and modified from the following reference.\n",
    "#### https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/blob/master/chapter8-vae/vae-mlp-mnist-8.1.1.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.806041Z",
     "iopub.status.busy": "2021-09-10T18:20:38.805746Z",
     "iopub.status.idle": "2021-09-10T18:20:38.817554Z",
     "shell.execute_reply": "2021-09-10T18:20:38.816597Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.806008Z"
    },
    "id": "eO5wEHhpsVwq"
   },
   "outputs": [],
   "source": [
    "start_dimension = 152\n",
    "input_shape = (152, )\n",
    "intermediate_dim = 100\n",
    "batch_size = 200\n",
    "latent_dim = 4 \n",
    "epochs = 700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.819479Z",
     "iopub.status.busy": "2021-09-10T18:20:38.818978Z",
     "iopub.status.idle": "2021-09-10T18:20:38.830518Z",
     "shell.execute_reply": "2021-09-10T18:20:38.829515Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.819435Z"
    },
    "id": "rPwOfFzssVwr"
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvoKezkzsVwt"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.832436Z",
     "iopub.status.busy": "2021-09-10T18:20:38.831964Z",
     "iopub.status.idle": "2021-09-10T18:20:38.897639Z",
     "shell.execute_reply": "2021-09-10T18:20:38.896650Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.832400Z"
    },
    "id": "C-0-fDSxsVwu",
    "outputId": "9e98e25c-3385-45fc-85b5-b56d9421c643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 152)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          15300       ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 4)            404         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 4)            404         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 4)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,108\n",
      "Trainable params: 16,108\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder model\n",
    "inputs = keras.Input(shape=input_shape, name='encoder_input')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "z = Lambda(sampling,\n",
    "           output_shape=(latent_dim,), \n",
    "           name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8H3zbhEmsVww"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.899377Z",
     "iopub.status.busy": "2021-09-10T18:20:38.898996Z",
     "iopub.status.idle": "2021-09-10T18:20:38.928103Z",
     "shell.execute_reply": "2021-09-10T18:20:38.926894Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.899344Z"
    },
    "id": "yeR8fO9WsVwy",
    "outputId": "2ca6142c-07d1-49b5-9496-d84df78cb867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               500       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 152)               15352     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,852\n",
      "Trainable params: 15,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder model\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(start_dimension, activation='tanh')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.929588Z",
     "iopub.status.busy": "2021-09-10T18:20:38.929298Z",
     "iopub.status.idle": "2021-09-10T18:20:38.966142Z",
     "shell.execute_reply": "2021-09-10T18:20:38.964996Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.929559Z"
    },
    "id": "Dv68_qrJsVw1"
   },
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.967747Z",
     "iopub.status.busy": "2021-09-10T18:20:38.967458Z",
     "iopub.status.idle": "2021-09-10T18:20:38.975476Z",
     "shell.execute_reply": "2021-09-10T18:20:38.974325Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.967718Z"
    },
    "id": "_GQlhRSPsVw2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_trainvae, X_valvae, y_trvae, y_valvae = train_test_split(TrainData, TrainData, \n",
    "                                                    test_size=0.15, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.977044Z",
     "iopub.status.busy": "2021-09-10T18:20:38.976756Z",
     "iopub.status.idle": "2021-09-10T18:20:38.988106Z",
     "shell.execute_reply": "2021-09-10T18:20:38.987075Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.977017Z"
    },
    "id": "zA-ue55FsVw4"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:20:38.989906Z",
     "iopub.status.busy": "2021-09-10T18:20:38.989460Z",
     "iopub.status.idle": "2021-09-10T18:22:29.581914Z",
     "shell.execute_reply": "2021-09-10T18:22:29.581046Z",
     "shell.execute_reply.started": "2021-09-10T18:20:38.989852Z"
    },
    "id": "F-ioQFxusVw6",
    "outputId": "bfd7840e-2c73-4f9e-f096-d69da2c5e2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_mlp\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 152)]        0           []                               \n",
      "                                                                                                  \n",
      " encoder (Functional)           [(None, 4),          16108       ['encoder_input[0][0]']          \n",
      "                                 (None, 4),                                                       \n",
      "                                 (None, 4)]                                                       \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 152)          15852       ['encoder[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          15300       ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 4)            404         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 4)            404         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 4)           0           ['z_log_var[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 4)            0           ['z_mean[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor (TFOpLamb  (None, 152)         0           ['decoder[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 152)          0           ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 4)            0           ['tf.__operators__.add[0][0]',   \n",
      "                                                                  'tf.math.square[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)       (None, 4)            0           ['z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.squared_difference (TF  (None, 152)         0           ['tf.convert_to_tensor[0][0]',   \n",
      " OpLambda)                                                        'tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 4)           0           ['tf.math.subtract[0][0]',       \n",
      " )                                                                'tf.math.exp[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None,)             0           ['tf.math.squared_difference[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.math.subtract_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.math.multiply[0][0]',       \n",
      " mbda)                                                            'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  ()                  0           ['tf.__operators__.add_1[0][0]'] \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,960\n",
      "Trainable params: 31,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/700\n",
      "13/13 [==============================] - 1s 24ms/step - loss: 66.4071 - val_loss: 54.4230\n",
      "Epoch 2/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 43.5230 - val_loss: 32.0312\n",
      "Epoch 3/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 26.0812 - val_loss: 21.2307\n",
      "Epoch 4/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 19.5392 - val_loss: 18.0488\n",
      "Epoch 5/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 17.2679 - val_loss: 16.7362\n",
      "Epoch 6/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 16.0635 - val_loss: 15.2476\n",
      "Epoch 7/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 14.9329 - val_loss: 14.4370\n",
      "Epoch 8/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 13.8947 - val_loss: 13.3197\n",
      "Epoch 9/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 13.0403 - val_loss: 12.3990\n",
      "Epoch 10/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 12.4312 - val_loss: 12.0639\n",
      "Epoch 11/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 11.9384 - val_loss: 11.3852\n",
      "Epoch 12/700\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 11.6824 - val_loss: 11.3917\n",
      "Epoch 13/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 11.4212 - val_loss: 11.1030\n",
      "Epoch 14/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 11.0458 - val_loss: 10.9794\n",
      "Epoch 15/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 10.9341 - val_loss: 10.7781\n",
      "Epoch 16/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 10.7549 - val_loss: 10.6743\n",
      "Epoch 17/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 10.5428 - val_loss: 10.3200\n",
      "Epoch 18/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 10.5290 - val_loss: 10.4016\n",
      "Epoch 19/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 10.4010 - val_loss: 10.2771\n",
      "Epoch 20/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 10.3284 - val_loss: 10.2024\n",
      "Epoch 21/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 10.2363 - val_loss: 10.0727\n",
      "Epoch 22/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 10.2361 - val_loss: 10.2292\n",
      "Epoch 23/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 10.2066 - val_loss: 10.0567\n",
      "Epoch 24/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 10.1029 - val_loss: 9.8858\n",
      "Epoch 25/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 10.0204 - val_loss: 9.8994\n",
      "Epoch 26/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 10.0698 - val_loss: 9.9446\n",
      "Epoch 27/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 9.9424 - val_loss: 9.8090\n",
      "Epoch 28/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.9865 - val_loss: 9.7159\n",
      "Epoch 29/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.8758 - val_loss: 9.6784\n",
      "Epoch 30/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.8132 - val_loss: 9.7256\n",
      "Epoch 31/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.7804 - val_loss: 9.5974\n",
      "Epoch 32/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.7161 - val_loss: 9.5874\n",
      "Epoch 33/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.7316 - val_loss: 9.7564\n",
      "Epoch 34/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.6699 - val_loss: 9.7441\n",
      "Epoch 35/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.5624 - val_loss: 9.6143\n",
      "Epoch 36/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.6601 - val_loss: 9.5454\n",
      "Epoch 37/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.5987 - val_loss: 9.4038\n",
      "Epoch 38/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 9.5599 - val_loss: 9.3713\n",
      "Epoch 39/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.4955 - val_loss: 9.5288\n",
      "Epoch 40/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.5304 - val_loss: 9.5737\n",
      "Epoch 41/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 9.4837 - val_loss: 9.2305\n",
      "Epoch 42/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.4632 - val_loss: 9.4081\n",
      "Epoch 43/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.3733 - val_loss: 9.4516\n",
      "Epoch 44/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.4475 - val_loss: 9.2544\n",
      "Epoch 45/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.5125 - val_loss: 9.3238\n",
      "Epoch 46/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.4023 - val_loss: 9.2042\n",
      "Epoch 47/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.3540 - val_loss: 9.2072\n",
      "Epoch 48/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2853 - val_loss: 9.1989\n",
      "Epoch 49/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2650 - val_loss: 9.2714\n",
      "Epoch 50/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2956 - val_loss: 9.1649\n",
      "Epoch 51/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1966 - val_loss: 9.1110\n",
      "Epoch 52/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2802 - val_loss: 9.1558\n",
      "Epoch 53/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1922 - val_loss: 9.0235\n",
      "Epoch 54/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2045 - val_loss: 9.2114\n",
      "Epoch 55/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2066 - val_loss: 9.1496\n",
      "Epoch 56/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2204 - val_loss: 9.0986\n",
      "Epoch 57/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.2023 - val_loss: 9.1250\n",
      "Epoch 58/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.2105 - val_loss: 9.1388\n",
      "Epoch 59/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.0932 - val_loss: 9.1621\n",
      "Epoch 60/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.1055 - val_loss: 9.0536\n",
      "Epoch 61/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1262 - val_loss: 9.0095\n",
      "Epoch 62/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.0695 - val_loss: 8.9567\n",
      "Epoch 63/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.1164 - val_loss: 8.9163\n",
      "Epoch 64/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.0759 - val_loss: 8.9231\n",
      "Epoch 65/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.0550 - val_loss: 9.0909\n",
      "Epoch 66/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.9943 - val_loss: 8.9880\n",
      "Epoch 67/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.0596 - val_loss: 8.9799\n",
      "Epoch 68/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 9.0278 - val_loss: 8.8883\n",
      "Epoch 69/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.9723 - val_loss: 8.8010\n",
      "Epoch 70/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 9.0305 - val_loss: 8.8662\n",
      "Epoch 71/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.9561 - val_loss: 9.0524\n",
      "Epoch 72/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.9517 - val_loss: 8.9795\n",
      "Epoch 73/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.9341 - val_loss: 8.7741\n",
      "Epoch 74/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.9123 - val_loss: 8.9319\n",
      "Epoch 75/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.9772 - val_loss: 8.8922\n",
      "Epoch 76/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.9227 - val_loss: 8.8664\n",
      "Epoch 77/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8893 - val_loss: 8.7434\n",
      "Epoch 78/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.9613 - val_loss: 8.8303\n",
      "Epoch 79/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.9078 - val_loss: 8.8323\n",
      "Epoch 80/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8568 - val_loss: 8.7515\n",
      "Epoch 81/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8747 - val_loss: 8.6292\n",
      "Epoch 82/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.9006 - val_loss: 8.8059\n",
      "Epoch 83/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.9411 - val_loss: 8.8262\n",
      "Epoch 84/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.8968 - val_loss: 8.8295\n",
      "Epoch 85/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.8314 - val_loss: 8.7269\n",
      "Epoch 86/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8164 - val_loss: 8.7436\n",
      "Epoch 87/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.8233 - val_loss: 8.8127\n",
      "Epoch 88/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8567 - val_loss: 8.8361\n",
      "Epoch 89/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.8360 - val_loss: 8.8325\n",
      "Epoch 90/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.8046 - val_loss: 8.7304\n",
      "Epoch 91/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.7850 - val_loss: 8.6653\n",
      "Epoch 92/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.7637 - val_loss: 8.7704\n",
      "Epoch 93/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.7704 - val_loss: 8.8087\n",
      "Epoch 94/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.7492 - val_loss: 8.6129\n",
      "Epoch 95/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.7210 - val_loss: 8.8107\n",
      "Epoch 96/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.7580 - val_loss: 8.7420\n",
      "Epoch 97/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.7316 - val_loss: 8.6210\n",
      "Epoch 98/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.7629 - val_loss: 8.6744\n",
      "Epoch 99/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.7638 - val_loss: 8.5627\n",
      "Epoch 100/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.7129 - val_loss: 8.7928\n",
      "Epoch 101/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.7163 - val_loss: 8.6125\n",
      "Epoch 102/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.6438 - val_loss: 8.5892\n",
      "Epoch 103/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.6201 - val_loss: 8.6454\n",
      "Epoch 104/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.7226 - val_loss: 8.7875\n",
      "Epoch 105/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.7339 - val_loss: 8.6498\n",
      "Epoch 106/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.6624 - val_loss: 8.4663\n",
      "Epoch 107/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.6390 - val_loss: 8.6075\n",
      "Epoch 108/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.7040 - val_loss: 8.6428\n",
      "Epoch 109/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.6205 - val_loss: 8.3473\n",
      "Epoch 110/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.6115 - val_loss: 8.6607\n",
      "Epoch 111/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.6540 - val_loss: 8.4544\n",
      "Epoch 112/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.6942 - val_loss: 8.6583\n",
      "Epoch 113/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.6553 - val_loss: 8.4835\n",
      "Epoch 114/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.6438 - val_loss: 8.6561\n",
      "Epoch 115/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.6564 - val_loss: 8.4700\n",
      "Epoch 116/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.6564 - val_loss: 8.6391\n",
      "Epoch 117/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.6394 - val_loss: 8.6377\n",
      "Epoch 118/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.5263 - val_loss: 8.5479\n",
      "Epoch 119/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.5701 - val_loss: 8.4239\n",
      "Epoch 120/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.5330 - val_loss: 8.6868\n",
      "Epoch 121/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.6207 - val_loss: 8.5944\n",
      "Epoch 122/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.6023 - val_loss: 8.5901\n",
      "Epoch 123/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5587 - val_loss: 8.6175\n",
      "Epoch 124/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5275 - val_loss: 8.4136\n",
      "Epoch 125/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5271 - val_loss: 8.3814\n",
      "Epoch 126/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.5266 - val_loss: 8.3826\n",
      "Epoch 127/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5818 - val_loss: 8.5036\n",
      "Epoch 128/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5170 - val_loss: 8.5081\n",
      "Epoch 129/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5332 - val_loss: 8.3904\n",
      "Epoch 130/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.5052 - val_loss: 8.3590\n",
      "Epoch 131/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.4944 - val_loss: 8.3376\n",
      "Epoch 132/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.4937 - val_loss: 8.4323\n",
      "Epoch 133/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5390 - val_loss: 8.4912\n",
      "Epoch 134/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.4944 - val_loss: 8.4777\n",
      "Epoch 135/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.5162 - val_loss: 8.3697\n",
      "Epoch 136/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.4274 - val_loss: 8.3840\n",
      "Epoch 137/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.4529 - val_loss: 8.5384\n",
      "Epoch 138/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3991 - val_loss: 8.2781\n",
      "Epoch 139/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.4950 - val_loss: 8.2914\n",
      "Epoch 140/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.5154 - val_loss: 8.4285\n",
      "Epoch 141/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.5346 - val_loss: 8.3550\n",
      "Epoch 142/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.4815 - val_loss: 8.2428\n",
      "Epoch 143/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.5357 - val_loss: 8.4881\n",
      "Epoch 144/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.4859 - val_loss: 8.4073\n",
      "Epoch 145/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.4701 - val_loss: 8.4273\n",
      "Epoch 146/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.4298 - val_loss: 8.2889\n",
      "Epoch 147/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3977 - val_loss: 8.3909\n",
      "Epoch 148/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.4960 - val_loss: 8.3705\n",
      "Epoch 149/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3950 - val_loss: 8.3185\n",
      "Epoch 150/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3496 - val_loss: 8.3483\n",
      "Epoch 151/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3855 - val_loss: 8.2208\n",
      "Epoch 152/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3818 - val_loss: 8.5341\n",
      "Epoch 153/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.4600 - val_loss: 8.2151\n",
      "Epoch 154/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3107 - val_loss: 8.2558\n",
      "Epoch 155/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3499 - val_loss: 8.3646\n",
      "Epoch 156/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.3956 - val_loss: 8.2021\n",
      "Epoch 157/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.4024 - val_loss: 8.2020\n",
      "Epoch 158/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3247 - val_loss: 8.3619\n",
      "Epoch 159/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.3651 - val_loss: 8.2629\n",
      "Epoch 160/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3467 - val_loss: 8.3067\n",
      "Epoch 161/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3176 - val_loss: 8.2446\n",
      "Epoch 162/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2928 - val_loss: 8.2494\n",
      "Epoch 163/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2470 - val_loss: 8.2787\n",
      "Epoch 164/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3634 - val_loss: 8.2745\n",
      "Epoch 165/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.3595 - val_loss: 8.4491\n",
      "Epoch 166/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.3286 - val_loss: 8.2053\n",
      "Epoch 167/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2837 - val_loss: 8.3566\n",
      "Epoch 168/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2593 - val_loss: 8.2993\n",
      "Epoch 169/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.2777 - val_loss: 8.1055\n",
      "Epoch 170/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2689 - val_loss: 8.1768\n",
      "Epoch 171/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3101 - val_loss: 8.2387\n",
      "Epoch 172/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1846 - val_loss: 8.2015\n",
      "Epoch 173/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2948 - val_loss: 8.0954\n",
      "Epoch 174/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3101 - val_loss: 8.2010\n",
      "Epoch 175/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.3016 - val_loss: 8.3349\n",
      "Epoch 176/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.2872 - val_loss: 8.3104\n",
      "Epoch 177/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.2583 - val_loss: 8.1967\n",
      "Epoch 178/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.2246 - val_loss: 8.1752\n",
      "Epoch 179/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2284 - val_loss: 8.1692\n",
      "Epoch 180/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2489 - val_loss: 8.1692\n",
      "Epoch 181/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2496 - val_loss: 8.0772\n",
      "Epoch 182/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.1770 - val_loss: 8.1447\n",
      "Epoch 183/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1596 - val_loss: 8.0895\n",
      "Epoch 184/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2028 - val_loss: 8.1594\n",
      "Epoch 185/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2315 - val_loss: 8.3425\n",
      "Epoch 186/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.1843 - val_loss: 8.2165\n",
      "Epoch 187/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.2446 - val_loss: 8.1421\n",
      "Epoch 188/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2166 - val_loss: 8.0369\n",
      "Epoch 189/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.2884 - val_loss: 8.0027\n",
      "Epoch 190/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2425 - val_loss: 8.2126\n",
      "Epoch 191/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1421 - val_loss: 8.1973\n",
      "Epoch 192/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2055 - val_loss: 8.2129\n",
      "Epoch 193/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.2010 - val_loss: 8.1128\n",
      "Epoch 194/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.1761 - val_loss: 8.1952\n",
      "Epoch 195/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 8.1226 - val_loss: 8.1489\n",
      "Epoch 196/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.1088 - val_loss: 8.0806\n",
      "Epoch 197/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1493 - val_loss: 8.0991\n",
      "Epoch 198/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.1816 - val_loss: 8.2765\n",
      "Epoch 199/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1177 - val_loss: 8.0766\n",
      "Epoch 200/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1712 - val_loss: 7.9616\n",
      "Epoch 201/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1473 - val_loss: 8.1452\n",
      "Epoch 202/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.1316 - val_loss: 8.1629\n",
      "Epoch 203/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1170 - val_loss: 8.1235\n",
      "Epoch 204/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.1325 - val_loss: 8.1446\n",
      "Epoch 205/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0755 - val_loss: 8.1213\n",
      "Epoch 206/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.1099 - val_loss: 8.1091\n",
      "Epoch 207/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.1242 - val_loss: 8.0616\n",
      "Epoch 208/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0880 - val_loss: 8.0806\n",
      "Epoch 209/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0917 - val_loss: 8.0116\n",
      "Epoch 210/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0784 - val_loss: 8.0734\n",
      "Epoch 211/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.0403 - val_loss: 8.1047\n",
      "Epoch 212/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0562 - val_loss: 8.1364\n",
      "Epoch 213/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.0839 - val_loss: 7.9116\n",
      "Epoch 214/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.1501 - val_loss: 8.1195\n",
      "Epoch 215/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0895 - val_loss: 8.1067\n",
      "Epoch 216/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0778 - val_loss: 7.9734\n",
      "Epoch 217/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.0516 - val_loss: 7.9686\n",
      "Epoch 218/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0613 - val_loss: 8.1463\n",
      "Epoch 219/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0280 - val_loss: 8.0035\n",
      "Epoch 220/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0170 - val_loss: 8.0110\n",
      "Epoch 221/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0113 - val_loss: 8.0176\n",
      "Epoch 222/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0655 - val_loss: 8.0469\n",
      "Epoch 223/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.0310 - val_loss: 7.9248\n",
      "Epoch 224/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.0172 - val_loss: 8.0267\n",
      "Epoch 225/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0340 - val_loss: 8.0614\n",
      "Epoch 226/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 8.0460 - val_loss: 8.0505\n",
      "Epoch 227/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.9894 - val_loss: 7.9514\n",
      "Epoch 228/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0393 - val_loss: 7.9741\n",
      "Epoch 229/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9823 - val_loss: 8.1336\n",
      "Epoch 230/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.0416 - val_loss: 8.0388\n",
      "Epoch 231/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0199 - val_loss: 8.1785\n",
      "Epoch 232/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0893 - val_loss: 7.9435\n",
      "Epoch 233/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.0313 - val_loss: 7.8799\n",
      "Epoch 234/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9622 - val_loss: 7.9972\n",
      "Epoch 235/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0122 - val_loss: 7.9312\n",
      "Epoch 236/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 8.0279 - val_loss: 7.7462\n",
      "Epoch 237/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9842 - val_loss: 7.9821\n",
      "Epoch 238/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9850 - val_loss: 7.8490\n",
      "Epoch 239/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 8.0273 - val_loss: 8.0257\n",
      "Epoch 240/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9452 - val_loss: 7.9139\n",
      "Epoch 241/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9467 - val_loss: 7.8769\n",
      "Epoch 242/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.9911 - val_loss: 8.1788\n",
      "Epoch 243/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.9684 - val_loss: 8.1367\n",
      "Epoch 244/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9887 - val_loss: 8.0004\n",
      "Epoch 245/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9658 - val_loss: 7.9254\n",
      "Epoch 246/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.9483 - val_loss: 8.1217\n",
      "Epoch 247/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9391 - val_loss: 7.7006\n",
      "Epoch 248/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9084 - val_loss: 7.7617\n",
      "Epoch 249/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9546 - val_loss: 8.0382\n",
      "Epoch 250/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.9309 - val_loss: 7.8204\n",
      "Epoch 251/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.9228 - val_loss: 7.7944\n",
      "Epoch 252/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9009 - val_loss: 7.7868\n",
      "Epoch 253/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8818 - val_loss: 7.8550\n",
      "Epoch 254/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.9367 - val_loss: 7.9465\n",
      "Epoch 255/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8950 - val_loss: 7.9514\n",
      "Epoch 256/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9064 - val_loss: 7.8852\n",
      "Epoch 257/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.9386 - val_loss: 7.9017\n",
      "Epoch 258/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8915 - val_loss: 7.9112\n",
      "Epoch 259/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8955 - val_loss: 7.8633\n",
      "Epoch 260/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8752 - val_loss: 7.9204\n",
      "Epoch 261/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.8894 - val_loss: 7.8323\n",
      "Epoch 262/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8894 - val_loss: 8.0222\n",
      "Epoch 263/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7879 - val_loss: 7.8615\n",
      "Epoch 264/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8476 - val_loss: 7.9353\n",
      "Epoch 265/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.8457 - val_loss: 8.0127\n",
      "Epoch 266/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9205 - val_loss: 7.9578\n",
      "Epoch 267/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8393 - val_loss: 7.9729\n",
      "Epoch 268/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8925 - val_loss: 7.7667\n",
      "Epoch 269/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9126 - val_loss: 8.0204\n",
      "Epoch 270/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.8635 - val_loss: 7.7629\n",
      "Epoch 271/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8830 - val_loss: 7.7722\n",
      "Epoch 272/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8972 - val_loss: 7.7794\n",
      "Epoch 273/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.8922 - val_loss: 7.8851\n",
      "Epoch 274/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.8580 - val_loss: 7.8029\n",
      "Epoch 275/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8614 - val_loss: 7.7559\n",
      "Epoch 276/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7840 - val_loss: 7.7365\n",
      "Epoch 277/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8398 - val_loss: 7.7729\n",
      "Epoch 278/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.9292 - val_loss: 7.7586\n",
      "Epoch 279/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.8070 - val_loss: 7.8322\n",
      "Epoch 280/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7831 - val_loss: 7.8567\n",
      "Epoch 281/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8226 - val_loss: 7.7988\n",
      "Epoch 282/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8531 - val_loss: 7.8669\n",
      "Epoch 283/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.8022 - val_loss: 7.6417\n",
      "Epoch 284/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8731 - val_loss: 7.9920\n",
      "Epoch 285/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8368 - val_loss: 7.8328\n",
      "Epoch 286/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.8007 - val_loss: 7.7924\n",
      "Epoch 287/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.8465 - val_loss: 7.7195\n",
      "Epoch 288/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7677 - val_loss: 7.9521\n",
      "Epoch 289/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7945 - val_loss: 7.7596\n",
      "Epoch 290/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7904 - val_loss: 7.7193\n",
      "Epoch 291/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7810 - val_loss: 7.8673\n",
      "Epoch 292/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.8145 - val_loss: 7.7142\n",
      "Epoch 293/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7698 - val_loss: 7.8521\n",
      "Epoch 294/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7647 - val_loss: 7.8032\n",
      "Epoch 295/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7545 - val_loss: 7.8428\n",
      "Epoch 296/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7971 - val_loss: 7.7209\n",
      "Epoch 297/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.7870 - val_loss: 7.8906\n",
      "Epoch 298/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7871 - val_loss: 7.7020\n",
      "Epoch 299/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7617 - val_loss: 7.7772\n",
      "Epoch 300/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7163 - val_loss: 7.7536\n",
      "Epoch 301/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7903 - val_loss: 7.7128\n",
      "Epoch 302/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7634 - val_loss: 7.6792\n",
      "Epoch 303/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7446 - val_loss: 7.7392\n",
      "Epoch 304/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7826 - val_loss: 7.6790\n",
      "Epoch 305/700\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 7.7522 - val_loss: 7.6566\n",
      "Epoch 306/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.8273 - val_loss: 7.6392\n",
      "Epoch 307/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7759 - val_loss: 7.7794\n",
      "Epoch 308/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7500 - val_loss: 7.7786\n",
      "Epoch 309/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7382 - val_loss: 7.7121\n",
      "Epoch 310/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6991 - val_loss: 7.7378\n",
      "Epoch 311/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6848 - val_loss: 7.6192\n",
      "Epoch 312/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6992 - val_loss: 7.7732\n",
      "Epoch 313/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7313 - val_loss: 7.6786\n",
      "Epoch 314/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7782 - val_loss: 7.9215\n",
      "Epoch 315/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7444 - val_loss: 7.6223\n",
      "Epoch 316/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7052 - val_loss: 7.5964\n",
      "Epoch 317/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.6941 - val_loss: 7.7231\n",
      "Epoch 318/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7967 - val_loss: 7.9279\n",
      "Epoch 319/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7250 - val_loss: 7.8178\n",
      "Epoch 320/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7322 - val_loss: 7.8181\n",
      "Epoch 321/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7196 - val_loss: 7.7553\n",
      "Epoch 322/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7065 - val_loss: 7.6878\n",
      "Epoch 323/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.7687 - val_loss: 7.7000\n",
      "Epoch 324/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7614 - val_loss: 7.6656\n",
      "Epoch 325/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7292 - val_loss: 7.7433\n",
      "Epoch 326/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7365 - val_loss: 7.7668\n",
      "Epoch 327/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6637 - val_loss: 7.6849\n",
      "Epoch 328/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6435 - val_loss: 7.5617\n",
      "Epoch 329/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7114 - val_loss: 7.7718\n",
      "Epoch 330/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7398 - val_loss: 7.6107\n",
      "Epoch 331/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6788 - val_loss: 7.5782\n",
      "Epoch 332/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6966 - val_loss: 7.8151\n",
      "Epoch 333/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7771 - val_loss: 7.6504\n",
      "Epoch 334/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6965 - val_loss: 7.6860\n",
      "Epoch 335/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.7709 - val_loss: 7.5767\n",
      "Epoch 336/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6031 - val_loss: 7.8237\n",
      "Epoch 337/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6844 - val_loss: 7.5974\n",
      "Epoch 338/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6905 - val_loss: 7.5981\n",
      "Epoch 339/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6488 - val_loss: 7.7303\n",
      "Epoch 340/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.6900 - val_loss: 7.5762\n",
      "Epoch 341/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6682 - val_loss: 7.6923\n",
      "Epoch 342/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6482 - val_loss: 7.4607\n",
      "Epoch 343/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6954 - val_loss: 7.6098\n",
      "Epoch 344/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.7130 - val_loss: 7.5977\n",
      "Epoch 345/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.6401 - val_loss: 7.6060\n",
      "Epoch 346/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6414 - val_loss: 7.6674\n",
      "Epoch 347/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6077 - val_loss: 7.6974\n",
      "Epoch 348/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6785 - val_loss: 7.6852\n",
      "Epoch 349/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6171 - val_loss: 7.5839\n",
      "Epoch 350/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.6193 - val_loss: 7.6350\n",
      "Epoch 351/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6718 - val_loss: 7.7617\n",
      "Epoch 352/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6296 - val_loss: 7.5615\n",
      "Epoch 353/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6209 - val_loss: 7.7883\n",
      "Epoch 354/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6753 - val_loss: 7.5676\n",
      "Epoch 355/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.6249 - val_loss: 7.6459\n",
      "Epoch 356/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6321 - val_loss: 7.6025\n",
      "Epoch 357/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5428 - val_loss: 7.7114\n",
      "Epoch 358/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6407 - val_loss: 7.8298\n",
      "Epoch 359/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6177 - val_loss: 7.6836\n",
      "Epoch 360/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6338 - val_loss: 7.6592\n",
      "Epoch 361/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6724 - val_loss: 7.5068\n",
      "Epoch 362/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6442 - val_loss: 7.4639\n",
      "Epoch 363/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5681 - val_loss: 7.7695\n",
      "Epoch 364/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6347 - val_loss: 7.5112\n",
      "Epoch 365/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6143 - val_loss: 7.4322\n",
      "Epoch 366/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5992 - val_loss: 7.6979\n",
      "Epoch 367/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5411 - val_loss: 7.6934\n",
      "Epoch 368/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6322 - val_loss: 7.5155\n",
      "Epoch 369/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.5760 - val_loss: 7.6581\n",
      "Epoch 370/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6339 - val_loss: 7.6073\n",
      "Epoch 371/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.6220 - val_loss: 7.6263\n",
      "Epoch 372/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6030 - val_loss: 7.5730\n",
      "Epoch 373/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6446 - val_loss: 7.6406\n",
      "Epoch 374/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5821 - val_loss: 7.5210\n",
      "Epoch 375/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5920 - val_loss: 7.6577\n",
      "Epoch 376/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5857 - val_loss: 7.5451\n",
      "Epoch 377/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6284 - val_loss: 7.5813\n",
      "Epoch 378/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.6276 - val_loss: 7.6230\n",
      "Epoch 379/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5654 - val_loss: 7.4602\n",
      "Epoch 380/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5281 - val_loss: 7.4163\n",
      "Epoch 381/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5766 - val_loss: 7.5689\n",
      "Epoch 382/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5193 - val_loss: 7.5734\n",
      "Epoch 383/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5868 - val_loss: 7.6192\n",
      "Epoch 384/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5845 - val_loss: 7.7081\n",
      "Epoch 385/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5947 - val_loss: 7.6644\n",
      "Epoch 386/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5479 - val_loss: 7.5374\n",
      "Epoch 387/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5967 - val_loss: 7.5321\n",
      "Epoch 388/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5359 - val_loss: 7.6574\n",
      "Epoch 389/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5944 - val_loss: 7.7051\n",
      "Epoch 390/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6250 - val_loss: 7.5712\n",
      "Epoch 391/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.5562 - val_loss: 7.5746\n",
      "Epoch 392/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5484 - val_loss: 7.4070\n",
      "Epoch 393/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.6227 - val_loss: 7.5452\n",
      "Epoch 394/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5540 - val_loss: 7.5088\n",
      "Epoch 395/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5873 - val_loss: 7.4989\n",
      "Epoch 396/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6083 - val_loss: 7.7328\n",
      "Epoch 397/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5537 - val_loss: 7.5614\n",
      "Epoch 398/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.6035 - val_loss: 7.6484\n",
      "Epoch 399/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5692 - val_loss: 7.5884\n",
      "Epoch 400/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5891 - val_loss: 7.7229\n",
      "Epoch 401/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5320 - val_loss: 7.4677\n",
      "Epoch 402/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5842 - val_loss: 7.4426\n",
      "Epoch 403/700\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 7.5613 - val_loss: 7.5011\n",
      "Epoch 404/700\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 7.5495 - val_loss: 7.4949\n",
      "Epoch 405/700\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 7.5822 - val_loss: 7.6066\n",
      "Epoch 406/700\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 7.5539 - val_loss: 7.5152\n",
      "Epoch 407/700\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 7.5357 - val_loss: 7.6192\n",
      "Epoch 408/700\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 7.5478 - val_loss: 7.4381\n",
      "Epoch 409/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.5526 - val_loss: 7.5951\n",
      "Epoch 410/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5510 - val_loss: 7.5124\n",
      "Epoch 411/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5661 - val_loss: 7.5086\n",
      "Epoch 412/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5558 - val_loss: 7.5567\n",
      "Epoch 413/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5755 - val_loss: 7.5877\n",
      "Epoch 414/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5134 - val_loss: 7.4615\n",
      "Epoch 415/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5597 - val_loss: 7.5331\n",
      "Epoch 416/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.5401 - val_loss: 7.5620\n",
      "Epoch 417/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5034 - val_loss: 7.4635\n",
      "Epoch 418/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5286 - val_loss: 7.4880\n",
      "Epoch 419/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5878 - val_loss: 7.4908\n",
      "Epoch 420/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5210 - val_loss: 7.4928\n",
      "Epoch 421/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5310 - val_loss: 7.4226\n",
      "Epoch 422/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4998 - val_loss: 7.7094\n",
      "Epoch 423/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5355 - val_loss: 7.5555\n",
      "Epoch 424/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.5333 - val_loss: 7.3849\n",
      "Epoch 425/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4845 - val_loss: 7.5009\n",
      "Epoch 426/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5271 - val_loss: 7.5761\n",
      "Epoch 427/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5517 - val_loss: 7.6249\n",
      "Epoch 428/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4956 - val_loss: 7.4434\n",
      "Epoch 429/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5945 - val_loss: 7.6256\n",
      "Epoch 430/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5115 - val_loss: 7.4724\n",
      "Epoch 431/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5648 - val_loss: 7.5441\n",
      "Epoch 432/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5131 - val_loss: 7.6371\n",
      "Epoch 433/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.5856 - val_loss: 7.5355\n",
      "Epoch 434/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.5437 - val_loss: 7.5540\n",
      "Epoch 435/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4645 - val_loss: 7.4907\n",
      "Epoch 436/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4975 - val_loss: 7.4921\n",
      "Epoch 437/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5084 - val_loss: 7.4512\n",
      "Epoch 438/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4431 - val_loss: 7.4772\n",
      "Epoch 439/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4774 - val_loss: 7.4855\n",
      "Epoch 440/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5039 - val_loss: 7.4074\n",
      "Epoch 441/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4904 - val_loss: 7.3823\n",
      "Epoch 442/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4568 - val_loss: 7.6544\n",
      "Epoch 443/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4552 - val_loss: 7.5414\n",
      "Epoch 444/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5322 - val_loss: 7.3859\n",
      "Epoch 445/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5070 - val_loss: 7.4525\n",
      "Epoch 446/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4702 - val_loss: 7.3504\n",
      "Epoch 447/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.4671 - val_loss: 7.3700\n",
      "Epoch 448/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5107 - val_loss: 7.3852\n",
      "Epoch 449/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4830 - val_loss: 7.4810\n",
      "Epoch 450/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4396 - val_loss: 7.6009\n",
      "Epoch 451/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4639 - val_loss: 7.4577\n",
      "Epoch 452/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4920 - val_loss: 7.4720\n",
      "Epoch 453/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4862 - val_loss: 7.4047\n",
      "Epoch 454/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5099 - val_loss: 7.4737\n",
      "Epoch 455/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5116 - val_loss: 7.4080\n",
      "Epoch 456/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4741 - val_loss: 7.4558\n",
      "Epoch 457/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4920 - val_loss: 7.3699\n",
      "Epoch 458/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4633 - val_loss: 7.5811\n",
      "Epoch 459/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4703 - val_loss: 7.5694\n",
      "Epoch 460/700\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 7.4844 - val_loss: 7.5471\n",
      "Epoch 461/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4428 - val_loss: 7.5179\n",
      "Epoch 462/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4113 - val_loss: 7.3682\n",
      "Epoch 463/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4406 - val_loss: 7.3031\n",
      "Epoch 464/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4521 - val_loss: 7.3959\n",
      "Epoch 465/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4857 - val_loss: 7.2746\n",
      "Epoch 466/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4937 - val_loss: 7.6134\n",
      "Epoch 467/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4555 - val_loss: 7.4321\n",
      "Epoch 468/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4220 - val_loss: 7.4419\n",
      "Epoch 469/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4627 - val_loss: 7.3548\n",
      "Epoch 470/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4179 - val_loss: 7.5323\n",
      "Epoch 471/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4762 - val_loss: 7.5190\n",
      "Epoch 472/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4492 - val_loss: 7.6294\n",
      "Epoch 473/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4285 - val_loss: 7.3681\n",
      "Epoch 474/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4911 - val_loss: 7.6184\n",
      "Epoch 475/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4569 - val_loss: 7.4959\n",
      "Epoch 476/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4635 - val_loss: 7.4265\n",
      "Epoch 477/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4843 - val_loss: 7.4248\n",
      "Epoch 478/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4203 - val_loss: 7.4661\n",
      "Epoch 479/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4871 - val_loss: 7.4410\n",
      "Epoch 480/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4439 - val_loss: 7.4076\n",
      "Epoch 481/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5194 - val_loss: 7.4867\n",
      "Epoch 482/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4154 - val_loss: 7.4437\n",
      "Epoch 483/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4587 - val_loss: 7.3353\n",
      "Epoch 484/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.5068 - val_loss: 7.5725\n",
      "Epoch 485/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4781 - val_loss: 7.3318\n",
      "Epoch 486/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4565 - val_loss: 7.3673\n",
      "Epoch 487/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4039 - val_loss: 7.3970\n",
      "Epoch 488/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4920 - val_loss: 7.4039\n",
      "Epoch 489/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4202 - val_loss: 7.4866\n",
      "Epoch 490/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4273 - val_loss: 7.4108\n",
      "Epoch 491/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4617 - val_loss: 7.4403\n",
      "Epoch 492/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4436 - val_loss: 7.5303\n",
      "Epoch 493/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4734 - val_loss: 7.6166\n",
      "Epoch 494/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4106 - val_loss: 7.4043\n",
      "Epoch 495/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4971 - val_loss: 7.4088\n",
      "Epoch 496/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.5707 - val_loss: 7.5057\n",
      "Epoch 497/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4080 - val_loss: 7.5623\n",
      "Epoch 498/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4898 - val_loss: 7.4024\n",
      "Epoch 499/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3777 - val_loss: 7.4270\n",
      "Epoch 500/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4881 - val_loss: 7.2887\n",
      "Epoch 501/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3970 - val_loss: 7.3343\n",
      "Epoch 502/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3832 - val_loss: 7.3334\n",
      "Epoch 503/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4293 - val_loss: 7.5755\n",
      "Epoch 504/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4343 - val_loss: 7.2895\n",
      "Epoch 505/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4543 - val_loss: 7.4088\n",
      "Epoch 506/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4175 - val_loss: 7.2590\n",
      "Epoch 507/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4123 - val_loss: 7.3716\n",
      "Epoch 508/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4188 - val_loss: 7.3893\n",
      "Epoch 509/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4784 - val_loss: 7.3602\n",
      "Epoch 510/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3788 - val_loss: 7.2330\n",
      "Epoch 511/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4350 - val_loss: 7.4831\n",
      "Epoch 512/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4218 - val_loss: 7.4533\n",
      "Epoch 513/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3790 - val_loss: 7.5999\n",
      "Epoch 514/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3992 - val_loss: 7.4285\n",
      "Epoch 515/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4303 - val_loss: 7.3482\n",
      "Epoch 516/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4000 - val_loss: 7.4897\n",
      "Epoch 517/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4679 - val_loss: 7.3568\n",
      "Epoch 518/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.3870 - val_loss: 7.3706\n",
      "Epoch 519/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4148 - val_loss: 7.4827\n",
      "Epoch 520/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4087 - val_loss: 7.3023\n",
      "Epoch 521/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4109 - val_loss: 7.3663\n",
      "Epoch 522/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3141 - val_loss: 7.4144\n",
      "Epoch 523/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4090 - val_loss: 7.4236\n",
      "Epoch 524/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4740 - val_loss: 7.3269\n",
      "Epoch 525/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3757 - val_loss: 7.3926\n",
      "Epoch 526/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4128 - val_loss: 7.4734\n",
      "Epoch 527/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4038 - val_loss: 7.4787\n",
      "Epoch 528/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3758 - val_loss: 7.3425\n",
      "Epoch 529/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3657 - val_loss: 7.4500\n",
      "Epoch 530/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4490 - val_loss: 7.4088\n",
      "Epoch 531/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4227 - val_loss: 7.3749\n",
      "Epoch 532/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3524 - val_loss: 7.4042\n",
      "Epoch 533/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3744 - val_loss: 7.4553\n",
      "Epoch 534/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3918 - val_loss: 7.4394\n",
      "Epoch 535/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3273 - val_loss: 7.3121\n",
      "Epoch 536/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3928 - val_loss: 7.4112\n",
      "Epoch 537/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4482 - val_loss: 7.3094\n",
      "Epoch 538/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4338 - val_loss: 7.4339\n",
      "Epoch 539/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4251 - val_loss: 7.4965\n",
      "Epoch 540/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4468 - val_loss: 7.4519\n",
      "Epoch 541/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4001 - val_loss: 7.4010\n",
      "Epoch 542/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3994 - val_loss: 7.3756\n",
      "Epoch 543/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3869 - val_loss: 7.3679\n",
      "Epoch 544/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3595 - val_loss: 7.3455\n",
      "Epoch 545/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3944 - val_loss: 7.2865\n",
      "Epoch 546/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3777 - val_loss: 7.4070\n",
      "Epoch 547/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4458 - val_loss: 7.3348\n",
      "Epoch 548/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3656 - val_loss: 7.4308\n",
      "Epoch 549/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3967 - val_loss: 7.3812\n",
      "Epoch 550/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4151 - val_loss: 7.5098\n",
      "Epoch 551/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3760 - val_loss: 7.3608\n",
      "Epoch 552/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3638 - val_loss: 7.3505\n",
      "Epoch 553/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3095 - val_loss: 7.2727\n",
      "Epoch 554/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3307 - val_loss: 7.3275\n",
      "Epoch 555/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3520 - val_loss: 7.3995\n",
      "Epoch 556/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4056 - val_loss: 7.3835\n",
      "Epoch 557/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3942 - val_loss: 7.2979\n",
      "Epoch 558/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3780 - val_loss: 7.2482\n",
      "Epoch 559/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3626 - val_loss: 7.2724\n",
      "Epoch 560/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3602 - val_loss: 7.3087\n",
      "Epoch 561/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3998 - val_loss: 7.3399\n",
      "Epoch 562/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3957 - val_loss: 7.3808\n",
      "Epoch 563/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3558 - val_loss: 7.3770\n",
      "Epoch 564/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3820 - val_loss: 7.2710\n",
      "Epoch 565/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4200 - val_loss: 7.2663\n",
      "Epoch 566/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3689 - val_loss: 7.3358\n",
      "Epoch 567/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4213 - val_loss: 7.4077\n",
      "Epoch 568/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.4004 - val_loss: 7.3296\n",
      "Epoch 569/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3548 - val_loss: 7.2233\n",
      "Epoch 570/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3896 - val_loss: 7.3993\n",
      "Epoch 571/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4032 - val_loss: 7.3729\n",
      "Epoch 572/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3604 - val_loss: 7.4235\n",
      "Epoch 573/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3720 - val_loss: 7.3747\n",
      "Epoch 574/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3591 - val_loss: 7.4752\n",
      "Epoch 575/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3653 - val_loss: 7.3532\n",
      "Epoch 576/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3837 - val_loss: 7.3562\n",
      "Epoch 577/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3989 - val_loss: 7.2944\n",
      "Epoch 578/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3624 - val_loss: 7.3962\n",
      "Epoch 579/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3294 - val_loss: 7.4314\n",
      "Epoch 580/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3449 - val_loss: 7.2720\n",
      "Epoch 581/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.4149 - val_loss: 7.1585\n",
      "Epoch 582/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3415 - val_loss: 7.3560\n",
      "Epoch 583/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3458 - val_loss: 7.2234\n",
      "Epoch 584/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3794 - val_loss: 7.3426\n",
      "Epoch 585/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3992 - val_loss: 7.4254\n",
      "Epoch 586/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3889 - val_loss: 7.2746\n",
      "Epoch 587/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4013 - val_loss: 7.2097\n",
      "Epoch 588/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3480 - val_loss: 7.3787\n",
      "Epoch 589/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3414 - val_loss: 7.3311\n",
      "Epoch 590/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3662 - val_loss: 7.3104\n",
      "Epoch 591/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.3456 - val_loss: 7.3909\n",
      "Epoch 592/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3478 - val_loss: 7.2885\n",
      "Epoch 593/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3010 - val_loss: 7.3373\n",
      "Epoch 594/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3670 - val_loss: 7.3099\n",
      "Epoch 595/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3353 - val_loss: 7.3182\n",
      "Epoch 596/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3457 - val_loss: 7.2834\n",
      "Epoch 597/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3833 - val_loss: 7.2997\n",
      "Epoch 598/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3558 - val_loss: 7.3696\n",
      "Epoch 599/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4011 - val_loss: 7.2929\n",
      "Epoch 600/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3696 - val_loss: 7.2792\n",
      "Epoch 601/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.2870 - val_loss: 7.2616\n",
      "Epoch 602/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3203 - val_loss: 7.2305\n",
      "Epoch 603/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3416 - val_loss: 7.2694\n",
      "Epoch 604/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4008 - val_loss: 7.3615\n",
      "Epoch 605/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3817 - val_loss: 7.3880\n",
      "Epoch 606/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3241 - val_loss: 7.3889\n",
      "Epoch 607/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2646 - val_loss: 7.2524\n",
      "Epoch 608/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3353 - val_loss: 7.4887\n",
      "Epoch 609/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2616 - val_loss: 7.3724\n",
      "Epoch 610/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3146 - val_loss: 7.3441\n",
      "Epoch 611/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3568 - val_loss: 7.5413\n",
      "Epoch 612/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3443 - val_loss: 7.3744\n",
      "Epoch 613/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3415 - val_loss: 7.4618\n",
      "Epoch 614/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3260 - val_loss: 7.4776\n",
      "Epoch 615/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3507 - val_loss: 7.2849\n",
      "Epoch 616/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3271 - val_loss: 7.5040\n",
      "Epoch 617/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.4184 - val_loss: 7.3163\n",
      "Epoch 618/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3484 - val_loss: 7.2495\n",
      "Epoch 619/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3101 - val_loss: 7.1290\n",
      "Epoch 620/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3602 - val_loss: 7.2613\n",
      "Epoch 621/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3143 - val_loss: 7.3358\n",
      "Epoch 622/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3483 - val_loss: 7.2246\n",
      "Epoch 623/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3499 - val_loss: 7.3625\n",
      "Epoch 624/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3702 - val_loss: 7.3749\n",
      "Epoch 625/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3194 - val_loss: 7.2429\n",
      "Epoch 626/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2870 - val_loss: 7.2972\n",
      "Epoch 627/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3751 - val_loss: 7.4747\n",
      "Epoch 628/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3068 - val_loss: 7.2137\n",
      "Epoch 629/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3439 - val_loss: 7.2768\n",
      "Epoch 630/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3264 - val_loss: 7.2871\n",
      "Epoch 631/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.2958 - val_loss: 7.2172\n",
      "Epoch 632/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3289 - val_loss: 7.3742\n",
      "Epoch 633/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3818 - val_loss: 7.3006\n",
      "Epoch 634/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3708 - val_loss: 7.3267\n",
      "Epoch 635/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3055 - val_loss: 7.2968\n",
      "Epoch 636/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3306 - val_loss: 7.2791\n",
      "Epoch 637/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.2931 - val_loss: 7.4179\n",
      "Epoch 638/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2524 - val_loss: 7.2649\n",
      "Epoch 639/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3160 - val_loss: 7.3277\n",
      "Epoch 640/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.2606 - val_loss: 7.2517\n",
      "Epoch 641/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2967 - val_loss: 7.3065\n",
      "Epoch 642/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3172 - val_loss: 7.2762\n",
      "Epoch 643/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3189 - val_loss: 7.2713\n",
      "Epoch 644/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2871 - val_loss: 7.2861\n",
      "Epoch 645/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3814 - val_loss: 7.2197\n",
      "Epoch 646/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3503 - val_loss: 7.2111\n",
      "Epoch 647/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3095 - val_loss: 7.2569\n",
      "Epoch 648/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2816 - val_loss: 7.2902\n",
      "Epoch 649/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3140 - val_loss: 7.3893\n",
      "Epoch 650/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3173 - val_loss: 7.1993\n",
      "Epoch 651/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2999 - val_loss: 7.3204\n",
      "Epoch 652/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3602 - val_loss: 7.2931\n",
      "Epoch 653/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3094 - val_loss: 7.0959\n",
      "Epoch 654/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3165 - val_loss: 7.3326\n",
      "Epoch 655/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2859 - val_loss: 7.1800\n",
      "Epoch 656/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.2885 - val_loss: 7.2619\n",
      "Epoch 657/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2967 - val_loss: 7.2543\n",
      "Epoch 658/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3163 - val_loss: 7.3005\n",
      "Epoch 659/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2658 - val_loss: 7.4017\n",
      "Epoch 660/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2890 - val_loss: 7.1506\n",
      "Epoch 661/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3219 - val_loss: 7.2807\n",
      "Epoch 662/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3241 - val_loss: 7.3588\n",
      "Epoch 663/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3255 - val_loss: 7.3009\n",
      "Epoch 664/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.2230 - val_loss: 7.1964\n",
      "Epoch 665/700\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 7.2851 - val_loss: 7.1813\n",
      "Epoch 666/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2837 - val_loss: 7.2572\n",
      "Epoch 667/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.2782 - val_loss: 7.1856\n",
      "Epoch 668/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2729 - val_loss: 7.4192\n",
      "Epoch 669/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.3092 - val_loss: 7.3538\n",
      "Epoch 670/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.2984 - val_loss: 7.3173\n",
      "Epoch 671/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.2852 - val_loss: 7.3879\n",
      "Epoch 672/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.2643 - val_loss: 7.2353\n",
      "Epoch 673/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2685 - val_loss: 7.2201\n",
      "Epoch 674/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2822 - val_loss: 7.2771\n",
      "Epoch 675/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3324 - val_loss: 7.4309\n",
      "Epoch 676/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2589 - val_loss: 7.2368\n",
      "Epoch 677/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3378 - val_loss: 7.2652\n",
      "Epoch 678/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3126 - val_loss: 7.2776\n",
      "Epoch 679/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2627 - val_loss: 7.2020\n",
      "Epoch 680/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2708 - val_loss: 7.3663\n",
      "Epoch 681/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.2792 - val_loss: 7.0701\n",
      "Epoch 682/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3049 - val_loss: 7.2910\n",
      "Epoch 683/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2628 - val_loss: 7.2676\n",
      "Epoch 684/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2471 - val_loss: 7.1781\n",
      "Epoch 685/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2683 - val_loss: 7.2060\n",
      "Epoch 686/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3337 - val_loss: 7.2556\n",
      "Epoch 687/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.3147 - val_loss: 7.3764\n",
      "Epoch 688/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2678 - val_loss: 7.3174\n",
      "Epoch 689/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.2127 - val_loss: 7.2129\n",
      "Epoch 690/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2573 - val_loss: 7.2141\n",
      "Epoch 691/700\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 7.2782 - val_loss: 7.2145\n",
      "Epoch 692/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3262 - val_loss: 7.3986\n",
      "Epoch 693/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.3475 - val_loss: 7.1837\n",
      "Epoch 694/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2526 - val_loss: 7.0985\n",
      "Epoch 695/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2844 - val_loss: 7.1662\n",
      "Epoch 696/700\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 7.2472 - val_loss: 7.2140\n",
      "Epoch 697/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2024 - val_loss: 7.2639\n",
      "Epoch 698/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.2545 - val_loss: 7.2905\n",
      "Epoch 699/700\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 7.1894 - val_loss: 7.1897\n",
      "Epoch 700/700\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 7.2916 - val_loss: 7.2947\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    loss = 'mse'\n",
    "    models = (encoder, decoder)\n",
    "    \n",
    "    if loss == 'bce':\n",
    "        reconstruction_loss = binary_crossentropy(inputs,\n",
    "                                                  outputs)\n",
    "    else:\n",
    "        reconstruction_loss = mse(inputs, outputs)\n",
    "        \n",
    "    reconstruction_loss *= start_dimension\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer='adam')\n",
    "    vae.summary()\n",
    "    \n",
    "    vae.fit(X_trainvae,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_valvae, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:22:29.583681Z",
     "iopub.status.busy": "2021-09-10T18:22:29.583402Z",
     "iopub.status.idle": "2021-09-10T18:22:29.922831Z",
     "shell.execute_reply": "2021-09-10T18:22:29.921797Z",
     "shell.execute_reply.started": "2021-09-10T18:22:29.583653Z"
    },
    "id": "L3f3EP3GsVw8"
   },
   "outputs": [],
   "source": [
    "def latent_data(vae, data):\n",
    "    encoder, decoder = vae\n",
    "    z_mean, _, _ = encoder.predict(data)\n",
    "    return z_mean\n",
    "LS_train = latent_data(models, TrainData)\n",
    "LS_test = latent_data(models, TestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRWGp6u-sVw-"
   },
   "source": [
    "### MSPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:22:29.925008Z",
     "iopub.status.busy": "2021-09-10T18:22:29.924555Z",
     "iopub.status.idle": "2021-09-10T18:25:12.983984Z",
     "shell.execute_reply": "2021-09-10T18:25:12.983118Z",
     "shell.execute_reply.started": "2021-09-10T18:22:29.924961Z"
    },
    "id": "Qi3g5hSNsVw_"
   },
   "outputs": [],
   "source": [
    "    #def SPOfn(latent_space_im,mino,majo,y_d):\n",
    "       \n",
    "    latent_space_im = LS_train\n",
    "    mino = -1\n",
    "    majo = 1\n",
    "    y_d = y_trn\n",
    "    \n",
    "    nTarget = np.sum(y_d == majo)\n",
    "\n",
    "\n",
    "    posy = y_d == mino\n",
    "    negy = y_d != mino\n",
    "    P = latent_space_im[np.where(posy == True)[0],:]\n",
    "    N = latent_space_im[np.where(negy == True)[0],:]\n",
    "\n",
    "    #print(len(P),len(N))\n",
    "\n",
    "    poscnt = P.shape[0]\n",
    "    NumToGen = nTarget - poscnt\n",
    "    Me  = np.mean((P),axis = 0)\n",
    "    PCov = np.cov(P.T)\n",
    "    \n",
    "    [D,V] = np.linalg.eig(PCov)\n",
    "    #d = [D[x,x] for x in range(D.shape[0])]\n",
    "    d = D\n",
    "    \n",
    "    #d = d.astype(np.float32)\n",
    "    n = P.shape[1] #Feature dimension\n",
    "    idx = d.argsort()[::-1]   \n",
    "    d = d[idx]\n",
    "    V = V[:,idx]\n",
    "    #d = d[0:n+1]\n",
    "    #v = V[:,n::-1]\n",
    "    \n",
    "    \n",
    "\n",
    "    Ind = (d<= 5e-04)\n",
    "\n",
    "    if np.sum(Ind) != 0:\n",
    "        M = (list(Ind).index(True)+1)\n",
    "    else:\n",
    "        M = n\n",
    "        \n",
    "   \n",
    "    PN = np.concatenate((P,N),axis=0)\n",
    "    TCov = np.cov(PN.T)\n",
    "    dT    = np.dot(V.T,np.dot(TCov, V))\n",
    "    dT = [dT[x,x] for x in range(dT.shape[0])]\n",
    "    \n",
    "\n",
    "    #Modify the Eigen spectrum according to a 1-Parameter Model\n",
    "    dMod  = np.zeros((n,1))\n",
    "    Alpha = d[0]* d[M-1]*(M-1) /(d[0] - d[M-1]) #d[0]* d[M-1]*(M-1) /(d[0] - d[M-1])\n",
    "    Beta  = ((M)*d[M-1] - d[0])/(d[0] - d[M-1])\n",
    "        \n",
    " \n",
    "    for i in range(n):\n",
    "        if i<M-1:\n",
    "\n",
    "            dMod[i] = d[i]\n",
    "        else:\n",
    "            dMod[i] = Alpha/(i+1+Beta)\n",
    "            if dMod[i] > dT[i]:\n",
    "                dMod[i] = dT[i]\n",
    "\n",
    "    R = 1.0\n",
    "    d = dMod\n",
    "            \n",
    "    ########################################\n",
    "    \n",
    "    \n",
    "    Rn = M\n",
    "    Un = len(Me) - M\n",
    "    Ptemp = P\n",
    "\n",
    "    MuR = np.zeros((Rn,1)) #mlayer#\n",
    "    SigmaR = np.identity((Rn)) #v_mat #\n",
    "\n",
    "    MuU = np.zeros((Un,1))\n",
    "    SigmaU = np.identity((Un))\n",
    "\n",
    "    SampGen = np.zeros((int(NumToGen*R), len(Me)))\n",
    "    SampSel = np.zeros((int(NumToGen), len(Me)))\n",
    "    Prob    = np.zeros((int(NumToGen*R),1))\n",
    "\n",
    "    cnt = 0\n",
    "    DD = np.sqrt(d)\n",
    "    MuR = MuR.reshape(MuR.shape[0],)\n",
    "    MuU = MuU.reshape(MuU.shape[0],)\n",
    "    \n",
    "    while cnt < int(R*NumToGen):\n",
    "        \n",
    "        \n",
    "        aR =  np.random.multivariate_normal(MuR.T, SigmaR, 1)\n",
    "        #print(aR)\n",
    "        #scipy.stats.multivariate_normal(MuR.T, SigmaR, 1)\n",
    "        tp = multivariate_normal.pdf(aR, MuR, SigmaR) #aR.pdf(1)\n",
    "        #print(tp)\n",
    "\n",
    "        if Un > 0:\n",
    "            aU = np.random.multivariate_normal(MuU, SigmaU, 1)\n",
    "            #scipy.stats.multivariate_normal(MuU, SigmaU, 1)\n",
    "            a = np.multiply(np.concatenate((aR,aU),axis=1).T,DD)   #The vector in Eigen transformed domain;\n",
    "        else:\n",
    "            a = np.multiply(aR.T,DD)\n",
    "            #print(a)\n",
    "\n",
    "        x = np.dot(a.T,V.T)+ Me\n",
    "        #print(x)\n",
    "        #pdb.set_trace()\n",
    "        PDist = np.sqrt(np.sum(np.square((x-P)),axis=1))\n",
    "        NDist = np.sqrt(np.sum(np.square((x-N)),axis=1))\n",
    "\n",
    "        [tmp,ind]  = [np.min(NDist),np.argmin(NDist)]\n",
    "\n",
    "        if np.min(PDist) < tmp:\n",
    "            PPDist = np.sqrt(np.sum(np.square((N[ind,:]-P)),axis=1))\n",
    "            if tmp >= np.min(PPDist) and tmp <= np.max(PPDist):\n",
    "                SampGen[cnt,:] = x\n",
    "                Prob[cnt,0] = tp  \n",
    "                cnt+=1\n",
    "                Ptemp = np.concatenate((Ptemp,SampGen),axis =0)\n",
    "\n",
    "    for i in range (int(R*NumToGen)):\n",
    "        [tmp,ind]  = [np.min(Prob),np.argmin(Prob)]\n",
    "        Prob[ind] =  np.inf\n",
    "        SampSel[i,:] = SampGen[ind,:]\n",
    "\n",
    "    Ynew = SampSel #np.concatenate((SampSel,P),axis = 0)\n",
    "    #Total = np.concatenate((Ynew,N),axis = 0)\n",
    "    \n",
    "    #return Ynew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:25:12.986187Z",
     "iopub.status.busy": "2021-09-10T18:25:12.985382Z",
     "iopub.status.idle": "2021-09-10T18:25:12.994980Z",
     "shell.execute_reply": "2021-09-10T18:25:12.993904Z",
     "shell.execute_reply.started": "2021-09-10T18:25:12.986124Z"
    },
    "id": "wCVKG232sVxB"
   },
   "outputs": [],
   "source": [
    "Datanew = np.concatenate((SampSel,P),axis = 0)\n",
    "Total = np.concatenate((Datanew,N),axis = 0)\n",
    "label = np.zeros((Total.shape[0],))\n",
    "label[0:Datanew.shape[0]] = -1\n",
    "label[Datanew.shape[0]:Total.shape[0]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyGLOD57sVxC"
   },
   "source": [
    "### MLP on SPO latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uP5-2Bq4ErrF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lZQ-T6dDuPv"
   },
   "outputs": [],
   "source": [
    "\n",
    "def metrics_aa_gm(ypred, ytrue):\n",
    "    cm = confusion_matrix(ytrue, ypred)\n",
    "    sum_classes = np.sum(cm, axis=1)\n",
    "    true_pred = np.diagonal(cm)\n",
    "    tp_rate = true_pred/sum_classes\n",
    "    ACSA = np.mean(tp_rate)\n",
    "    GM = np.prod(tp_rate)**(1/cm.shape[0])\n",
    "    return ACSA, GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:25:12.996784Z",
     "iopub.status.busy": "2021-09-10T18:25:12.996474Z",
     "iopub.status.idle": "2021-09-10T18:25:35.415473Z",
     "shell.execute_reply": "2021-09-10T18:25:35.414316Z",
     "shell.execute_reply.started": "2021-09-10T18:25:12.996755Z"
    },
    "id": "U0JYzbaasVxE",
    "outputId": "1e77047d-1cff-4a5c-8f37-2f740d8cd525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941662615459407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    class -1       0.98      0.99      0.98       712\n",
      "     class 1       1.00      1.00      1.00      3402\n",
      "\n",
      "    accuracy                           0.99      4114\n",
      "   macro avg       0.99      0.99      0.99      4114\n",
      "weighted avg       0.99      0.99      0.99      4114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = Total\n",
    "y_trnmlp = label\n",
    "X_test = (LS_test)\n",
    "y_test = (y_test)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_im,random_state=1, test_size=0.1)\n",
    "sc_X = StandardScaler()\n",
    "mm_X = MinMaxScaler(feature_range=(-3,3))\n",
    "X_trainscaled= X_train #mm_X.fit_transform(X_train)\n",
    "X_testscaled= X_test #mm_X.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(batch_size =16,hidden_layer_sizes=(8,16,10,7,),activation=\"tanh\",\n",
    "                    solver = 'sgd',random_state=1,max_iter = 5000,learning_rate_init = 0.0058,\n",
    "                   learning_rate = 'adaptive')\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(4,12,6,5),activation=\"tanh\",learning_rate_init = 0.0008,random_state=1,max_iter = 5000)\n",
    "clf.fit(X_trainscaled, y_trnmlp)\n",
    "y_pred=clf.predict(X_testscaled)\n",
    "print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"-1\",'1'])\n",
    "fig.figure_.suptitle(\"Confusion Matrix for SPO Latent space\")\n",
    "#plt.savefig('ConfusionMatrixoforiginallatentspace.png')\n",
    "#plt.show()\n",
    "target_names = ['class -1', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:25:35.417542Z",
     "iopub.status.busy": "2021-09-10T18:25:35.417085Z",
     "iopub.status.idle": "2021-09-10T18:25:35.429863Z",
     "shell.execute_reply": "2021-09-10T18:25:35.428335Z",
     "shell.execute_reply.started": "2021-09-10T18:25:35.417497Z"
    },
    "id": "wntmKNjAsVxG",
    "outputId": "07aa9eeb-97dc-4093-d9b5-47e73505a4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for VAE-LSSPO technique\n",
      "ACSA = 0.9909199149211634 GM= 0.9909074769952257\n"
     ]
    }
   ],
   "source": [
    "#print('F1score:',f1_score(y_test, y_pred, average='weighted'))\n",
    "#print('The geometric mean is {}'.format(geometric_mean_score(y_test,y_pred)))\n",
    "acsa,gm = metrics_aa_gm(y_pred, y_test)\n",
    "print(\"Metrics for VAE-LSSPO technique\")\n",
    "print('ACSA =',acsa,'GM=',gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-10T18:25:35.434640Z",
     "iopub.status.busy": "2021-09-10T18:25:35.434290Z",
     "iopub.status.idle": "2021-09-10T18:25:35.442036Z",
     "shell.execute_reply": "2021-09-10T18:25:35.440887Z",
     "shell.execute_reply.started": "2021-09-10T18:25:35.434598Z"
    },
    "id": "y8dxoI10sVxI"
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=10,shuffle = True)\n",
    "# print(\"Cross Validation\")\n",
    "\n",
    "# for train_indices, test_indices in kf.split((X_trainscaled)):\n",
    "#     clf.fit(X_trainscaled[train_indices], y_trnmlp[train_indices])\n",
    "#     # print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "#     y_pred=clf.predict(X_testscaled)\n",
    "#     print('F1score:',f1_score(y_test, y_pred, average='weighted'),\"GM: {}\".format(geometric_mean_score(y_test,y_pred)))\n",
    "#     #print('The geometric mean is {}'.format(geometric_mean_score(y_test,y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXLpDFnVev1C"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pcac1nv0J9xY",
    "outputId": "29eefef0-e1a6-4c2c-fb20-a082afed1f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for VAE-LSSPO latent data = 0.3385134427805329\n"
     ]
    }
   ],
   "source": [
    "score_lsspo = silhouette_score(Total, label, metric='l2')\n",
    "print(\"Silhouette score for VAE-LSSPO latent data =\",score_lsspo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-09-10T18:25:35.444183Z",
     "iopub.status.busy": "2021-09-10T18:25:35.443752Z",
     "iopub.status.idle": "2021-09-10T18:25:35.454778Z",
     "shell.execute_reply": "2021-09-10T18:25:35.453981Z",
     "shell.execute_reply.started": "2021-09-10T18:25:35.444139Z"
    },
    "id": "Giq2sAb8sVxK",
    "outputId": "4017a8bc-eb07-47ac-a755-c28953079dd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 210.1985342502594\n"
     ]
    }
   ],
   "source": [
    "print('Time taken:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02fuSoXTCdyb"
   },
   "source": [
    "#### No oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQJRPWxQCi1b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7gowSICsCbTD",
    "outputId": "2c883074-901e-4d32-fbf4-54b66222b558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for VAE latent data = 0.20644955\n"
     ]
    }
   ],
   "source": [
    "score_noOS = silhouette_score(LS_train, y_trn, metric='l2')\n",
    "print(\"Silhouette score for VAE latent data =\",score_noOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufCH2QjXDeFu"
   },
   "source": [
    "##### MLP on latent data without oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "-0ho9_o4DNk6",
    "outputId": "7522e86c-65c4-4ee7-9dae-80d4c6d3e4e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9769081186193486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    class -1       0.98      0.88      0.93       712\n",
      "     class 1       0.98      1.00      0.99      3402\n",
      "\n",
      "    accuracy                           0.98      4114\n",
      "   macro avg       0.98      0.94      0.96      4114\n",
      "weighted avg       0.98      0.98      0.98      4114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = LS_train\n",
    "y_trnmlp = y_trn\n",
    "X_test = (LS_test)\n",
    "y_test = (y_test)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_im,random_state=1, test_size=0.1)\n",
    "sc_X = StandardScaler()\n",
    "mm_X = MinMaxScaler(feature_range=(-3,3))\n",
    "X_trainscaled= X_train #mm_X.fit_transform(X_train)\n",
    "X_testscaled= X_test #mm_X.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(batch_size =16,hidden_layer_sizes=(8,16,10,7,),activation=\"tanh\",\n",
    "                    solver = 'sgd',random_state=1,max_iter = 5000,learning_rate_init = 0.0058,\n",
    "                   learning_rate = 'adaptive')\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(4,12,6,5),activation=\"tanh\",learning_rate_init = 0.0008,random_state=1,max_iter = 5000)\n",
    "clf.fit(X_trainscaled, y_trnmlp)\n",
    "y_pred=clf.predict(X_testscaled)\n",
    "print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"-1\",'1'])\n",
    "fig.figure_.suptitle(\"Confusion Matrix for SPO Latent space\")\n",
    "#plt.savefig('ConfusionMatrixoforiginallatentspace.png')\n",
    "#plt.show()\n",
    "target_names = ['class -1', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEX24vrtDO4Z",
    "outputId": "9b8efb2a-151d-41b0-ded2-f0880141a17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for no oversampling technique\n",
      "ACSA = 0.9393945398939156 GM= 0.9376409480167573\n"
     ]
    }
   ],
   "source": [
    "acsa,gm = metrics_aa_gm(y_pred, y_test)\n",
    "print(\"Metrics for no oversampling technique\")\n",
    "print('ACSA =',acsa,'GM=',gm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdPwjCsnh_wC"
   },
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzlttSK5DSVY"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIBJsx0kiHy2"
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_sm, y_sm = oversample.fit_resample(LS_train, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "d3o62rnjidF3",
    "outputId": "9a4027d3-be5b-4cba-aa7e-3145ca3c842c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9837141468157511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    class -1       0.98      0.93      0.95       712\n",
      "     class 1       0.98      1.00      0.99      3402\n",
      "\n",
      "    accuracy                           0.98      4114\n",
      "   macro avg       0.98      0.96      0.97      4114\n",
      "weighted avg       0.98      0.98      0.98      4114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_sm  \n",
    "y_trnmlp = y_sm\n",
    "X_test = (LS_test)\n",
    "y_test = (y_test)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_im,random_state=1, test_size=0.1)\n",
    "sc_X = StandardScaler()\n",
    "mm_X = MinMaxScaler(feature_range=(-3,3))\n",
    "X_trainscaled= X_train #mm_X.fit_transform(X_train)\n",
    "X_testscaled= X_test #mm_X.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(batch_size =64,hidden_layer_sizes=(8,32,10,7,),activation=\"tanh\",\n",
    "                    solver = 'sgd',random_state=1,max_iter = 5000,learning_rate_init = 0.0058,\n",
    "                   learning_rate = 'adaptive')\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(4,12,6,5),activation=\"tanh\",learning_rate_init = 0.0008,random_state=1,max_iter = 5000)\n",
    "clf.fit(X_trainscaled, y_trnmlp)\n",
    "y_pred=clf.predict(X_testscaled)\n",
    "print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"-1\",'1'])\n",
    "fig.figure_.suptitle(\"Confusion Matrix for SMOTE Latent space\")\n",
    "#plt.savefig('ConfusionMatrixoforiginallatentspace.png')\n",
    "#plt.show()\n",
    "target_names = ['class -1', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nmfVpKwiyPI",
    "outputId": "c36051f2-f4c2-46f8-a587-3cd233a5ded9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for SMOTE technique\n",
      "ACSA = 0.9607232857076802 GM= 0.9600796328772736\n"
     ]
    }
   ],
   "source": [
    "acsa,gm = metrics_aa_gm(y_pred, y_test)\n",
    "print(\"Metrics for SMOTE technique\")\n",
    "print('ACSA =',acsa,'GM=',gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bYokMTnjXD3",
    "outputId": "bd7a2595-7fed-4a89-9ce4-7f9dc333d631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for SMOTE oversampled latent data = 0.23163643\n"
     ]
    }
   ],
   "source": [
    "score_sm = silhouette_score(X_sm, y_sm, metric='l2')\n",
    "print(\"Silhouette score for SMOTE oversampled latent data =\",score_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tS7zvc3vs721"
   },
   "source": [
    "#### ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3RpXOHztAXN"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lf451TvtFUx"
   },
   "outputs": [],
   "source": [
    "oversample = ADASYN()\n",
    "X_adsn, y_adsn = oversample.fit_resample(LS_train, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdhovNW7tdOp",
    "outputId": "4271228d-58aa-4139-9fc0-532cbe46c71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for VAE+ADASYN oversampled data = 0.121660806\n"
     ]
    }
   ],
   "source": [
    "score_adsn = silhouette_score(X_adsn, y_adsn, metric='l2')\n",
    "print(\"Silhouette score for VAE+ADASYN oversampled data =\",score_adsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "OEgfKfxNtmnA",
    "outputId": "0bd447e5-d410-4137-b152-24b3add9e00b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9837141468157511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    class -1       0.98      0.93      0.95       712\n",
      "     class 1       0.98      1.00      0.99      3402\n",
      "\n",
      "    accuracy                           0.98      4114\n",
      "   macro avg       0.98      0.96      0.97      4114\n",
      "weighted avg       0.98      0.98      0.98      4114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_adsn   \n",
    "y_trnmlp = y_adsn\n",
    "X_test = (LS_test)\n",
    "y_test = (y_test)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_im,random_state=1, test_size=0.1)\n",
    "sc_X = StandardScaler()\n",
    "mm_X = MinMaxScaler(feature_range=(-3,3))\n",
    "X_trainscaled= X_train #mm_X.fit_transform(X_train)\n",
    "X_testscaled= X_test #mm_X.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(batch_size =16,hidden_layer_sizes=(8,32,10,7,),activation=\"tanh\",\n",
    "                    solver = 'sgd',random_state=1,max_iter = 5000,learning_rate_init = 0.0058,\n",
    "                   learning_rate = 'adaptive')\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(4,12,6,5),activation=\"tanh\",learning_rate_init = 0.0008,random_state=1,max_iter = 5000)\n",
    "clf.fit(X_trainscaled, y_trnmlp)\n",
    "y_pred=clf.predict(X_testscaled)\n",
    "print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"-1\",'1'])\n",
    "fig.figure_.suptitle(\"Confusion Matrix for ADASYN Latent space\")\n",
    "#plt.savefig('ConfusionMatrixoforiginallatentspace.png')\n",
    "#plt.show()\n",
    "target_names = ['class -1', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-Uhh3FLuNOF",
    "outputId": "d7e7516c-6394-4782-a968-e25dd3da7075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No oversampling - VAE+ADASYN+MLP\n",
      "ACSA = 0.9607232857076802 GM= 0.9600796328772736\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "acsa, gm = metrics_aa_gm(y_pred, y_test) \n",
    "print('No oversampling - VAE+ADASYN+MLP')\n",
    "print( 'ACSA =',acsa,'GM=', gm,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4erNGQprwXa"
   },
   "source": [
    "#### RANDOM SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvFQ_rWNrwIQ"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_rand, y_rand = ros.fit_resample(LS_train, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFGXAbplmMy5",
    "outputId": "435605f7-93f8-4602-87d5-6f837fb35020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for VAE+Random oversampled data = 0.21932627\n"
     ]
    }
   ],
   "source": [
    "score_rand = silhouette_score(X_rand, y_rand, metric='l2')\n",
    "print(\"Silhouette score for VAE+Random oversampled data =\",score_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "11iWwGHtuzKJ",
    "outputId": "53661ded-cf67-4bc9-db82-d147818826fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9844433641225085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    class -1       0.97      0.94      0.95       712\n",
      "     class 1       0.99      0.99      0.99      3402\n",
      "\n",
      "    accuracy                           0.98      4114\n",
      "   macro avg       0.98      0.97      0.97      4114\n",
      "weighted avg       0.98      0.98      0.98      4114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_rand   \n",
    "y_trnmlp = y_rand\n",
    "X_test = (LS_test)\n",
    "y_test = (y_test)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_im,random_state=1, test_size=0.1)\n",
    "sc_X = StandardScaler()\n",
    "mm_X = MinMaxScaler(feature_range=(-3,3))\n",
    "X_trainscaled= X_train #mm_X.fit_transform(X_train)\n",
    "X_testscaled= X_test #mm_X.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(batch_size =16,hidden_layer_sizes=(8,32,10,7,),activation=\"tanh\",\n",
    "                    solver = 'sgd',random_state=1,max_iter = 5000,learning_rate_init = 0.0058,\n",
    "                   learning_rate = 'adaptive')\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(4,12,6,5),activation=\"tanh\",learning_rate_init = 0.0008,random_state=1,max_iter = 5000)\n",
    "clf.fit(X_trainscaled, y_trnmlp)\n",
    "y_pred=clf.predict(X_testscaled)\n",
    "print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"-1\",'1'])\n",
    "fig.figure_.suptitle(\"Confusion Matrix for RANDOM SAMPLED Latent space\")\n",
    "#plt.savefig('ConfusionMatrixoforiginallatentspace.png')\n",
    "#plt.show()\n",
    "target_names = ['class -1', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-XyWzcivbBr",
    "outputId": "df787c7c-b07a-4236-cbb5-e491d2a7865a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No oversampling - VAE+RANDOM+MLP\n",
      "ACSA = 0.9661616762116138 GM= 0.9657570372039114\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "acsa, gm = metrics_aa_gm(y_pred, y_test) \n",
    "print('No oversampling - VAE+RANDOM+MLP')\n",
    "print( 'ACSA =',acsa,'GM=', gm,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Bl8lGoivqoq"
   },
   "source": [
    "#### BORDERLINE SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3gi3muZwA5J"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "X_bos, y_bos = BorderlineSMOTE().fit_resample(LS_train, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxJ3Hy05wVqq",
    "outputId": "dc5b6a05-329a-4337-dc5c-627cba1fffc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for VAE+Borderline SMOTE oversampled data = 0.1418609\n"
     ]
    }
   ],
   "source": [
    "score_bos = silhouette_score(X_bos, y_bos, metric='l2')\n",
    "print(\"Silhouette score for VAE+Borderline SMOTE oversampled data =\",score_bos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "Qf3LRAADwcvs",
    "outputId": "90739be2-dd53-4dc3-e452-f0416c3a68ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9795819154107924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    class -1       0.98      0.90      0.94       712\n",
      "     class 1       0.98      1.00      0.99      3402\n",
      "\n",
      "    accuracy                           0.98      4114\n",
      "   macro avg       0.98      0.95      0.96      4114\n",
      "weighted avg       0.98      0.98      0.98      4114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_bos    \n",
    "y_trnmlp = y_bos\n",
    "X_test = (LS_test)\n",
    "y_test = (y_test)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_im,random_state=1, test_size=0.1)\n",
    "sc_X = StandardScaler()\n",
    "mm_X = MinMaxScaler(feature_range=(-3,3))\n",
    "X_trainscaled= X_train #mm_X.fit_transform(X_train)\n",
    "X_testscaled= X_test #mm_X.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(batch_size =16,hidden_layer_sizes=(8,32,10,7,),activation=\"tanh\",\n",
    "                    solver = 'sgd',random_state=1,max_iter = 5000,learning_rate_init = 0.0058,\n",
    "                   learning_rate = 'adaptive')\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(4,12,6,5),activation=\"tanh\",learning_rate_init = 0.0008,random_state=1,max_iter = 5000)\n",
    "clf.fit(X_trainscaled, y_trnmlp)\n",
    "y_pred=clf.predict(X_testscaled)\n",
    "print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"-1\",'1'])\n",
    "fig.figure_.suptitle(\"Confusion Matrix for BORDERLINE SMOTE SAMPLED Latent space\")\n",
    "#plt.savefig('ConfusionMatrixoforiginallatentspace.png')\n",
    "#plt.show()\n",
    "target_names = ['class -1', 'class 1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ut1AWDbMw8P5",
    "outputId": "97ac6f31-4cf3-4348-d348-81497b5aaeaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No oversampling - VAE+BoS+MLP\n",
      "ACSA = 0.9471192589950392 GM= 0.9458171237127364\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "acsa, gm = metrics_aa_gm(y_pred, y_test) \n",
    "print('No oversampling - VAE+BoS+MLP')\n",
    "print( 'ACSA =',acsa,'GM=', gm,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhmqQTSNxPkM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wafer_lsspo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
