{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "13bd3cbf-9e9b-4af6-946a-f885241d8387",
    "_uuid": "0ec62224-3bbf-46c0-9037-1ec1037793e6",
    "execution": {
     "iopub.execute_input": "2021-09-11T14:22:48.855860Z",
     "iopub.status.busy": "2021-09-11T14:22:48.855525Z",
     "iopub.status.idle": "2021-09-11T14:22:48.870394Z",
     "shell.execute_reply": "2021-09-11T14:22:48.869563Z",
     "shell.execute_reply.started": "2021-09-11T14:22:48.855828Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91948\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Australian Credit Dataset\n",
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "#from pymfe.mfe import MFE\n",
    "import csv\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "#from focal_loss import BinaryFocalLoss\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "import random\n",
    "random.seed(3)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense, Layer\n",
    "#from keras.layers import BatchNormalization,LayerNormalization\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy,categorical_crossentropy,sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten \n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# In[5]:\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('AUS_NEW.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:22:48.872271Z",
     "iopub.status.busy": "2021-09-11T14:22:48.871994Z",
     "iopub.status.idle": "2021-09-11T14:22:51.795577Z",
     "shell.execute_reply": "2021-09-11T14:22:51.794891Z",
     "shell.execute_reply.started": "2021-09-11T14:22:48.872244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 518 samples in 0.002s...\n",
      "[t-SNE] Computed neighbors for 518 samples in 0.026s...\n",
      "[t-SNE] Computed conditional probabilities for sample 518 / 518\n",
      "[t-SNE] Mean sigma: 0.533747\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 58.762047\n",
      "[t-SNE] KL divergence after 1050 iterations: 0.207599\n",
      "t-SNE done! Time elapsed: 2.379697561264038 seconds\n",
      "(236, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[6]:\n",
    "\n",
    "\n",
    "x_train = mat['train_x'] \n",
    "ytrn = mat['train_y'] \n",
    "y_train =  ytrn[:,0]*2+ytrn[:,1]*1\n",
    "\n",
    "x_test = mat['test_x'] \n",
    "ytst = mat['test_y'] \n",
    "y_test =  ytst[:,0]*2+ytst[:,1]*1\n",
    "\n",
    "\n",
    "\n",
    "# ### T-SNE\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=5000)\n",
    "tsne_org = tsne.fit_transform(x_train)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"r\",\"b\"])\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = ['b', 'r']\n",
    "\n",
    "points = tsne_org[y_train ==1]\n",
    "print(points.shape)\n",
    "p2 = plt.scatter(points[:, 0], points[:, 1], marker=('o'), color=colors[0])\n",
    "points = tsne_org[y_train == 2]\n",
    "p1 = plt.scatter(points[:, 0], points[:, 1], marker=('^'), color=colors[1])\n",
    "plt.legend((p2,p1),('Minority','Majority'),loc='upper right')\n",
    "\n",
    "#plt.savefig('Aus_TSNE.png')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "mmscaler    = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#x_train = scaler.fit_transform(x_train)\n",
    "#x_test = scaler.transform(x_test)\n",
    "x_train   = mmscaler.fit_transform(x_train)\n",
    "x_test = mmscaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:22:51.801687Z",
     "iopub.status.busy": "2021-09-11T14:22:51.799663Z",
     "iopub.status.idle": "2021-09-11T14:24:18.786638Z",
     "shell.execute_reply": "2021-09-11T14:24:18.785700Z",
     "shell.execute_reply.started": "2021-09-11T14:22:51.801636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            120         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 5)            45          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 5)            45          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 5)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 210\n",
      "Trainable params: 210\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                126       \n",
      "=================================================================\n",
      "Total params: 174\n",
      "Trainable params: 174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"vae_mlp\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 5), (None, 5 210         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 14)           174         encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            120         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 5)            45          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 5)            45          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 5)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.square (TFOpLambda)     (None, 5)            0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor (TFOpLambd (None, 14)           0           decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 14)           0           encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 5)            0           tf.__operators__.add[0][0]       \n",
      "                                                                 tf.math.square[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 5)            0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.squared_difference (TFO (None, 14)           0           tf.convert_to_tensor[0][0]       \n",
      "                                                                 tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 5)            0           tf.math.subtract[0][0]           \n",
      "                                                                 tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None,)              0           tf.math.squared_difference[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None,)              0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None,)              0           tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None,)              0           tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None,)              0           tf.math.multiply[0][0]           \n",
      "                                                                 tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb ()                   0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              ()                   0           tf.math.reduce_mean_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 384\n",
      "Trainable params: 384\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91948\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 10ms/step - loss: 13.2703 - val_loss: 13.3422\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 13.0170 - val_loss: 13.7212\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 13.2782 - val_loss: 12.5329\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 12.6276 - val_loss: 12.9883\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 12.4078 - val_loss: 12.8214\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 12.3050 - val_loss: 12.7636\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 12.1521 - val_loss: 12.3937\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.9118 - val_loss: 12.3823\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.9717 - val_loss: 12.0455\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 11.7664 - val_loss: 11.9072\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 11.5474 - val_loss: 11.7454\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.5584 - val_loss: 11.7307\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.3731 - val_loss: 11.5428\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.2914 - val_loss: 11.3632\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.2987 - val_loss: 10.8708\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.9017 - val_loss: 11.1201\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 11.0241 - val_loss: 10.9442\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.7753 - val_loss: 10.4481\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.6258 - val_loss: 10.4415\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.6217 - val_loss: 10.1763\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.4626 - val_loss: 10.2161\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.4607 - val_loss: 10.6481\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.2573 - val_loss: 10.0701\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.1234 - val_loss: 10.1767\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.9961 - val_loss: 10.1320\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 10.0941 - val_loss: 10.0927\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.7421 - val_loss: 9.8319\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.9230 - val_loss: 9.8374\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.7453 - val_loss: 9.3367\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 9.7128 - val_loss: 9.4964\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.3610 - val_loss: 9.6406\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.3864 - val_loss: 9.3170\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.4418 - val_loss: 9.5091\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 9.2736 - val_loss: 8.9988\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.1330 - val_loss: 9.6426\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.2373 - val_loss: 8.9978\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.1654 - val_loss: 9.4822\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.0711 - val_loss: 8.8964\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 9.0409 - val_loss: 9.1047\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.9135 - val_loss: 8.9223\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.9805 - val_loss: 9.1237\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.9168 - val_loss: 8.8566\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.7767 - val_loss: 8.4941\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 8.8219 - val_loss: 8.6368\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.7598 - val_loss: 8.6950\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.7040 - val_loss: 8.2775\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.5021 - val_loss: 8.4148\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.5561 - val_loss: 8.5003\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.3681 - val_loss: 8.3221\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.4035 - val_loss: 8.3430\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.5209 - val_loss: 8.0821\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.3391 - val_loss: 7.8274\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.2845 - val_loss: 8.0086\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.3146 - val_loss: 7.9348\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.1404 - val_loss: 8.1187\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.1172 - val_loss: 7.8790\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.0560 - val_loss: 8.0741\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.0452 - val_loss: 7.9401\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.9583 - val_loss: 7.8315\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 7.9728 - val_loss: 7.8125\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.0028 - val_loss: 7.8509\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.8291 - val_loss: 7.8133\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 8.0692 - val_loss: 7.8194\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.8173 - val_loss: 7.7541\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.6923 - val_loss: 7.6988\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 7.7752 - val_loss: 7.6407\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.7938 - val_loss: 7.4819\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.6475 - val_loss: 7.6731\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.6360 - val_loss: 7.5851\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.6204 - val_loss: 7.5912\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.5040 - val_loss: 7.4236\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.5786 - val_loss: 7.2768\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.5689 - val_loss: 7.1819\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.4427 - val_loss: 7.2763\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.4137 - val_loss: 7.3871\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.3433 - val_loss: 7.0711\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.3798 - val_loss: 7.3386\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.4576 - val_loss: 7.2301\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.3758 - val_loss: 7.0207\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.3355 - val_loss: 6.9102\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.1686 - val_loss: 7.0919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 7.2526 - val_loss: 6.9493\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.1160 - val_loss: 6.8977\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.1111 - val_loss: 7.0348\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.1654 - val_loss: 6.9468\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.1295 - val_loss: 6.8861\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 7.2225 - val_loss: 6.9811\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.9235 - val_loss: 6.9060\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.1801 - val_loss: 7.0072\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.0406 - val_loss: 6.7618\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.9355 - val_loss: 6.5910\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.9449 - val_loss: 6.6410\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 7.0421 - val_loss: 6.8529\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9516 - val_loss: 6.5483\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 6.9374 - val_loss: 6.5900\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.8160 - val_loss: 6.5791\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.8968 - val_loss: 6.3904\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.9242 - val_loss: 6.7155\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.8000 - val_loss: 6.6208\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.8223 - val_loss: 6.6599\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.6831 - val_loss: 6.5785\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.7241 - val_loss: 6.4553\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.6516 - val_loss: 6.4783\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.6846 - val_loss: 6.5709\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.7497 - val_loss: 6.3707\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.5536 - val_loss: 6.4112\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.5850 - val_loss: 6.5565\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.6588 - val_loss: 6.4322\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 6.4757 - val_loss: 6.2062\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.6285 - val_loss: 6.3537\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.5378 - val_loss: 6.5005\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.5168 - val_loss: 6.2364\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.5714 - val_loss: 6.2365\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 6.6048 - val_loss: 6.2542\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.4176 - val_loss: 6.2013\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.3897 - val_loss: 6.1256\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.4938 - val_loss: 6.2106\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.3556 - val_loss: 6.2185\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.4953 - val_loss: 6.2573\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.4758 - val_loss: 6.0104\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.4479 - val_loss: 6.3753\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.4024 - val_loss: 6.2602\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.3904 - val_loss: 6.1002\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.3555 - val_loss: 6.0495\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 6.3325 - val_loss: 6.0350\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.3171 - val_loss: 6.2132\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.3301 - val_loss: 5.8612\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.1317 - val_loss: 5.9158\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.3570 - val_loss: 5.7373\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.2087 - val_loss: 5.9827\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.1900 - val_loss: 5.9387\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.2973 - val_loss: 5.9650\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.1008 - val_loss: 5.7273\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.2362 - val_loss: 5.8244\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.2184 - val_loss: 6.0637\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 6.0766 - val_loss: 5.6253\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.0617 - val_loss: 5.8723\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.1408 - val_loss: 5.7053\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.1427 - val_loss: 5.8125\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.1114 - val_loss: 5.8941\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.0943 - val_loss: 5.7208\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.9844 - val_loss: 5.7732\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.0579 - val_loss: 5.7185\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.0862 - val_loss: 5.7519\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.0075 - val_loss: 5.6719\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.0280 - val_loss: 5.7721\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 6.0153 - val_loss: 5.7554\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.9352 - val_loss: 5.5990\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9919 - val_loss: 5.6405\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.9030 - val_loss: 5.6810\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.9780 - val_loss: 5.8025\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.9321 - val_loss: 5.5669\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.9056 - val_loss: 5.5894\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.9881 - val_loss: 5.5179\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.8375 - val_loss: 5.6601\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.9248 - val_loss: 5.5300\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.8567 - val_loss: 5.5408\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.8449 - val_loss: 5.4674\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.8220 - val_loss: 5.5252\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.8193 - val_loss: 5.3648\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.7969 - val_loss: 5.6088\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 5.9027 - val_loss: 5.5311\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8694 - val_loss: 5.4441\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9037 - val_loss: 5.8281\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7764 - val_loss: 5.5443\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7771 - val_loss: 5.6991\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.8512 - val_loss: 5.5815\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7783 - val_loss: 5.4933\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7494 - val_loss: 5.3227\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.7558 - val_loss: 5.3446\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.7346 - val_loss: 5.3566\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.8393 - val_loss: 5.4787\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.8316 - val_loss: 5.4346\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7842 - val_loss: 5.3457\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7643 - val_loss: 5.2085\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5941 - val_loss: 5.3590\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6964 - val_loss: 5.3388\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.7271 - val_loss: 5.4189\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7632 - val_loss: 5.3843\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.6538 - val_loss: 5.4230\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.6704 - val_loss: 5.4584\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5968 - val_loss: 5.2933\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.6743 - val_loss: 5.3542\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.6353 - val_loss: 5.1816\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.6157 - val_loss: 5.3384\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.7828 - val_loss: 5.3804\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5965 - val_loss: 5.3529\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.6103 - val_loss: 5.3090\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6364 - val_loss: 5.2548\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.6513 - val_loss: 5.1591\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5376 - val_loss: 5.1089\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5796 - val_loss: 5.2937\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5075 - val_loss: 5.0487\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5482 - val_loss: 5.4137\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5985 - val_loss: 5.2127\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.6750 - val_loss: 5.1725\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5151 - val_loss: 5.2849\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5351 - val_loss: 5.1371\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5679 - val_loss: 5.0865\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5625 - val_loss: 5.0174\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4579 - val_loss: 5.2503\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4765 - val_loss: 4.9443\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5021 - val_loss: 5.2495\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4949 - val_loss: 4.9670\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4405 - val_loss: 5.0219\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4694 - val_loss: 5.1978\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5553 - val_loss: 4.9601\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5713 - val_loss: 5.1613\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4136 - val_loss: 5.0551\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.5442 - val_loss: 5.0445\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4818 - val_loss: 5.0847\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4283 - val_loss: 5.0046\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5207 - val_loss: 5.0614\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4595 - val_loss: 5.1455\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3681 - val_loss: 5.1840\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3881 - val_loss: 5.1048\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.4460 - val_loss: 4.9007\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4370 - val_loss: 5.3142\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4483 - val_loss: 5.0143\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3979 - val_loss: 5.1109\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4460 - val_loss: 5.2415\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3564 - val_loss: 5.1004\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4198 - val_loss: 4.9966\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4815 - val_loss: 5.1723\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3596 - val_loss: 4.7704\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.4037 - val_loss: 5.1314\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3945 - val_loss: 5.0102\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.3868 - val_loss: 4.9447\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2491 - val_loss: 5.0334\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3309 - val_loss: 5.0600\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3314 - val_loss: 4.9428\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3333 - val_loss: 4.9389\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3835 - val_loss: 5.0341\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.3047 - val_loss: 5.1386\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3859 - val_loss: 4.9004\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3109 - val_loss: 5.0462\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3021 - val_loss: 4.7384\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3087 - val_loss: 5.1160\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2644 - val_loss: 4.9494\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3222 - val_loss: 4.8285\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3435 - val_loss: 5.0353\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2968 - val_loss: 5.0818\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3681 - val_loss: 4.9564\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2950 - val_loss: 4.8130\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2569 - val_loss: 4.9422\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3922 - val_loss: 4.8748\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3204 - val_loss: 4.9341\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.3505 - val_loss: 4.8146\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3258 - val_loss: 4.7979\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3016 - val_loss: 4.7516\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2886 - val_loss: 4.9446\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3290 - val_loss: 4.8643\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.3307 - val_loss: 4.9338\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3077 - val_loss: 5.1241\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2472 - val_loss: 4.8082\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2948 - val_loss: 4.8626\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3520 - val_loss: 4.9829\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 4.984 - 0s 2ms/step - loss: 5.1835 - val_loss: 4.8778\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.2251 - val_loss: 4.8704\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2923 - val_loss: 4.8983\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3170 - val_loss: 5.1105\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2441 - val_loss: 4.9764\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2006 - val_loss: 4.7554\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.2810 - val_loss: 4.9228\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2238 - val_loss: 4.9089\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2468 - val_loss: 4.6589\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1782 - val_loss: 4.8410\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1920 - val_loss: 4.9762\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2324 - val_loss: 5.0479\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1581 - val_loss: 4.7015\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2105 - val_loss: 5.0356\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.3685 - val_loss: 4.6711\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1861 - val_loss: 4.9427\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1898 - val_loss: 4.7608\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.1810 - val_loss: 5.0280\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1695 - val_loss: 4.8241\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1815 - val_loss: 4.8364\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1903 - val_loss: 4.7006\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2043 - val_loss: 4.8348\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1912 - val_loss: 4.8331\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.1913 - val_loss: 4.8231\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2629 - val_loss: 4.8400\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1919 - val_loss: 4.6493\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0969 - val_loss: 4.9217\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2306 - val_loss: 4.8345\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.1882 - val_loss: 4.8508\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1223 - val_loss: 4.8314\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1671 - val_loss: 4.7567\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2351 - val_loss: 4.6977\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1982 - val_loss: 4.6291\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1943 - val_loss: 4.7761\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1469 - val_loss: 4.7835\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2184 - val_loss: 4.7232\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2120 - val_loss: 4.7033\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1088 - val_loss: 4.7112\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1189 - val_loss: 4.5929\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.1159 - val_loss: 4.6996\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1381 - val_loss: 4.8169\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1759 - val_loss: 4.7171\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1878 - val_loss: 4.6728\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1387 - val_loss: 4.7994\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1477 - val_loss: 4.6148\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.1466 - val_loss: 4.6345\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1562 - val_loss: 4.8825\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0752 - val_loss: 4.7108\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1116 - val_loss: 4.7086\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1334 - val_loss: 4.7192\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.1748 - val_loss: 4.6415\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1438 - val_loss: 4.7984\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0882 - val_loss: 4.7792\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1626 - val_loss: 4.7449\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1274 - val_loss: 4.5645\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.2315 - val_loss: 4.7427\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1305 - val_loss: 4.6619\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1495 - val_loss: 4.7196\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0942 - val_loss: 4.9099\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1957 - val_loss: 4.7415\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.1580 - val_loss: 4.5971\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.0852 - val_loss: 4.7726\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1043 - val_loss: 4.6205\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0620 - val_loss: 4.7400\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0607 - val_loss: 4.7009\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0286 - val_loss: 4.7993\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.0025 - val_loss: 4.9169\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0715 - val_loss: 4.5342\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1395 - val_loss: 4.7312\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0936 - val_loss: 4.5874\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0332 - val_loss: 4.6166\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0392 - val_loss: 4.6856\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.0420 - val_loss: 4.7358\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0612 - val_loss: 4.6321\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0685 - val_loss: 4.6944\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1959 - val_loss: 4.8821\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0847 - val_loss: 4.7535\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9608 - val_loss: 4.5549\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1027 - val_loss: 4.6196\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0387 - val_loss: 4.6627\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1339 - val_loss: 4.6609\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1072 - val_loss: 4.7068\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1713 - val_loss: 4.8160\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1344 - val_loss: 4.7231\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0534 - val_loss: 4.5392\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0279 - val_loss: 4.8404\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9998 - val_loss: 4.7259\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0374 - val_loss: 4.5529\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1325 - val_loss: 4.5586\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.0267 - val_loss: 4.6123\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0565 - val_loss: 4.7008\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0262 - val_loss: 4.6345\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9822 - val_loss: 4.6600\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1113 - val_loss: 4.4910\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0426 - val_loss: 4.7489\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0711 - val_loss: 4.7692\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9740 - val_loss: 4.9819\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9535 - val_loss: 4.6581\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0131 - val_loss: 4.6721\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1207 - val_loss: 4.6166\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.0521 - val_loss: 4.4748\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.1293 - val_loss: 4.7247\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0041 - val_loss: 4.7885\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9856 - val_loss: 4.4923\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9580 - val_loss: 4.6369\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 5.0150 - val_loss: 4.5838\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8985 - val_loss: 4.4883\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9620 - val_loss: 4.3770\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9431 - val_loss: 4.5255\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0420 - val_loss: 4.5792\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0176 - val_loss: 4.6322\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0276 - val_loss: 4.6472\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0164 - val_loss: 4.5950\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0205 - val_loss: 4.4835\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9705 - val_loss: 4.6079\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9435 - val_loss: 4.6758\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.9700 - val_loss: 4.5725\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0099 - val_loss: 4.8060\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0464 - val_loss: 4.7201\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0850 - val_loss: 4.5205\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9527 - val_loss: 4.6051\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9612 - val_loss: 4.6972\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8842 - val_loss: 4.6283\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9769 - val_loss: 4.5451\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9664 - val_loss: 4.3717\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9871 - val_loss: 4.7133\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9640 - val_loss: 4.5937\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0724 - val_loss: 4.4780\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9118 - val_loss: 4.4914\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9547 - val_loss: 4.5847\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9689 - val_loss: 4.5554\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9533 - val_loss: 4.6281\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9504 - val_loss: 4.5604\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0480 - val_loss: 4.4989\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8555 - val_loss: 4.6502\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9564 - val_loss: 4.5374\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9918 - val_loss: 4.4101\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9139 - val_loss: 4.4992\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.9744 - val_loss: 4.6476\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9580 - val_loss: 4.5915\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8871 - val_loss: 4.4195\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9666 - val_loss: 4.4759\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0349 - val_loss: 4.5656\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0603 - val_loss: 4.6817\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9430 - val_loss: 4.5890\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9912 - val_loss: 4.5056\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8965 - val_loss: 4.6415\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9190 - val_loss: 4.4183\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9215 - val_loss: 4.4277\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9679 - val_loss: 4.5440\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9968 - val_loss: 4.4835\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.0449 - val_loss: 4.5907\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.9633 - val_loss: 4.5362\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0137 - val_loss: 4.5100\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9249 - val_loss: 4.5464\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9301 - val_loss: 4.5241\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9389 - val_loss: 4.6466\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8524 - val_loss: 4.4624\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9101 - val_loss: 4.5149\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8761 - val_loss: 4.5366\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9842 - val_loss: 4.5000\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9180 - val_loss: 4.4777\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.9679 - val_loss: 4.2796\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9005 - val_loss: 4.4003\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8484 - val_loss: 4.6209\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9747 - val_loss: 4.4751\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9171 - val_loss: 4.5247\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9383 - val_loss: 4.5970\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8596 - val_loss: 4.5663\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9215 - val_loss: 4.5054\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8755 - val_loss: 4.5980\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9016 - val_loss: 4.3502\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9945 - val_loss: 4.4432\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9671 - val_loss: 4.6540\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.9818 - val_loss: 4.3924\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8970 - val_loss: 4.5106\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9868 - val_loss: 4.3181\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8576 - val_loss: 4.5223\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9184 - val_loss: 4.6832\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.9143 - val_loss: 4.4843\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9061 - val_loss: 4.5546\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8342 - val_loss: 4.5353\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8686 - val_loss: 4.7565\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8720 - val_loss: 4.4800\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8788 - val_loss: 4.4218\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9126 - val_loss: 4.3947\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8526 - val_loss: 4.4544\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8743 - val_loss: 4.5711\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8924 - val_loss: 4.4646\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8706 - val_loss: 4.4984\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8954 - val_loss: 4.5529\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8255 - val_loss: 4.6019\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9617 - val_loss: 4.4852\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8590 - val_loss: 4.3693\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8789 - val_loss: 4.5994\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 5.0063 - val_loss: 4.6011\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8521 - val_loss: 4.4792\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9854 - val_loss: 4.4898\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8541 - val_loss: 4.4290\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8623 - val_loss: 4.5340\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7809 - val_loss: 4.5661\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9761 - val_loss: 4.4234\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8834 - val_loss: 4.4282\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8010 - val_loss: 4.3376\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 983us/step - loss: 4.8884 - val_loss: 4.6749\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8461 - val_loss: 4.4413\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8377 - val_loss: 4.4127\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8328 - val_loss: 4.2179\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7741 - val_loss: 4.3491\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9216 - val_loss: 4.3684\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.9082 - val_loss: 4.4884\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8114 - val_loss: 4.4378\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8408 - val_loss: 4.3862\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9254 - val_loss: 4.5227\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8858 - val_loss: 4.4445\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8140 - val_loss: 4.6117\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9536 - val_loss: 4.5297\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8127 - val_loss: 4.2894\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8596 - val_loss: 4.4376\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8204 - val_loss: 4.3917\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8517 - val_loss: 4.6177\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8865 - val_loss: 4.3477\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8256 - val_loss: 4.5658\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8099 - val_loss: 4.2285\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9300 - val_loss: 4.3560\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9299 - val_loss: 4.4631\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.9198 - val_loss: 4.2730\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8339 - val_loss: 4.3419\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9005 - val_loss: 4.3436\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9065 - val_loss: 4.3687\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8752 - val_loss: 4.4488\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8237 - val_loss: 4.4293\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8091 - val_loss: 4.4774\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8950 - val_loss: 4.3456\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8417 - val_loss: 4.4902\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9219 - val_loss: 4.5134\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8188 - val_loss: 4.4938\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8677 - val_loss: 4.2870\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7930 - val_loss: 4.3629\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7810 - val_loss: 4.6963\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8009 - val_loss: 4.5202\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8993 - val_loss: 4.3846\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8419 - val_loss: 4.3921\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8962 - val_loss: 4.3681\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8412 - val_loss: 4.5299\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8016 - val_loss: 4.3605\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8486 - val_loss: 4.3461\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9309 - val_loss: 4.5388\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7775 - val_loss: 4.4763\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8347 - val_loss: 4.4536\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7727 - val_loss: 4.5432\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.8303 - val_loss: 4.4739\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7900 - val_loss: 4.3338\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7633 - val_loss: 4.3391\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7821 - val_loss: 4.2429\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7569 - val_loss: 4.3821\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7540 - val_loss: 4.3371\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8436 - val_loss: 4.5234\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8564 - val_loss: 4.2894\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8169 - val_loss: 4.2662\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7944 - val_loss: 4.6057\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7969 - val_loss: 4.3933\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7554 - val_loss: 4.5661\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8671 - val_loss: 4.4995\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7195 - val_loss: 4.4109\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8588 - val_loss: 4.2798\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7294 - val_loss: 4.2644\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8791 - val_loss: 4.5563\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7495 - val_loss: 4.3510\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6783 - val_loss: 4.3557\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8855 - val_loss: 4.4872\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7745 - val_loss: 4.5468\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8974 - val_loss: 4.0905\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.9090 - val_loss: 4.2278\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7645 - val_loss: 4.3000\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7994 - val_loss: 4.5556\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7658 - val_loss: 4.4994\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8046 - val_loss: 4.3868\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8527 - val_loss: 4.2520\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8526 - val_loss: 4.3632\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9251 - val_loss: 4.2784\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8690 - val_loss: 4.3693\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8476 - val_loss: 4.4680\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.7324 - val_loss: 4.2545\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7552 - val_loss: 4.4907\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7945 - val_loss: 4.4444\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7288 - val_loss: 4.2361\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7305 - val_loss: 4.3004\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7583 - val_loss: 4.3346\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7147 - val_loss: 4.3800\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8151 - val_loss: 4.3758\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8381 - val_loss: 4.3337\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8077 - val_loss: 4.5414\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8269 - val_loss: 4.3506\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7804 - val_loss: 4.4514\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6901 - val_loss: 4.5276\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8393 - val_loss: 4.3850\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8105 - val_loss: 4.1798\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7612 - val_loss: 4.3145\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.8293 - val_loss: 4.2928\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7403 - val_loss: 4.2278\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8629 - val_loss: 4.4133\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8311 - val_loss: 4.2445\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7830 - val_loss: 4.3667\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7903 - val_loss: 4.3948\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8037 - val_loss: 4.2194\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7728 - val_loss: 4.6555\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8826 - val_loss: 4.4343\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8415 - val_loss: 4.3723\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7754 - val_loss: 4.5179\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8102 - val_loss: 4.5034\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7760 - val_loss: 4.2771\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7644 - val_loss: 4.3549\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7446 - val_loss: 4.3430\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7018 - val_loss: 4.4681\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8087 - val_loss: 4.3292\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8680 - val_loss: 4.4716\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8545 - val_loss: 4.3281\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7949 - val_loss: 4.2926\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8547 - val_loss: 4.3979\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7594 - val_loss: 4.2986\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8034 - val_loss: 4.3271\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8435 - val_loss: 4.2635\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6397 - val_loss: 4.5491\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8460 - val_loss: 4.5352\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8337 - val_loss: 4.4022\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7483 - val_loss: 4.3251\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7533 - val_loss: 4.3932\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8251 - val_loss: 4.4198\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8122 - val_loss: 4.2661\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6998 - val_loss: 4.4131\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7135 - val_loss: 4.4086\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7675 - val_loss: 4.6641\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7739 - val_loss: 4.4152\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7011 - val_loss: 4.3949\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7501 - val_loss: 4.5038\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7839 - val_loss: 4.2405\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7722 - val_loss: 4.3492\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.7772 - val_loss: 4.3090\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7229 - val_loss: 4.2412\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7046 - val_loss: 4.5011\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7470 - val_loss: 4.2628\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8036 - val_loss: 4.2811\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.7520 - val_loss: 4.3379\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 4.339 - 0s 2ms/step - loss: 4.8250 - val_loss: 4.1950\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6905 - val_loss: 4.4460\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6896 - val_loss: 4.3924\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8005 - val_loss: 4.5107\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8225 - val_loss: 4.3908\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7902 - val_loss: 4.4382\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6323 - val_loss: 4.3082\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6854 - val_loss: 4.3003\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7553 - val_loss: 4.3438\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7165 - val_loss: 4.2576\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7924 - val_loss: 4.3074\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7918 - val_loss: 4.4372\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7361 - val_loss: 4.3953\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7438 - val_loss: 4.3482\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7301 - val_loss: 4.4503\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7771 - val_loss: 4.5133\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7710 - val_loss: 4.0947\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7194 - val_loss: 4.3197\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6900 - val_loss: 4.5019\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6366 - val_loss: 4.4955\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6711 - val_loss: 4.2730\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7733 - val_loss: 4.4983\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7569 - val_loss: 4.3439\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7107 - val_loss: 4.3287\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7781 - val_loss: 4.5834\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7863 - val_loss: 4.4876\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7992 - val_loss: 4.4097\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6765 - val_loss: 4.3663\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6971 - val_loss: 4.5355\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7202 - val_loss: 4.3224\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6688 - val_loss: 4.2962\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6985 - val_loss: 4.3091\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7433 - val_loss: 4.1824\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6495 - val_loss: 4.3372\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6255 - val_loss: 4.2336\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8726 - val_loss: 4.3561\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7564 - val_loss: 4.4484\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6003 - val_loss: 4.2702\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6813 - val_loss: 4.2842\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7056 - val_loss: 4.3201\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6584 - val_loss: 4.2852\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6561 - val_loss: 4.3114\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6399 - val_loss: 4.6521\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7291 - val_loss: 4.4232\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7008 - val_loss: 4.1135\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7828 - val_loss: 4.2601\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6937 - val_loss: 4.3941\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7595 - val_loss: 4.4545\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7016 - val_loss: 4.3618\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6827 - val_loss: 4.4343\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7838 - val_loss: 4.4961\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7027 - val_loss: 4.4178\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6892 - val_loss: 4.4204\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6049 - val_loss: 4.3255\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6696 - val_loss: 4.2352\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7532 - val_loss: 4.4623\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6759 - val_loss: 4.4168\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8178 - val_loss: 4.2376\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6377 - val_loss: 4.3466\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6781 - val_loss: 4.4104\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6712 - val_loss: 4.3517\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7447 - val_loss: 4.3679\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7206 - val_loss: 4.2390\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6975 - val_loss: 4.3305\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7256 - val_loss: 4.4289\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6310 - val_loss: 4.4630\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6414 - val_loss: 4.4020\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6717 - val_loss: 4.3160\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7323 - val_loss: 4.2652\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6917 - val_loss: 4.2631\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7141 - val_loss: 4.3428\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7209 - val_loss: 4.3237\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6046 - val_loss: 4.1830\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7326 - val_loss: 4.5045\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6568 - val_loss: 4.3342\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6990 - val_loss: 4.2869\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7830 - val_loss: 4.3892\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6704 - val_loss: 4.3090\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7352 - val_loss: 4.4096\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7944 - val_loss: 4.2562\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6666 - val_loss: 4.4537\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6419 - val_loss: 4.3489\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6889 - val_loss: 4.3941\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6268 - val_loss: 4.3886\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6006 - val_loss: 4.1918\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6434 - val_loss: 4.4275\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6350 - val_loss: 4.3003\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6552 - val_loss: 4.4146\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6576 - val_loss: 4.4420\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7358 - val_loss: 4.4873\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6231 - val_loss: 4.3538\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7497 - val_loss: 4.2704\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6641 - val_loss: 4.1859\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6165 - val_loss: 4.3580\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6663 - val_loss: 4.3186\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7291 - val_loss: 4.3844\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6119 - val_loss: 4.2845\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6911 - val_loss: 4.1837\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.7334 - val_loss: 4.1882\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6728 - val_loss: 4.4923\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7237 - val_loss: 4.3986\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6865 - val_loss: 4.2352\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8420 - val_loss: 4.3110\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6178 - val_loss: 4.3914\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7380 - val_loss: 4.3470\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5941 - val_loss: 4.4045\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5872 - val_loss: 4.2166\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6772 - val_loss: 4.3270\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8351 - val_loss: 4.2567\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6561 - val_loss: 4.2785\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7322 - val_loss: 4.4356\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7254 - val_loss: 4.2545\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7805 - val_loss: 4.3669\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6827 - val_loss: 4.4456\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6793 - val_loss: 4.2530\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6900 - val_loss: 4.1696\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6218 - val_loss: 4.2601\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6989 - val_loss: 4.3694\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6909 - val_loss: 4.2627\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6075 - val_loss: 4.3779\n",
      "Epoch 722/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5868 - val_loss: 4.4457\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6025 - val_loss: 4.2040\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6435 - val_loss: 4.0927\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6278 - val_loss: 4.3340\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7045 - val_loss: 4.2937\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6075 - val_loss: 4.3946\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 4.548 - 0s 1ms/step - loss: 4.6681 - val_loss: 4.4633\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6308 - val_loss: 4.5201\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6357 - val_loss: 4.4011\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6909 - val_loss: 4.1190\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6172 - val_loss: 4.2668\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6682 - val_loss: 4.2642\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5820 - val_loss: 4.4050\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6046 - val_loss: 4.2816\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6566 - val_loss: 4.3223\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6691 - val_loss: 4.3278\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.8405 - val_loss: 4.3065\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7556 - val_loss: 4.2787\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6046 - val_loss: 4.2967\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6981 - val_loss: 4.1823\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7368 - val_loss: 4.2565\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6477 - val_loss: 4.2427\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7505 - val_loss: 4.2516\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6000 - val_loss: 4.7060\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6723 - val_loss: 4.3632\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.5855 - val_loss: 4.1618\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6224 - val_loss: 4.3010\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6360 - val_loss: 4.2757\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6210 - val_loss: 4.3323\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7168 - val_loss: 4.1680\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6497 - val_loss: 4.3851\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6280 - val_loss: 4.2951\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6222 - val_loss: 4.3423\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.5764 - val_loss: 4.4412\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5809 - val_loss: 4.3267\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6073 - val_loss: 4.4321\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6727 - val_loss: 4.2855\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6031 - val_loss: 4.2221\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6633 - val_loss: 4.2946\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6826 - val_loss: 4.1164\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5477 - val_loss: 4.5099\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6099 - val_loss: 4.1861\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6582 - val_loss: 4.2886\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6492 - val_loss: 4.4293\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6360 - val_loss: 4.4895\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7330 - val_loss: 4.3507\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6075 - val_loss: 4.3231\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6235 - val_loss: 4.2390\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6278 - val_loss: 4.2343\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6147 - val_loss: 4.2456\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6827 - val_loss: 4.5839\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5746 - val_loss: 4.2646\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.7284 - val_loss: 4.1848\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5776 - val_loss: 4.2795\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6531 - val_loss: 4.2694\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6031 - val_loss: 4.2702\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6653 - val_loss: 4.2872\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6119 - val_loss: 4.1496\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6488 - val_loss: 4.2040\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7413 - val_loss: 4.1539\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6296 - val_loss: 4.3837\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6066 - val_loss: 4.3457\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6536 - val_loss: 4.3019\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6806 - val_loss: 4.2570\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5806 - val_loss: 4.3381\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7138 - val_loss: 4.4359\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5581 - val_loss: 4.1240\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6984 - val_loss: 4.3718\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6053 - val_loss: 4.3817\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5875 - val_loss: 4.3848\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6468 - val_loss: 4.2389\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.5619 - val_loss: 4.2881\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6196 - val_loss: 4.4059\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.7057 - val_loss: 4.2579\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6393 - val_loss: 4.1864\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5832 - val_loss: 4.1493\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.6290 - val_loss: 4.2097\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5386 - val_loss: 4.3293\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5630 - val_loss: 4.2627\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6035 - val_loss: 4.2585\n",
      "Epoch 802/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6654 - val_loss: 4.3138\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5311 - val_loss: 4.2298\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5817 - val_loss: 4.2566\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6835 - val_loss: 4.3077\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5967 - val_loss: 4.2408\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6198 - val_loss: 4.3151\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6781 - val_loss: 4.3453\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.5632 - val_loss: 4.2464\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6605 - val_loss: 4.4304\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7470 - val_loss: 4.3223\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6268 - val_loss: 4.2508\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5377 - val_loss: 4.3075\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6042 - val_loss: 4.3757\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6955 - val_loss: 4.4460\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6322 - val_loss: 4.3020\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6502 - val_loss: 4.2856\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5894 - val_loss: 4.2655\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6541 - val_loss: 4.4739\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5817 - val_loss: 4.2895\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6629 - val_loss: 4.2484\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5761 - val_loss: 4.4397\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5029 - val_loss: 4.2712\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5670 - val_loss: 4.3218\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6130 - val_loss: 4.2232\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6192 - val_loss: 4.1133\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5498 - val_loss: 4.2497\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6820 - val_loss: 4.3726\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5720 - val_loss: 4.1617\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5459 - val_loss: 4.3021\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5509 - val_loss: 4.3400\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5989 - val_loss: 4.3312\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6155 - val_loss: 4.1795\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5583 - val_loss: 4.3505\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6603 - val_loss: 4.2648\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5577 - val_loss: 4.2408\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6406 - val_loss: 4.2539\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6047 - val_loss: 4.2520\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5786 - val_loss: 4.3093\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6945 - val_loss: 4.4183\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5983 - val_loss: 4.3368\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6291 - val_loss: 4.3557\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6245 - val_loss: 4.1773\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5103 - val_loss: 4.3895\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5748 - val_loss: 4.2943\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6251 - val_loss: 4.3606\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6358 - val_loss: 4.3304\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5343 - val_loss: 4.4373\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5663 - val_loss: 4.4039\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5908 - val_loss: 4.2401\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6044 - val_loss: 4.1615\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5556 - val_loss: 4.3572\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.7443 - val_loss: 4.3089\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5956 - val_loss: 4.1926\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6252 - val_loss: 4.2935\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7160 - val_loss: 4.3586\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6344 - val_loss: 4.4344\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7434 - val_loss: 4.2716\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6623 - val_loss: 4.3920\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6290 - val_loss: 4.2823\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 4.382 - 0s 2ms/step - loss: 4.6422 - val_loss: 4.1479\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5069 - val_loss: 4.3850\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.7012 - val_loss: 4.1685\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5935 - val_loss: 4.1467\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6192 - val_loss: 4.2393\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6204 - val_loss: 4.3159\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6715 - val_loss: 4.5593\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5998 - val_loss: 4.3585\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.7294 - val_loss: 4.3305\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6465 - val_loss: 4.4511\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5929 - val_loss: 4.2356\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.5763 - val_loss: 4.1821\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5684 - val_loss: 4.4607\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6587 - val_loss: 4.4631\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5609 - val_loss: 4.2689\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6114 - val_loss: 4.2322\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5914 - val_loss: 4.2366\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6821 - val_loss: 4.1109\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5688 - val_loss: 4.2225\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.5700 - val_loss: 4.3082\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6330 - val_loss: 4.4032\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4825 - val_loss: 4.5068\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5925 - val_loss: 4.4041\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4481 - val_loss: 4.2175\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5882 - val_loss: 4.1856\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.5885 - val_loss: 4.2965\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5674 - val_loss: 4.3386\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5379 - val_loss: 4.3512\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5596 - val_loss: 4.3200\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6503 - val_loss: 4.3233\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6464 - val_loss: 4.2801\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6543 - val_loss: 4.3728\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5837 - val_loss: 4.3417\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5626 - val_loss: 4.3894\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6441 - val_loss: 4.4606\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6983 - val_loss: 4.4812\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5528 - val_loss: 4.3851\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5891 - val_loss: 4.3752\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6878 - val_loss: 4.2963\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6064 - val_loss: 4.4089\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5365 - val_loss: 4.2529\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5721 - val_loss: 4.2539\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6128 - val_loss: 4.3969\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5153 - val_loss: 4.2212\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5928 - val_loss: 4.2839\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5865 - val_loss: 4.2547\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5681 - val_loss: 4.1873\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5353 - val_loss: 4.0838\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6749 - val_loss: 4.4421\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6080 - val_loss: 4.2792\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5624 - val_loss: 4.3285\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5657 - val_loss: 4.2009\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.5601 - val_loss: 4.3431\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5410 - val_loss: 4.2358\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 4.915 - 0s 2ms/step - loss: 4.5723 - val_loss: 4.3052\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5299 - val_loss: 4.2789\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5964 - val_loss: 4.3625\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5761 - val_loss: 4.2482\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5720 - val_loss: 4.3350\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5063 - val_loss: 4.2934\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.6297 - val_loss: 4.3343\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5749 - val_loss: 4.4833\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5134 - val_loss: 4.3279\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5444 - val_loss: 4.2650\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6008 - val_loss: 4.2483\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5661 - val_loss: 4.2365\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5507 - val_loss: 4.4246\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6090 - val_loss: 4.2756\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6304 - val_loss: 4.3007\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6376 - val_loss: 4.2440\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5675 - val_loss: 4.3968\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5872 - val_loss: 4.3247\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6310 - val_loss: 4.3125\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6002 - val_loss: 4.3197\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6018 - val_loss: 4.2078\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5467 - val_loss: 4.5054\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5656 - val_loss: 4.3529\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4763 - val_loss: 4.1376\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5833 - val_loss: 4.1611\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5256 - val_loss: 4.2872\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5703 - val_loss: 4.1029\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6494 - val_loss: 4.5527\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4918 - val_loss: 4.3427\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6003 - val_loss: 4.2577\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5593 - val_loss: 4.3725\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4898 - val_loss: 4.1965\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6718 - val_loss: 4.4012\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.6726 - val_loss: 4.2864\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.5884 - val_loss: 4.3283\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.5430 - val_loss: 4.2751\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5994 - val_loss: 4.2258\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4524 - val_loss: 4.3037\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5051 - val_loss: 4.3710\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6782 - val_loss: 4.3189\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5624 - val_loss: 4.2953\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6203 - val_loss: 4.3522\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5659 - val_loss: 4.1700\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4968 - val_loss: 4.4484\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5663 - val_loss: 4.2569\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.4370 - val_loss: 4.2735\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5323 - val_loss: 4.3024\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5291 - val_loss: 4.4269\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.5762 - val_loss: 4.2212\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 4.6149 - val_loss: 4.3206\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5411 - val_loss: 4.2834\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4755 - val_loss: 4.1081\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5113 - val_loss: 4.3707\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6404 - val_loss: 4.4226\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5617 - val_loss: 4.3276\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5603 - val_loss: 4.2137\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5468 - val_loss: 4.2679\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6058 - val_loss: 4.0839\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5853 - val_loss: 4.1936\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5413 - val_loss: 4.3966\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6062 - val_loss: 4.2824\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5611 - val_loss: 4.3357\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5189 - val_loss: 4.2882\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5706 - val_loss: 4.3560\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6934 - val_loss: 4.1822\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5126 - val_loss: 4.3535\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4998 - val_loss: 4.4011\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5254 - val_loss: 4.2551\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6308 - val_loss: 4.2971\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5545 - val_loss: 4.3935\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5198 - val_loss: 4.3180\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5744 - val_loss: 4.2177\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5529 - val_loss: 4.2125\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6072 - val_loss: 4.1969\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5988 - val_loss: 4.2528\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5803 - val_loss: 4.2571\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5172 - val_loss: 4.2312\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5599 - val_loss: 4.3511\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5459 - val_loss: 4.4088\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4901 - val_loss: 4.2638\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4862 - val_loss: 4.2647\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5931 - val_loss: 4.4084\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.6020 - val_loss: 4.1765\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4757 - val_loss: 4.2360\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.5346 - val_loss: 4.5075\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.4711 - val_loss: 4.2828\n"
     ]
    }
   ],
   "source": [
    "# ### VAE\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "start_dimension = x_train.shape[1]\n",
    "# network parameters\n",
    "input_shape = (start_dimension, )\n",
    "intermediate_dim = 8\n",
    "batch_size = 24\n",
    "latent_dim = 5\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# build encoder model\n",
    "inputs = keras.Input(shape=input_shape, name='encoder_input')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary \n",
    "# with the TensorFlow backend\n",
    "z = Lambda(sampling,\n",
    "           output_shape=(latent_dim,), \n",
    "           name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(start_dimension, activation='tanh')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "X_imtrain, X_imval, y_imtrain, y_imval = train_test_split(x_train, x_train, \n",
    "                                                    test_size=0.2, random_state=1)\n",
    "\n",
    "start_time = time.time()\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    loss = 'mse'\n",
    "    models = (encoder, decoder)\n",
    "    \n",
    "    if loss == 'bce':\n",
    "        reconstruction_loss = binary_crossentropy(inputs,\n",
    "                                                  outputs)\n",
    "    else:\n",
    "        reconstruction_loss = mse(inputs, outputs)\n",
    "        \n",
    "    reconstruction_loss *= start_dimension\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    opt = keras.optimizers.Adam(lr =0.0001)\n",
    "    vae.compile(optimizer=opt,)\n",
    "    vae.summary()\n",
    "            \n",
    "    vae.fit(X_imtrain,\n",
    "            epochs=epochs,\n",
    "            #verbose = 10,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_imval, None))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:24:18.789151Z",
     "iopub.status.busy": "2021-09-11T14:24:18.788888Z",
     "iopub.status.idle": "2021-09-11T14:24:24.256905Z",
     "shell.execute_reply": "2021-09-11T14:24:24.256177Z",
     "shell.execute_reply.started": "2021-09-11T14:24:18.789122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 518 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 518 samples in 0.012s...\n",
      "[t-SNE] Computed conditional probabilities for sample 518 / 518\n",
      "[t-SNE] Mean sigma: 0.209272\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 43.041122\n",
      "[t-SNE] KL divergence after 2850 iterations: 0.072633\n",
      "t-SNE done! Time elapsed: 4.199498653411865 seconds\n",
      "(236, 2)\n",
      "46\n",
      "[0.40355383 0.37199466 0.06198569 0.00040442 0.00290215]\n",
      "[False False False False False] 5\n",
      "0.001619295300599114 -0.9959874119222208\n",
      "[[0.40355383]\n",
      " [0.37199466]\n",
      " [0.06198569]\n",
      " [0.00290215]\n",
      " [0.00040442]]\n",
      "32.199999999999996\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train data latent space\n",
    "def latent_data(vae, data):\n",
    "    encoder, decoder = vae\n",
    "    z_mean, _, _ = encoder.predict(data)\n",
    "    return z_mean\n",
    "LS_Aus_train = latent_data(models, x_train)\n",
    "LS_Aus_test = latent_data(models, x_test)\n",
    "\n",
    "\n",
    "# ### T-SNE\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=5000)\n",
    "tsne_org = tsne.fit_transform(LS_Aus_train)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"r\",\"b\"])\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = ['r', 'b']\n",
    "\n",
    "points = tsne_org[y_train ==1]\n",
    "print(points.shape)\n",
    "p2 = plt.scatter(points[:, 0], points[:, 1], marker=('o'), color=colors[0])\n",
    "points = tsne_org[y_train == 2]\n",
    "p1 = plt.scatter(points[:, 0], points[:, 1], marker=('^'), color=colors[1])\n",
    "plt.legend((p2,p1,),('Minority','Majority',), loc='upper right')\n",
    "#plt.savefig('Aus_TSNE.png')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ### MSPO\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "latent_space_im = LS_Aus_train\n",
    "mino = 1\n",
    "majo = 2\n",
    "y_d = y_train\n",
    "\n",
    "nTarget = np.sum(y_d == majo)\n",
    "\n",
    "\n",
    "posy = y_d == mino\n",
    "negy = y_d != mino\n",
    "P = latent_space_im[np.where(posy == True)[0],:]\n",
    "N = latent_space_im[np.where(negy == True)[0],:]\n",
    "\n",
    "#print(len(P),len(N))\n",
    "\n",
    "poscnt = P.shape[0]\n",
    "NumToGen = nTarget - poscnt\n",
    "Me  = np.mean((P),axis = 0)\n",
    "PCov = np.cov(P.T)\n",
    "print(NumToGen)\n",
    "[D,V] = np.linalg.eig(PCov)\n",
    "#d = [D[x,x] for x in range(D.shape[0])]\n",
    "d = D\n",
    "print(D)\n",
    "#d = d.astype(np.float32)\n",
    "n = P.shape[1] #Feature dimension\n",
    "idx = d.argsort()[::-1]   \n",
    "d = d[idx]\n",
    "V = V[:,idx]\n",
    "#d = d[0:n+1]\n",
    "#v = V[:,n::-1]\n",
    "\n",
    "\n",
    "\n",
    "Ind = (d<= 5e-09)\n",
    "\n",
    "if np.sum(Ind) != 0:\n",
    "    M = (list(Ind).index(True)+1)\n",
    "else:\n",
    "    M = n\n",
    "    \n",
    "print(Ind,M)\n",
    "\n",
    "PN = np.concatenate((P,N),axis=0)\n",
    "TCov = np.cov(PN.T)\n",
    "dT    = np.dot(V.T,np.dot(TCov, V))\n",
    "dT = [dT[x,x] for x in range(dT.shape[0])]\n",
    "\n",
    "\n",
    "#Modify the Eigen spectrum according to a 1-Parameter Model\n",
    "dMod  = np.zeros((n,1))\n",
    "Alpha = d[0]* d[M-1]*(M-1) /(d[0] - d[M-1]) #d[0]* d[M-1]*(M-1) /(d[0] - d[M-1])\n",
    "Beta  = ((M)*d[M-1] - d[0])/(d[0] - d[M-1])\n",
    "print(Alpha,Beta)\n",
    "\n",
    "for i in range(n):\n",
    "    if i<M-1:\n",
    "\n",
    "        dMod[i] = d[i]\n",
    "    else:\n",
    "        dMod[i] = Alpha/(i+1+Beta)\n",
    "        if dMod[i] > dT[i]:\n",
    "            dMod[i] = dT[i]\n",
    "\n",
    "R = 0.7\n",
    "d = dMod\n",
    "print(d)\n",
    "    \n",
    "########################################\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal\n",
    "Rn = M\n",
    "Un = len(Me) - M\n",
    "Ptemp = P\n",
    "\n",
    "MuR = np.zeros((Rn,1)) #mlayer#\n",
    "SigmaR = np.identity((Rn)) #v_mat #\n",
    "\n",
    "MuU = np.zeros((Un,1))\n",
    "SigmaU = np.identity((Un))\n",
    "\n",
    "SampGen = np.zeros((int(NumToGen*R), len(Me)))\n",
    "SampSel = np.zeros((int(NumToGen*R), len(Me)))\n",
    "Prob    = np.zeros((int(NumToGen*R),1))\n",
    "\n",
    "cnt = 0\n",
    "DD = np.sqrt(d)\n",
    "MuR = MuR.reshape(MuR.shape[0],)\n",
    "MuU = MuU.reshape(MuU.shape[0],)\n",
    "print(R*NumToGen)\n",
    "\n",
    "while cnt < int(R*NumToGen):\n",
    "    \n",
    "    if(cnt%2000 == 0):\n",
    "        print(cnt)\n",
    "\n",
    "    aR =  np.random.multivariate_normal(MuR.T, SigmaR, 1)\n",
    "    #print(aR)\n",
    "    #scipy.stats.multivariate_normal(MuR.T, SigmaR, 1)\n",
    "    tp = multivariate_normal.pdf(aR, MuR, SigmaR) #aR.pdf(1)\n",
    "    #print(tp)\n",
    "\n",
    "    if Un > 0:\n",
    "        aU = np.random.multivariate_normal(MuU, SigmaU, 1)\n",
    "        #scipy.stats.multivariate_normal(MuU, SigmaU, 1)\n",
    "        a = np.multiply(np.concatenate((aR,aU),axis=1).T,DD)   #The vector in Eigen transformed domain;\n",
    "    else:\n",
    "        a = np.multiply(aR.T,DD)\n",
    "        #print(a)\n",
    "\n",
    "    x = np.dot(a.T,V.T)+ Me\n",
    "    #print(x)\n",
    "    #pdb.set_trace()\n",
    "    PDist = np.sqrt(np.sum(np.square((x-P)),axis=1))\n",
    "    NDist = np.sqrt(np.sum(np.square((x-N)),axis=1))\n",
    "\n",
    "    [tmp,ind]  = [np.min(NDist),np.argmin(NDist)]\n",
    "\n",
    "    if np.min(PDist) < tmp:\n",
    "        PPDist = np.sqrt(np.sum(np.square((N[ind,:]-P)),axis=1))\n",
    "        if tmp >= np.min(PPDist) and tmp <= np.max(PPDist):\n",
    "            SampGen[cnt,:] = x\n",
    "            Prob[cnt,0] = tp  \n",
    "            cnt+=1\n",
    "            Ptemp = np.concatenate((Ptemp,SampGen),axis =0)\n",
    "\n",
    "for i in range (int(R*NumToGen)):\n",
    "    [tmp,ind]  = [np.min(Prob),np.argmin(Prob)]\n",
    "    Prob[ind] =  np.inf\n",
    "    SampSel[i,:] = SampGen[ind,:]\n",
    "\n",
    "Ynew = SampSel #np.concatenate((SampSel,P),axis = 0)\n",
    "#Total = np.concatenate((Ynew,N),axis = 0)\n",
    "\n",
    "#return Ynew\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "Datanew = np.concatenate((SampSel,P),axis = 0)\n",
    "Total = np.concatenate((Datanew,N),axis = 0)\n",
    "label = np.zeros((Total.shape[0],))\n",
    "label[0:Datanew.shape[0]] = 1\n",
    "label[Datanew.shape[0]:Total.shape[0]] = 2\n",
    "\n",
    "\n",
    "# In[26]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:24:24.262666Z",
     "iopub.status.busy": "2021-09-11T14:24:24.260430Z",
     "iopub.status.idle": "2021-09-11T14:24:32.519635Z",
     "shell.execute_reply": "2021-09-11T14:24:32.518718Z",
     "shell.execute_reply.started": "2021-09-11T14:24:24.262618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 550 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 550 samples in 0.014s...\n",
      "[t-SNE] Computed conditional probabilities for sample 550 / 550\n",
      "[t-SNE] Mean sigma: 0.208737\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 45.376434\n",
      "[t-SNE] KL divergence after 2550 iterations: 0.112831\n",
      "t-SNE done! Time elapsed: 4.024383544921875 seconds\n",
      "(268, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2000bfdde48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAHSCAYAAAAnsVjHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3Tc5X3v+/cj27JsQ0owDiY2lsA7JA2EJKvOZZNLc2kuzU4JJNAdEIaYsh1w07jpbho7Pm6zO8tt2r16crJOIJRuLAiecAmXYydNdwtJaS5NdzCNQ3EICTGSq3hMwFAuMWakmef88dNII2lGGkkzmp9G79daWtL85jczz1iWPvo+v+cSYoxIkqR0aWt2AyRJ0ngGtCRJKWRAS5KUQga0JEkpZEBLkpRCBrQkSSm0sNkNKHfSSSfFrq6uZjdDkqRZc//99z8RY1wx9niqArqrq4u9e/c2uxmSJM2aEEJfpeN2cUuSlEIGtCRJKWRAS5KUQqm6Bi1JmjsGBgbo7+/n2LFjzW7KnNDR0cHq1atZtGhRTecb0JKkaenv7+f444+nq6uLEEKzm5NqMUaOHDlCf38/p512Wk2PsYtbkjQtx44dY/ny5YZzDUIILF++fEq9DQa0JGnaDOfaTfXfyoCWJM1ZIQTWr18/fHtwcJAVK1bw/ve/H4A9e/bw2c9+tm6vd8455wDQ29vLl7/85bo9byUGtCRpzlq2bBkPPvggzz//PAB33303q1atGr7/3HPPZcuWLTN+nUKhAMA///M/Awa0JKmVZLPQ1QVtbcnnbLYuT/ubv/mb/O3f/i0AN998MxdddNHwfTfccAMf+9jHAPjIRz7Cxz/+cc455xxOP/10br/9diAZwPXJT36Ss846i1e96lXceuutANx77728/e1v5+KLL+ZVr3oVAMcddxwAW7Zs4dvf/javec1r+NznPsdb3vIW9u3bN/y6b3rTm3jggQdm9L4MaElS42WzsHEj9PVBjMnnjRvrEtIf/vCHueWWWzh27BgPPPAAb3jDG6qem8vl+M53vsPXvva14cr6zjvvZN++ffzwhz/knnvu4ZOf/CS5XA6A73//++zYsYMf/ehHo57ns5/97HAof+ITn+CKK67ghhtuAOAnP/kJL7zwAmefffaM3pcBLUlqvG3b4OjR0ceOHk2Oz9DZZ59Nb28vN998M+973/smPPe8886jra2NV77ylTz22GMAfOc73+Giiy5iwYIFnHzyyfz6r/869913HwCvf/3ra5oWdeGFF/K1r32NgYEBdu7cyUc+8pEZvy/nQUuSGu/gwakdn6Jzzz2XP/zDP+Tee+/lyJEjVc9bvHjx8NcxxlGfK1m2bFlNr7906VLe9a53sXv3bm677ba6bPxkBS1Jarw1a6Z2fIouv/xy/viP/3j4WvFUvPWtb+XWW2+lUCjw+OOP861vfYvXv/71Ez7m+OOP59lnnx117IorruDjH/84r3vd6zjxxBOn3I6xDGhJUuPt2AFLl44+tnRpcrwOVq9ezebNm6f12PPPP5+zzz6bV7/61bzjHe/gL//yL1m5cuWEjzn77LNZuHAhr371q/nc5z4HwK/92q/xohe9iA0bNkyrHWOFiUr72bZu3broftCSNDc89NBD/Oqv/mrtD8hmk2vOBw8mlfOOHdDd3bgGzrJDhw7xtre9jR//+Me0tVWufyv9m4UQ7o8xrht7rhW0JGl2dHdDby8Ui8nnFgrnL33pS7zhDW9gx44dVcN5qhwkJknSDF166aVceumldX3OeV1B53Kwdi0cPtzslkiSNNq8DehcDl7xCnj0Uchkmt0aSZJGm7cBvWULPPNMsqBNT49VtCQpXeZlQO/bB1/60sjtwcGkii7v8rb7W5LUTPMyoD/0odG3BwaSKnrr1qTL+4wzYOtv/4xHDxQ545SnOXzq6+q2qLskqX4m226ymr179/Lxj398Sq9V/ph77713eGerRpl3o7j37YMDB8YfHxiAXbuSLu9nn43c9J1OIm08y4vY2r+Jno0bkxNbaFqAJM115dtNLlmyZNx2k9WsW7eOdevGTT2uanBwcNRj7r33Xo477rjh/aEbYX5V0Nks/3Xdz4Dxi7MMDkKhUDoeKLJg+OubuITDR4+vy6LukjSfNeLy4UTbTX7/+9/nnHPO4bWvfS3nnHMODz/8MJAEbKnKfvLJJznvvPM4++yzeeMb3zi8TeRnPvMZNm7cyLvf/W4uvfTS4cf09vZy7bXX8rnPfY7XvOY1fPvb3+a0005jYGAAgGeeeYaurq7h29M1fwI6myX33/6YnxROB0KFE+KY4yNfF1jI6fyUw30vNLiRktTaMplkjZJ6zp6ZaLvJV7ziFXzrW9/iBz/4AX/6p3/Kpz/96XGP/5M/+RNe+9rX8sADD/Bnf/Zno+Yz33///ezevZsvf/nLw8e6urq48sor+cQnPsG+fft4y1vewtve9rbhPxJuueUWPvShD7Fo0aIZva/5E9DbtrHl+e0V7qhlqdPA8xzH1qWfr3erJGneyOWS8T7FYn1nz0y03eTTTz/NhRdeyFlnncUnPvEJ9u/fP+7x3/nOd4avY7/jHe/gyJEjPP3000CyS9aSJUsmbcMVV1xBT08PAD09PXVZj3veBHSuL89NXMr46jmM+VxN4EtHL5j8P1Q2C11d0NaWfHZwmSQBSdVcLCZfFwr1raJL202Wd28DbN++nbe//e08+OCDfPWrX+XYsWPjHltpT4oQkkyodbvJN73pTfT29vJP//RPFAoFzjrrrGm8i9HmTUBnjvsL4qQhPLEibRP/h8pmYeNG6OtLRpv19cH69bBp04xeV5LmulL1nM8nt/P5+lbR1babfPrpp4cHjd1www0VH/vWt76V7FAxde+993LSSSfxohe9aMLXq7Td5KWXXspFF11Ut92s5kVA79sH1z53CUmVXPpLqVrX9sRd3tdfP8F/qG3b4OjRMU8X4dprraQlzWvl1XNJPavoattN/tEf/RFbt27lTW96E4VCYdR9pSr5M5/5DHv37uXss89my5Yt3HjjjZO+3m/91m9x1113DQ8SA+ju7uapp54aV8VP17zYbvKss6DCZYdJjB00NmLTJrj66gp3tLUlgQzkWMmb+Q7f5U2s5DHo7ExGRkhSi5jKdpOrV8PPfz7++KpV0N9f54bV4I477mDPnj01hXGtbr/9dnbv3s1NN91U9Ry3myyzb990whkmuib9139dpYpes2b4ywzb6aWLDEMD0w4enE4jJKkl9Pcn9cvYj2aE8549e9i2bRsf/ehH6/acv/d7v8eWLVvYvr3SYOTpafkKenrVc3VtbUk3TcUqOpuF9evJxZM5nQMcYwlLOMoBTmdlZ4cVtKSWMpUKWgkr6CG5XH3DGUauoezcWaGK7u6GK68kw3aKQxV4gTYyC/4H7NhR34ZIklpaSwd0JgPt7Y157ny+8uCG3PZr6Fm0kTwdyXl00NP2Oxx+p0uESmo9aeqFTbup/lu1dEDv2TMypL/eqk20z2SgGEYvcV4IC91zWlLL6ejo4MiRI4Z0DWKMHDlyhI6Ojpof0/LXoMtVG0U4uciv8BTPs3S4MoakOr/iitHXotM2UlGSGmVgYID+/v6Ki39ovI6ODlavXj1uCdBq16Dn1W5W5QE5tbAOPM2LGTuyO5+H3btHAjqXg8WLk88rV9ajxZKUXosWLeK0005rdjNaVkt3cU+kvx9iZxeXcgO1rccNUGQTVxMJxNA2bopAIxaBlyTNT/M2oAFyf/hXZCmtMDaZALTRwwZ+yKtYu+DRUdefG7UIvCRpfprXAb3lvg9RGN73uTaDLKCbm3m0sIYzzhgJ4kYuAi9Jmn/mdUDfcQfUVj2PGGAx+3klMQaefRa2bm38IvCSpPlnXgf0CSdUPj751p8joX7TTUlIN3IReEnS/DOvA7rS2rCHDk1t7nShALfdNv4xpRHekiRNx7yaZlWLTCYJ3anI551aJUmqr3ldQVeyZ8/UH2N3tiSp3gzoMcq7vVetqv1xdmdLkurJLu4JuDSnJKlZrKAlSUohA1qSpBQyoCVJSiEDWpKkFJpxQIcQOkII3w8h/DCEsD+E8D+Gjp8WQvg/IYSfhhBuDSG0z7y5kiTND/WooF8A3hFjfDXwGuC9IYQ3An8BfC7G+DLgKeB36vBakqQ5LJeDtWvdq6AWMw7omHhu6OaioY8IvAO4fej4jcB5M30tSdLckctBZyecemry+fDhZFGn3l4Xd6pFXa5BhxAWhBD2Ab8A7gZ+BvxHjHFw6JR+YArLfkiS5opqVXEmAwcPJmtKHDwIW7YkO/0Vi+74V4u6BHSMsRBjfA2wGng98KuVTqv02BDCxhDC3hDC3scff7wezZEkzaJKVXEuBzt3jj7vphuLFI8lOwsVnn+BzCUPz14j56C6juKOMf4HcC/wRuCEEEJppbLVwKEqj7kuxrguxrhuxYoV9WyOJKnBcrnKVXEmAwMDo88tEsiTjBfOs5jrv7GGrhXPWUlXUY9R3CtCCCcMfb0E+A3gIeAfgQuGTrsMcLVqSWoRpW7tzZvh2LHkWGnjoFL1XCyOfVQYdesFOuh7Ytlw5e0AstHqUUGfAvxjCOEB4D7g7hjj14BPAX8QQngEWA5cX4fXkiSlQCYDjz4Kt98+ciyfT6rorVvHV8+VBSAMV94OIBstxFjx0nBTrFu3Lu7du7fZzZAkTSCXg9NPH6mcy7W3w6JF8MtfTvQMkfJqur0dLroIbr01ec4lS+DAAVi5st4tT6cQwv0xxnVjj7uSmCRpSjKZpDu7knw+CdlcLtm299AhWLx47Flh3GN27Rp5zlJX+XxnQEuSalYaFFapC3vJErjwwiRgt25NjmUySQBPplAYec5SV/l8vxZtQEuSajZR9VwowFe+knx9ww3wzW/Cnj1JJT1VVtEGtCRpCvbsqT4AbGyl/MEPwn33QUfH1F8nn4fd83zujwEtSapZpcBdsgTuvnv8uU8/DR/9aPWKe/FiWLMm6TY/dCgZeFa6dh1jsgLZfLZw8lMkSUps2TJ+9HahABdcUPn8r361+nO98EKyBGgmkwRyaYrV1VfXrblzmtOsJEk1O+64yaZQjdfWVmnRkhGlinw+TrECp1lJkmYolxvprl6yZKQ7+qqrJn7cROEMyfXm0vVrB4eNMKAlSTXJZEbCtnxZz56eqT1PezssWDByu1gceV6nWI0woCVJkyoFcanSzeeT9ba3bh1fIbe3w2WXJYO+KnVV5/PVB46BVXSJAS1JmlR59VySzydrcY+dXlU63tsL73lPEtglHR0w2caFTrFKGNCSpEnt2TM+iItFOP74kWlRpY9Dh5IquFhMlvAsf1w+Dy95STJwbNOm8Y91itUIA1qSNKn+/iR4y68dt7cni5GMlclAcTDpwy4URs8UKhZh//6h/aP/ZpDDp74uSeuuLnJfuMPtJssY0JKkmmzZMvracT6fhOw9L7mYRWGAB176XnJfuIOe/zVIfrCU5KHicwEUBgbZ0r+JtfGnHO47Rub3j9D7aPT68xDnQUuSJrVvH7z2teOPt/MCy3iOpziRM3mQty74HtcXLiVPbet7tjFIJHApX+JWPswxlrBkCXzve0l1/t3vtv6caOdBS5Km7ZJLKh/Ps5inOBEI7Ocsbi+cW3M4AxRZQGQBu1hPYajaLhSgu3tkZbH5yoCWJE0ol0uuG1eykNEjx07kKVbx78Akq5MMGwplFjAwFOz5fNl16nk8J9qAliRNKJMZPVXqzDOTkdY/WPleBlnEyHXmwMO8gp+zmsrXnuPQWYPDX4+ofK16Ps+JNqAlSVWNXaAEkur2gQfgkgW3VHlUoHLgJsciC6vcP958XlnMgJYkVVVpgRKAiy+Gh3InMD5oawveapYtG12tw/ytog1oSVJVlRYogaSKPvXUkQ0zDh0aH6xTE9m0CU44ofLKZPNxZTEDWpJUVX9/slvV2PBta4O+vmRu9Nq1sHlz5SCvXWD37uT1XFksYUBLkiZUbZlPSJbyfPRRuPPO6T9/aevK8hDO5Zj3q4oZ0JKkCY2tas88c+S+QiE5NtHuVJOpdI05k3EetAEtSarZvn3V50RP19hrzKWR486DliSpRtVWFBtv4mWkly2rfo25fOT4fB3BDQa0JKlGE60oNt746VYr2x6jY2gV0GKxcmU8dt6186AlSZrE2BXFJtPOMTZxNZFAXLqMd5/zHMeOJfdVq4wrzbuer1W0AS1Jqkm1OdHV5OlgNx+Azk5yf/Elst9bO3Jflcq40ms4D1qSpAmUj+Y+dIjh7uqS0nSp0ijvM8+E/rgaenvZct+Hxo30rlQZOw96hAEtSZqyal3RmzePXKcurdkNcMcd459jvlbGtTKgJUlTVq0reuyCJRdfnFTVY6vnSouTaDQDWpI0ZZW6on/wAxgcHH3e/v3w+7/vwK/pMKAlSXVRbY70nXc68Gs6Fja7AZKk1vDQQ5WPF4tJha2pMaAlSXUxk/W4NZ5d3JIkpZABLUlSChnQkiSlkAEtSVIKGdCSJKWQAS1JUgoZ0JIkpZABLUlSChnQkiSlkAEtSVIKGdCSJKWQAS1JUgoZ0JIkpZABLUlSChnQkiSlkAEtSVIKGdCSJKWQAS1JUgoZ0JIkpZABLUlSChnQkiSlkAEtSVIKGdCSJKWQAS1JUgrNOKBDCKeGEP4xhPBQCGF/CGHz0PETQwh3hxB+OvT5xTNvriRJ80M9KuhB4L/HGH8VeCPwuyGEVwJbgG/EGF8GfGPotiRJqsGMAzrGmIsx/uvQ188CDwGrgA8ANw6ddiNw3kxfS5Kk+aKu16BDCF3Aa4H/A5wcY8xBEuLAS+r5WpIktbK6BXQI4TjgDuD3Y4zPTOFxG0MIe0MIex9//PF6NUeSpDmtLgEdQlhEEs7ZGOOdQ4cfCyGcMnT/KcAvKj02xnhdjHFdjHHdihUr6tEcSZLmvHqM4g7A9cBDMcb/u+yuPcBlQ19fBuye6WtJkjRfLKzDc7wJWA/8Wwhh39CxTwOfBW4LIfwOcBC4sA6vJUnSvDDjgI4xfgcIVe5+50yfX5Kk+ciVxCRJSiEDWpKkFDKgJUlKIQNakqQUMqAlSUohA1qSpBQyoCVJSiEDWpKkFDKgJUlKIQNakqQUMqAlSUohA1qSpBQyoCVJSiEDWpKkFDKgJUlKIQNakqQUMqAlSUohA1qSpBQyoCVJSiEDWpKkFDKgJUlKIQNakqQUMqAlSUohA1qSpBQyoCVJSiEDWpKkFDKgJUlKIQNakqQUMqAlSUohA1qSpBQyoCVJSiEDWpKkFDKgJUlKIQNakqQUMqAlSUohA1qSpBQyoCVJSiEDWpKkFDKgJUlKIQNakqQUMqAlSUohA1qSpBQyoCVJSiEDWpKkFDKgJUlKIQNakqQUMqAlSUohA1qSpBQyoKVaZLPQ1QVtbcnnbHbGT7lvHyxYAAsXwgMPzPjpJLWYhc1ugJR62Sxs3AhHjya3+/qS2wDd3VN+ulwO3vzm5OtiMfl88cXw4IN1aKuklmEFLU1m8+aRcC45ehS2bZvW02Uy8OijcODAyLH9+62iJY1mQEsTyWbhyJGKd+X68nR2Jj3ehw/X9nS5HPT0QIzj77v44uk3U1LrMaClarJZcpd+irU8wmFOHnVXjpW8PPyYgwehry+y5T99peL16VwO1q4dCfBMBgqFyi9nFS2pnAEtVTJ03TlT/DS9dJFh+6i7t/DnPBuPH7oV2PXL8zkcXzJ8fTr3hTtYuxa2boXe3iSYS9XzwED1l7WKllQSYqW+tiZZt25d3Lt3b7ObIUFXF7m+FzidAxxjCUs4ygFOJxL4z3yPf2c1xVFjLCOXcQM3cDkAm477Etf+cj1tbUnFvGQJ/PZvw803Qz5f/WVL50uaP0II98cY1409bgUtQVIxn3QShJB89PWRYTtFAgAF2siwnQzb6aOTIgvGPEFgF+s5zMns42yufa6bGEfCtlCA22+fOJxXrTKcJY1wmpWUzcKGDaP6nnOspIcN5OkAIE8HX+QqFvICDIX2WAUWsJZHWEmOOOacfD6Z85zLwcqVDXsnklqIFbS0bdtwOOdYyVoeYSt/Nlw9l0QCA0OBXVngKMs4wH+iUogXCsm1aEmqhQEtHTw4/GWG7fTSxe1cOFw9jwhUq55Hn1NZPg+7d0+7lZLmGQNaWrMGGOnWLrKAIm1cRg9tFDiTf6ONwYoP7eysdLRySG/aBP39dWqzpJZnQEs7dsCiRaMGhQ3Sxi7WU2QB+zlrzIjtEX19tb9MT0/tC5pIUl0COoSwM4TwixDCg2XHTgwh3B1C+OnQ5xfX47WkaRva8CIXXsraRX0c/siWZGGR9evJLVozalDYAB0Uxo3UTgQGgalPT/QatKSpqFcFfQPw3jHHtgDfiDG+DPjG0G2pOTZtgvXrh6ZP/V/0Dq4mc+OpSQkcI5mjf0BhXNd0GPM5EVk47lgtvAYtaSrqEtAxxm8BT445/AHgxqGvbwTOq8drSVOWzcK110KMo64z97BheAnPPZw7yQhtWMAAF3IrU62elyxJplfF6DVoSbVr5DXok2OMOYChzy+pdFIIYWMIYW8IYe/jjz/ewOZo3tq2bXh3ikqLjwDcx+vo4PmhBxQrPk2BhdzJ+Uy1erZrW9J0NH2QWIzxuhjjuhjjuhUrVjS7OWpFQ9OoKi0+Uqqiy4O7jSLJ0p09ZaENECiwaMKXaqvwE2XXtqTpaGRAPxZCOAVg6PMvGvhaUnVD06jKQ7ikQBtb+PNRwV0cusacjOKu/Udk06akWo5x/Idd25KmqpEBvQe4bOjrywBrCDXHjh2wdCl7OHfc4iN5OridC8cFNyRLd+ZZPOZooI3KC2ZbJUuqp3pNs7oZ+B7w8hBCfwjhd4DPAu8KIfwUeNfQbWn2dXfDddfR3/lmIoG4YOGozyfwHxVWDQMIyQCvL9xB7OwihjZiZxeFXbdYJUtqOLeb1Pw1tOczR48CsImruZ7LR4V1eztccQVcfXWzGimp1bndpDTWUGXN8uUAlbvAHeAlqUkMaM1v3d3wxBOwa1fSBT7UjR13Ze26ltRU7gctQRLU3d3NboUkDbOCliQphQxoSZJSyICWJCmFDGhJklLIgJYkKYUMaEmSUsiAliQphQxoSZJSyICWJCmFDGhJklLIgJYkKYUMaEmSUsiAliS1vH37YNEieOCBZrekdga0JKkl5XKwdi0cPgyXXAKDg3Dx+56Cri5oa0s+Z7OjzksTA1qS1JIyGejthY9/HPbvT47t//kJfLOvK9nsva8PNm4ks/4nPPoovPzl6QppA1qS1HJyOejpgWIRvvKV0fddwO3kWMlaHuGHR9fS8801xAjPPAMbNzanvZUY0JKklpPJJOE8XuAplnMZOznA6fw2t1KII/d+9avpqaINaElSSylVz/l89XPu5r1A4Ce8ggE6Rt33X/4LhADf/GZj2zkZA1qS1FKqV88lYcLH/+u/Jp8vuICmDiAzoCVJLWXPnomr50QY83m8p56Cj340GWiWydSpcVNgQEuSWkp/fzJI+6qroC1MWEpP6qtfTarxnTtnv4o2oCVJLemuu6AY6xNz+fzsV9EGtCSpJZ1/PrRzrC7P1Ywq2oCWJLWkPXsgP2aE9kzMdhVtQEuSWlJ/P8RdWeLSZVzFNUCc9DETKRbhzjvr07ZaLJy9l5IkaZZ1dwNw16XvguLE06sm094OH/xgPRpVGytoSVJr6+7m/I++hHZemNHT5POwe3ed2lQDK2hJUstLrkcvrnBPBEIyHSu0VV3g5CUvgccea2QLx7OCliS1vNLc6LgrS+zs4hAvpSMco7RQSTFWD2eAFStmp53lDGhJ0vzR3Q29vWSuOkRx0egR3u3tyRrclTz00Cy0bQwDWpI071RaDjSfh5e+dKjSHvNRKMx+Gw1oSdK8ksvB4sWwbx+cfnpyuxTE/f3Nbt0IAzqFmrl7iiS1ukwm2QBjqLe7KRth1MKATqHSf560/qeRpLmqtFd0sQj79yefe3rSWRAZ0ClT/p+n528GOXzq65JRCwsXJp+7uiCbbXYzJWlOqrRXdKGQzoLIgE6LbBa6usi89BqKx5LJ9IWBQTL9HwEgV1jBWh7hcN8x2LjRkJakKSoVQJUGh6WxijagG6x0PfmHP5zgunI2Cxs3kut7gR42DE+mz9NBDxs4zMlk2E4vXWTYDkePwrZts/tGJGmOq1Q9lzz/PGzZMrvtmYwB3WA1DUbYtg2OHiXDdoqMnoRXoI0t/Dk9bKDIAnaygS4e5Yd9v+JAMkmagkpTq8p96Uvp+p1qQDdQtcEI46rpgwcB2MO547ZGy9PB7Vw4HNx52umjk/+64A4HkknSFAyvJlb2sXTpyP0xJlcQOzuT4T7NDmsDuoEqdacMDlaoptesAaCfU4mEUR+HOIUCC4aDu8hCIPBwYW0S+F98nsNX3zFr70mSWsXddydXDMt99atJzdTX1/wCyIBukGqDEQYGKgzt37Fj9J9xZSp1e5cbjIGXf+w3OPyRlF08kaSUO++8ie/fubO5VbQB3SATDUYoGR7a390N112X9KuEAMuXw4IFQOVu70QS2gN08AwvYsuNLycXTmHtoj4rakmaRKXqeax8vrlVtAHdIJMNRoDk/muugW9+k5F+72IRjjtueOHXfk7lKq6hjcEJnimwi/Vs5c/oHVxNZvMTTsOSpAmcf/7k5xSLza2iDegGKQ1GOHQIOioVwGUuuGDk61wO1vZ9g8OcnNxm5dAI7om37i6wgJtYn4z0Lqzn8Jb/Z6ZvQZJa1i9/Wdt5zayiDegGq6Wr+6mn4IEHRs5/lNM4g4eH5z9PdA16RKBI0i2ep314gRNJ0vQVi7B7d3NeO8QYm/PKFaxbty7u3bu32c2oq9Wr4ec/n/y8l788mSj/i1/AsWMAkY9wA3fzLn7O6gqPiDBBcHfwPI/mlrBy5TQbLkktbnXor/L7NZHLMSu/Q0MI98cY1409bgXdYP39STf30Jivqh5+OBnan4QzQOAm1rOXdZzJv5EEcrmJq+o8i8hc8vA0Wy1Jra+/882sovr+kk6zmge2bJneZt8FFrJ5yXXs5ywmDuTxvSBFFnLnP54w9ReVpPlixw76l7yM810AABzaSURBVL68akg3q2u7xICeBXfMYNbTbc+/n0Ukm2cs4hiVwjgJ79HH2znGB4u3T/+FJanVDU1x7e98MzG0ETu7iLuyw6uM9VcvrmeF16BnwUTXoVeuhP/4j/Ku7bHGXmtObrdzjCu4nkjgi1xFpQp71YIc/YOnzKjtkqTG8hp0E1Va/7X0cf75k3V/jw3e0prcHezkcnayAQgs4Sg5Vo4sE7p0Gf03frNB70iS1GgGdJPt2ZMs/1nJsmUTP/YYHQywCEh2vcqwfeTOyy5Lum8kSXOSAd1k/f2walXl+044Aa66Ctrbqz06DC9gUr53NABf/3rd2ypJmj0GdApU6wK/777xG24sCc+zj1ezoMLSn6Oq6KEtLCVJc5MBnWKVViErLFpC95k/pMD4idV5OtjNB5IbQ1tYSpLmJgM6xSptuJHPJ9tVlg8eKx8g1s+pydaVO3bMalslSfVlQKdYpa7vStekk67tP05udHYmW1c6QEyS5rSGB3QI4b0hhIdDCI+EELY0+vVaXcWqmg52r9qUJHhvr+EsSS1g4j0MZyiEsAC4GngX0A/cF0LYE2P8USNft5U1e2UbSdLsaHQF/XrgkRjjgRhjHrgFSqOYJElSNY0O6FXAv5fd7h86NiyEsDGEsDeEsPfxxx9vcHMkSZobGh3QlbZgGrX4d4zxuhjjuhjjuhUrVjS4OZIkzQ2NDuh+4NSy26uBQw1+TUmS5rxGB/R9wMtCCKeFENqBDwN7GvyakiTNeQ0dxR1jHAwhfAz4e2ABsDPGuL+RrylJUitoaEADxBi/DrhzgyRJU+BKYpIkpZABLUlSChnQkiSlkAEtSUqNXA7WroXDh0duv/SlEAJ85Suj72t1BrQkKTUymWTPn0wmub1lSxLSAJdcMvq+VhdijJOfNUvWrVsX9+7d2+xmSJJmWS4Hb3wj/OIXcOxYUjHffTe8613JRn3lliyBAwdg5crmtLXeQgj3xxjXjT1uBS1JmnWjurKzWTJn3MTBg0XyxwpAEsof+tD4cAYoFOZHFW1AS5Jm3XBX9iUPk9vwaXY+dwHQRpEFw+c8/XTlx+bz0NPT+teiDWhJ0qzK5ZKALRah5xtr2DrwGQZYNKXnmA9VtAEtSZpVmUwSzgCDBHaxnuIUF7bM52H37gY0LkUMaElSY2Wz0NUFbW3kVr+Onv81SD6f3DVAB4Wybu3JrFqVXJeOEfr7G9PctDCgJUmNk83Cxo3Q1wcxkvn5BooDg2NOChM+xXRCeex86rnIgJYkNc62bXD06PDNPZxLno6Kpy7hKDlWEhe1E3dlZ1Qpj51PPRcZ0JKkxjl4cNTNfk4lEoY/ruIa2nkBgAJtZNgOL3rRlF5ibLW8bx9ce+3QILQ5PNrbgJYkNc6aNVXv2sfZXMuV5FkMQJ4OetjA4SMLYf162LSpppfIZODRR+GMM5IwvuSSkfnTg4PJUqEPPDDjdzLrDGhJUuPs2AFLl1a86xJ2Ecdcfy6wIKmiY0zK4Gx2wqcvTdmKEZ59Fk4/HfbvH7l/YCC578ILZ/xOZp0BLUlqnO5uuO66cYdzrGQ/ZzJ2gFiexezmA8mNGJNr2FXkcvDylydzokuef77yuT/5ydyrog1oSVJjdXdDZ+eoQxm2004y16qdF1hAMrJ7CUfZS9my1GOuYZfbsiWpmgcGamvGxRdPrdnNZkBLkhpvx47hL3OspIcNw6O58ywengs9PFCspMo17Fxu0t7vcfbvn1tVtAEtSWq87m545zuBpHoujpv7nNweHijGycm167JgL5fJjO7artVcqqINaEnS7LjnHrjqqgnnQsNQFX3cXybXrru7x91fGhg2HQ89NL3HNYMBLUmaPddcQ39cPbwIyapV40/J08HuX7m0YjjD6LW8a1VajWw6VXezTG11ckmS6mg6q4TddRfDa3nXYtWqublutxW0JCn9yjbcOP+5m2ijyJltD9HOsaET4tBH8vUPeRWxs2tOb6phBS1JSrdsFi6/HPJ5cqxk53MXUKSN/cVXMDKPOjAS0HAht/HwwTOb0dq6sYKWJKXb5s3DfdoZtjPAoionjoT1T3gFD6x896w0r1EMaElS85R1XdPVVXly85EjQDJ/eicbKA53/k68TeWF8Za6NnW2GdCSpOYYs1c0fX3J7SorkFSunmPFcyHwk8MnzNmdrMCAliQ1y5i9ooHkdpX1t+/i/LLquWTiKtr9oCVJmqpq62z39Y3u7l6+HIDzuats1HZtdu+eQfuazICWJDXHBHtF09cHGzbASScNX4OutgJZaRGSSh9zdYoVGNCSpGaZYK9oINmmaiicAfrDGiIhmd+8K9sSITwR50FLkpqjtJTntm1JxTyZGJNtK3t7G9qstLCCliQ1T3d3Erhj9ouuaoL9oVuNAS1Jar7JurtLJrpu3WIMaElS83V3J9tLdnZCCMnI7fb20edMsD90KzKgJUnpUOruLhbhiSdg586RwO7srLo/dKtykJgkKZ26u+dVII9lBS1JUgoZ0JIkpZABLUlSChnQkiSlkAEtSVIKGdCSJKWQAS1JUgoZ0JIkpZABLUlSChnQkiSlkAEtSVIKGdCSNJdks9DVBW1tyedsttktUoO4WYYkzQXZLGzeDEeOjBzr64ONG5Ov5/GmEq3KClqS0i6bTYK4PJxLjh6Fbdtmv01gNd9gVtCSlHbbtiVBXM3Bg7PXlpLSHw2ldlnN150VtCSl3WQBvGbN7LSjXKU/GppZzbcgA1qS0m6yAN6xY3baUa7aHw3NqOZblAEtSWm3YweEUPm+5cun16U8nevH5Y9pqxIfzajmW5QBLUlp190NV145PqSXLoXPf37qz1e6ftzXBzGOXD+eKKSzWbj88pHHFArjz1m6tDnVfIsyoCVpLrjmGrjpJujsTIK6sxOuu2561fN0rh9v3gz5/PjjbW0zb48qCjHGZrdh2Lp16+LevXub3QxJam1tbUkVPFYIUCyO3M5mk9A+eLDy+SUpypG5KIRwf4xx3djjTrOSpPnmxBMrz6mOMbnGXOqm3rABBgZmtWkaMaMu7hDChSGE/SGEYghh3Zj7toYQHgkhPBxCeM/MmilJmrHSIK9K4VxSuh790Y/WFs7Ll9eteRptphX0g8AHgb8uPxhCeCXwYeBM4KXAPSGEM2KMFUYVSJIaYtOm5LpwoTAy6rq8C7uaiRZFKbdo0fQGqakmM6qgY4wPxRgfrnDXB4BbYowvxBgfBR4BXj+T15IkTcGmTfDFL46Mti4WawvnWnV2Qk+Pg8IaqFHXoFcB/1J2u3/omCSpEcoHdK1Z09gFQ0KA3t7GPb+AGgI6hHAPsLLCXdtijLurPazCsYrD/EIIG4GNAGuc4C5JU1dpXexG8nf1rJg0oGOMvzGN5+0HTi27vRo4VOX5rwOug2Sa1TReS5Lmt82ba79uXA8uRjIrGrVQyR7gwyGExSGE04CXAd9v0GtJ0vyVzU48Krvepru0qKZsptOszg8h9AP/GfjbEMLfA8QY9wO3AT8C/jfwu47glqQGmMLuUTlWspZHOMzJ03ut6S4tqmmZ6Sjuu2KMq2OMi2OMJ8cY31N2344Y49oY48tjjH8386ZK0jw10cYWUxgMlmE7vXSRYfvU2+BSnrPOpT4lKc3GDgCDpJItheVJJ9XUxZ1jJadzgGMsYQlHOcDprOSx2trQ2emo7QaqttSnm2VIUppNtLFFNgvPPFPT02TYTnFogk2Bttqr6EWLHBTWJFbQkpRmE21ssWZNTVOqyqvnknFV9HHHwXPPJa9XWtBk+fLkmrPd2g1lBS1Jc1G1OcdTWIykvHouKbAgqaI7O2HXLnj22ZF9nmNMPp54YjicczlYuxYOH57Ru9EUGNCSlGY7diTXnMstXZocr3HBkD2cS56OUcfyLGb3qt9Nri13d08awJlMcmomM/W3oOkxoCUpzbq7kwFhnZ1Jt3b5aOpq4b1rV1IB79oFnZ30hzXEzi7irmxSHO/KEju76D80Mip8ogDO5ZJlt4vF5LNV9OzwGrQkzWVj1+DesWPia8YVRoXnOIXT+dnoEd7LnoOODnjySTYtu5Hrj11MfnAB7e1wxRVw9dWz8N7miWrXoA1oSZpPurrGDSzbxNVcz+Xk6aCdY1zB9VzNx4AqA8yWwIEDsLLSLg2aMgeJSZLGhXOOlfSwYfgadZ4OetgwvNpYxQFmBa9FzwYDWpLmi2w2uY5dpvII75F50hUHmOVhd7W9DFU3BrQkzRfbto2bU115hHcHu/kAAP2cSiSMfAwNNuvvn7VWz1sGtCS1qrFreFdY1GRcAA999I/aMbhMX18yyKx8PXA1hAEtSa0mm03W6L7kkiRQY6xpxbGalZYaVUMZ0Kq/iXbekdRYpWlUjd4jegq7aGl6Fja7AWox2Sxs2AADA8ntvr7kNrierzQbKm2u0Qg1rmKm6bOCVn1t3jwSziUDA8nx6bIil2o3G5VtaalRNZQBrfqq1q02le628kA+6aSkAi+/juYAFam6RlW2pelZ5UuNqqEMaKVL6fpZKZCPHBlfkTtARaqu0vrckymt3z20djchJFtNLl8+sv73TTclP5NDm2uo8bwGrfpavrxytbx8eW2Pr/X6WV9fUl0/+WRt6w9L80Xp56C0PncII/s7lytVxGN/fvw5Sg0raNXX5z8P7e2jj7W3J8cnUurWnspUkCNHRrq9L7/cbm+ppLs7qXSLRXjxiyufc+KJyf1WxKllQKu+urth587RW+Pt3Fnb7jozmaeZz89sIJrUqp58cmrHlRp2cav+ursnD+Ty7fGee64+00IaPe9TmovWrKn8x6/TpFLPClqza+wgsL6++gar07Ck0SoNGnOa1JxgQGt2NXoRhb6+ZHnDk04aCWrnUWs+6+5OpkWVX3ZymtScEOKYnU2aad26dXHv3r3NboYaacxWdw21dClcdhnceOPoPwqWLvUXVL1ls8kYgFJvyPLlycBA/42lSYUQ7o8xrht73Apas2e2K9ejR5MgHluxO4+6vrLZZBR9+aWKI0eSBWbsrZCmzYDW7GlGKBYKlY/39dntXQ/ZbNJLkc+Pv29gwD+EpBlwFLdmT5p2vwlhZGRraflQsEt2KkoD/qr9EQTp+p5Lc4wVtGbPNKZ15FjJWh7hMCfXrx0hJCPIy9ntPXW1DPhzKo80bQa0Zs/73jflh2TYTi9dZNg+89cvjWCtNjDSam9qJvv3WrTIqTzSDBjQmj1f//qUTs+xkh42UGQBPWyorYpesKDy8c7OkWUNOzsrn2O1NzUT/XstXw49PV4ykGbAgNbsmWKFmmE7RZJpWQXaJq+ily5NrolOtiiDCzfUR6V/xxDgqqvgiScMZ2mGDGjNnilUqKXqOU8HAHk6KlfR5dvhXXcdXHPN5IsyuHBDfXR3JyO4y+e2x5jMO3dUvDRjLlSi2VMa9VvDSmKbuJrruXw4oAHaOcYVXM/VfGzkxM7OpNtazVFtBzK/L1LNXKhEzVeqXGuwJ5w3KpwhqaJ384HRJ6Z1YNd8WV602r9/Wr8v0hxiQGt2dXdXH6RVpn/NOcTQRiSM+ujn1NEnpnFgV6UNQTZubM2QrvbvH0LlP07myx8uUh0Y0Jp9lQYXjVXainIiaR3YVWl+cKvOs96xA9rbxx8vFsf/cTKf/nCR6sCA1uwrH6RVzZo11UcJQ7oHdk3W7dtKVWR3Nxx//MTnlP44mU9/uEh1YECrObq7k0FEu3ZVn/JUabT1TTcl1VdvbzrDGapX/mvWVK8iN22aG6Fd6Y+LJ5+c/HEHD3q9WpoiR3Gr+bLZpIoqdWuXwnmuqjRavbTF5bZtlUc9j5XGLTGrva8lS0bvZFVJqbfEEd/SOI7iVnqVqunSSl8zCKVcDtauhcOH69a6qZtonnWt1WKp6zdN3eHVuqhh4n2+Sz0iLhAjTYkBrZaSySQZn7nk4eYGW7U/OiYZ+DZqc5BS9/eY7vDcF+5ozh8h1f64ePJJuPLKyiG9fPnIHycuECNNiQGtlpHLJcs/F4vQ841TOdx3bCTYLrkETjqp+dd2JxnBPmpzkAULKlasma1Hkz9CMo1t6jgTXVu/5ppkfEB5+O7aNX7Jzzr2lkitzoBWy8hkkt/7UGXt7iNHmj+tZ2wVWba5x7jNQQonjXt4jpX0PHdB8kdIzyxX0ZN1URu+Ul0Z0GoJpeo5n09uV127Ow3TesqD7MYbh0Ovls1BknOSH9tCYUwV3ejr1XZRS7PKUdxqCZs2wfXXjwQ0VFm7G5JwKZXaaZDNkrv0U5xe/CnHWDJ8eAlHOcDprOQxIKmeT+fA6HOWwIEDsPIbE4wcN0ClVHMUt1ranj2jwxmqrN0N6VsetLubTPHTw9VzyfN0sJU/H75dXmGXDFfRLgIitRwDWi2hvz8ZDzb8sStLXH7S+LW70zCtZ2xX9KZN7OHccZuDQBtf4cLhW5XOyedh981HXQREakEGtFpTd3cygnjXrnRdM620ktgXv0g/pw5vCHKIU+jgeQCKtA1fRy8/Z9QGIi+sgBNPrPx6aestkFQzA1qtLW0jiyt1RY9RbbDYqDnS5Y4ehWPHxs9DTkNvgaRpM6Cl2TSmy3ls6JamWpW6sstHo4+aIz3WL3+ZVOTlLrus+X+QSJo2A1qaTWO6nMeGbsWBYLSxhT8fPUd6bBVdyRe/2PzlQSVNmwEtzaayxT7GLUzCyZUHgtHB7Vw4HNxjR3dPyD2XpTnLgJamYqaLgZQW+1i+vOK15koDwQ5xCgUWlAV3GzdxSW1VNDjdSpqjDGipVpVGYK9fn6ySUuvju7pg/XpyT3VUvdY8VuVu74W1V9HgdCtpDjKgpVpVGoEdI1x77eSV9Jhwr7QwSbXlPSvPkQ6j5khPyulW0pxjQEu1qlaFxjh5F/KYcK92rbnSymf9nDpqbnRJ+RzpUZxuJbUEA1qq1URV6GRdyGPur7royNiVz4ZUG909PEd64amsfckzHM7F8ds+NntxFknTYkBLtdqxY3x1WjJZF/IMu5gnrLg7O8n8+j30PnH8+D2in3sONm9u3A5XkhrGgJZq1d0NV145vS7kSnspT6bsdfqXvyZZXzyOXnO8P64m971eer57RrJH9N8Mcvi/bR8ZyHbkSPJRGtR2ySVw0kkGtTQHzCigQwj/M4Tw4xDCAyGEu0IIJ5TdtzWE8EgI4eEQwntm3lQpBa65ZnpdyKXpVQsW1PY6y5YloVo6/7jj4LvfrTjFK5MZ2T2zMFAg8/x/n/i5jxxxbrQ0B8xoP+gQwruBb8YYB0MIfwEQY/xUCOGVwM3A64GXAvcAZ8QYCxM9n/tBq+VlK+zbPF3t7eT+6suc/gcf4NjAwuHDY/eRrqqzM1mfXFJTNWQ/6BjjP8QYB4du/guweujrDwC3xBhfiDE+CjxCEtbS/NbdnayRXe1a9lTk82Q+8STFgcFRh6tN1xrHudFSqtXzGvTlwN8Nfb0K+Pey+/qHjkn6+tfHb2wxTXsGf7Pm6VrjODdaSrWFk50QQrgHWFnhrm0xxt1D52wDBoHSRa1K5UHF30ghhI3ARoA1/sLQfFDHyrXatKxJOTdaSr1JAzrG+BsT3R9CuAx4P/DOOHJBux9G/eZYDRyq8vzXAddBcg26hjZLc9uaNcmI6tm0aBG86EXw5JPJ6+/Y4dxoKeVmOor7vcCngHNjjOWjXvYAHw4hLA4hnAa8DPj+TF5Lahnve1/jX6OtDZYvHxlp3tMDTzyRDPfu7TWcpTlg0gp6El8AFgN3h2TQy7/EGK+MMe4PIdwG/Iik6/t3JxvBLc0L2SzceGNjX2P5cvj85w1haY6b0TSrenOalVpeV9fMu7eXL4dnnoGBgZFjS5e6pKc0RzVkmpWkKZrpALGrrkq6qnt6XG9banEz7eKWNBVTGSC2bFmyoEl5L9e11yafr7nGQJZanBW0NJsqrcndVuHHcOlS6OgYP1+61v2nJc15BrQ0m0prcpe6p5cvh4VjOrJCSFYbe/LJys8RY7JDVYV1uSW1DgNamm3d3clUp2Ix2QQjnx99f4zJamMTLdxz5MjIjlV9fW5+IbUgA1pqpmqDxg4enHj/6bGOHoVt2+rXLklNZ0BLzVStSl6zpvr+09W4+YXUUgxoqZkqDRorXye70v7Ty5dXfi7XspdaigEtNdPYQWOV5jSXX7Pu7U1WCZso1CW1BOdBS83W3T21Oc2lc7dtS7q13fxCakkGtDQXTTXUJc05dnFLkpRCBrQkSSlkQEuSlEIGtCRJKWRAS5KUQga0JEkpZEBLkpRCBrQkSSlkQEuSlEIGtCRJKWRAS5KUQga0JEkpZEBLkpRCBrQkSSlkQEuSlEIhxtjsNgwLITwO9NX5aU8CnqjzczZbK74n8H3NJa34nqA131crvidorffVGWNcMfZgqgK6EUIIe2OM65rdjnpqxfcEvq+5pBXfE7Tm+2rF9wSt+77K2cUtSVIKGdCSJKXQfAjo65rdgAZoxfcEvq+5pBXfE7Tm+2rF9wSt+76Gtfw1aEmS5qL5UEFLkjTntGRAhxD+ZwjhxyGEB0IId4UQTii7b2sI4ZEQwsMhhPc0s51TFUK4MISwP4RQDCGsKzveFUJ4PoSwb+jj2ma2c6qqva+h++bs96skhPCZEMLPy74/72t2m2YihPDeoe/HIyGELc1uTz2EEHpDCP829P3Z2+z2TFcIYWcI4RchhAfLjp0YQrg7hPDToc8vbmYbp6PK+2qpn6tKWjKggbuBs2KMZwM/AbYChBBeCXwYOBN4L3BNCGFB01o5dQ8CHwS+VeG+n8UYXzP0ceUst2umKr6vFvh+lftc2ffn681uzHQN/ftfDfwm8ErgoqHvUyt4+9D3Zy5P3bmB5Gel3BbgGzHGlwHfGLo919zA+PcFLfJzVU1LBnSM8R9ijINDN/8FWD309QeAW2KML8QYHwUeAV7fjDZOR4zxoRjjw81uR71N8L7m9PerRb0eeCTGeCDGmAduIfk+KQVijN8Cnhxz+APAjUNf3wicN6uNqoMq76vltWRAj3E58HdDX68C/r3svv6hY63gtBDCD0II/xRCeEuzG1MnrfT9+tjQJZedc7GLsUwrfU/KReAfQgj3hxA2NrsxdXZyjDEHMPT5JU1uTz21ys9VRQub3YDpCiHcA6yscNe2GOPuoXO2AYNAtvSwCuenahh7Le+rghywJsZ4JITwa8D/F0I4M8b4TMMaOkXTfF+p/36VTPT+gC8CGZK2Z4C/IvnDcS6aM9+TKXpTjPFQCOElwN0hhB8PVW1Kr1b6uapozgZ0jPE3Jro/hHAZ8H7gnXFkLlk/cGrZaauBQ41p4fRM9r6qPOYF4IWhr+8PIfwMOANIzWCX6bwv5sD3q6TW9xdC+Bvgaw1uTiPNme/JVMQYDw19/kUI4S6SrvxWCejHQginxBhzIYRTgF80u0H1EGN8rPR1C/xcVdSSXdwhhPcCnwLOjTEeLbtrD/DhEMLiEMJpwMuA7zejjfUUQlhRGjwVQjid5H0daG6r6qIlvl9DvxRLzicZFDdX3Qe8LIRwWgihnWQQ354mt2lGQgjLQgjHl74G3s3c/h6NtQe4bOjry4BqPVZzSov9XFU0ZyvoSXwBWEzSVQXwLzHGK2OM+0MItwE/Iun6/t0YY6GJ7ZySEML5wP8LrAD+NoSwL8b4HuCtwJ+GEAaBAnBljHHODKio9r7m+verzF+GEF5D0hXXC3y0uc2ZvhjjYAjhY8DfAwuAnTHG/U1u1kydDNw19LtiIfDlGOP/bm6TpieEcDPwNuCkEEI/8CfAZ4HbQgi/AxwELmxeC6enyvt6W6v8XFXjSmKSJKVQS3ZxS5I01xnQkiSlkAEtSVIKGdCSJKWQAS1JUgoZ0JIkpZABLUlSChnQkiSl0P8Pkn2uH5qX4vUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ### T-SNE on MSPO\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=5000)\n",
    "tsne_org = tsne.fit_transform(Total)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"r\",\"b\"])\n",
    "plt.figure(figsize=(8,8))\n",
    "colors = ['r', 'b']\n",
    "\n",
    "points = tsne_org[label ==1]\n",
    "print(points.shape)\n",
    "p2 = plt.scatter(points[:, 0], points[:, 1], marker=('o'), color=colors[0])\n",
    "points = tsne_org[label == 2]\n",
    "p1 = plt.scatter(points[:, 0], points[:, 1], marker=('^'), color=colors[1])\n",
    "\n",
    "plt.legend((p2,p1,),('Minority','Majority',), loc='upper right')\n",
    "#plt.savefig('Aus_TSNE.png')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# In[29]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:29:26.018159Z",
     "iopub.status.busy": "2021-09-11T14:29:26.017854Z",
     "iopub.status.idle": "2021-09-11T14:29:28.942876Z",
     "shell.execute_reply": "2021-09-11T14:29:28.942160Z",
     "shell.execute_reply.started": "2021-09-11T14:29:26.018126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8837209302325582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.86      0.86      0.86        71\n",
      "     class 2       0.90      0.90      0.90       101\n",
      "\n",
      "    accuracy                           0.88       172\n",
      "   macro avg       0.88      0.88      0.88       172\n",
      "weighted avg       0.88      0.88      0.88       172\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEjCAYAAACxTI37AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxdRZ338c836YYAIYQkJBNCIGEV5BFERBZ1EAKCK+PI4iCDgoALigOPisIoOCLhccRlUDHKSAQeCAoIIyqbIMaBMGEnBAgggZCYzsqSEEi6f/NHVeNN2933nuTe7ns633de55V76pxbp+7266o6dU4pIjAzK7NB/V0AM7P15UBmZqXnQGZmpedAZmal50BmZqXnQGZmpTcgApmkTST9l6QXJP1iPfI5VtLN9Sxbf5D0W0nHr+NzvyFpsaS/1LtcZo3Sp4FM0j9JminpZUkL8g/u7XXI+sPAGGBkRBy5rplExBURcWgdyrMWSQdKCknXdknfI6ffUWM+50i6vNp+EXF4RExdh3KOB84AdouIvyv6/B7yDEkLJbVUpLVIapMUFWlvlHSzpGWSlku6V9J78rYDJXXk781Lkh6X9PGK524s6XxJz0p6RdIcSV+QpF7K9YykSevweu6Q9Imiz+slv5C0Y73y21D1WSCTdDrwXeCbpKCzLfBD4IN1yH474ImIWFOHvBplEbC/pJEVaccDT9TrAErW5zPdDlgSEW3rcOyWXjYvBw6vWH8PsKzLPv8F3EL6bowGPge8WLF9fkQMBYYBXwJ+Imm3vO0XwME5382B44CTge8VfR1WUhHR8AXYAngZOLKXfTYmBbr5efkusHHediAwj1RbaAMWAB/P284FXgNW52OcCJwDXF6R9wQggJa8/jHgaeAl4M/AsRXp0yuetz/wP8AL+f/9K7bdAfwb8Kecz83AqB5eW2f5LwY+k9MG57SvAndU7Ps94DnSj/he4B05/bAur/PBinKcl8vxCrBjTvtE3v4j4JcV+V8A3AaoSxkn5ed35PwvzekfAGaRgtEdwK4Vz3mGFFQeAl7tfH+75BvA2cAvKtJ+CZyVvn4BMCrvN7y3969L2iJSTfxgYBUwvsv2twHtwI495PkMMKmb9C2BX+f8l+XH2+Rt5+U8V+X36KKc/gZSEF4KPA4cVZHfpcAPgBvz92QGsEPedmd+3Styfkd3U54dgT+QvoOLgWld3tvPkb7Li4FvAYPyth2A3wNL8rYrKt9fYDxwbX6dSzpfS952AjA7v/6bgO36Ik6sV4zpk4OkH+Ga7r7oFft8Hbib9Nd4K+C/gX+r+CKvyfu0kv7yrgS2zNvPYe3A1XV9Qv7QW4DNSEFil7xtLPDG/Phj5EAGjMgf5HH5eR/J6yPz9juAp4CdgU3y+uTefoikwDgjp70nf0k+wdqB7KPAyHzMM4C/AEO6e10V5XgWeGN+TitrB7JNSbW+jwHvyF/qbXorZ8X6zqQf2SE53y8CTwIbVQSDB/KPYpMe8gxgd2AhMDwvC3Na5H0EzCEFjSOAMT2Vi9SK+AdSQN8FmAz8oYdjzwVO6WHbM3QfyEYC/5jft81Jtb1fdXm/P1GxvhnpD8/H8/u/V36PO79Tl5IC3D55+xXAVV3en26Dbd5+JSnoDwKGAG/v8tzbSd/VbfPn3Pm575g/t41Jv6c7ge/mbYOBB4Hv5PK/nm9+/58Eds3lPRv4776IE+uz9FXTciSwOHpv+h0LfD0i2iJiEammdVzF9tV5++qI+A3pL9gu61ieDmB3SZtExIKImNXNPu8F5kTEZRGxJiKuBB4D3l+xz88i4omIeAW4Gtizt4NGxH8DIyTtAvwz8PNu9rk8IpbkY36b9EWs9jovjYhZ+Tmru+S3khQcLwQuBz4bEfOq5NfpaODGiLgl5/vvpKC9f8U+34+I5/J70JNVpKbj0cAxwA05rbOMAbyLFFy+DSyQdKeknSry2FrSclKQ+BpwXEQ8TqrNLejhuAvy9prl9/6aiFgZES+RamF/38tT3gc8ExE/y+//fcA1pNpip2sj4p78/b+CKt+TLlaTmvxbR8SqiJjeZfsFEbE0Ip4ltWI+kl/Hk/lzezX/ni6seB37AFsDX4iIFV3yPQU4PyJm5/J+E9hT0nYFytzn+iqQLQFGVelH2Zr0F7TT3Jz2eh5dAuFKYGjRgkTECtIP6pOkH8yNkt5QQ3k6yzSuYr3yzF6t5bkMOJX0w72u60ZJZ0ianc/ALic1y6v9GJ/rbWNE3ENqfogUcGu11nsQER35WJXvQa/HrvBzUvDuKYDPi4hTI2IH0g93RZf95kfE8IgYERF7RsRVOX0xqVbdnbF5e80kbSrpx5LmSnqRVJMZLmlwD0/ZDnhbPkGxPH9mxwKVJ0vW5XvS6Yukz+0eSbMkndBle+X7//pvRtJoSVdJej6/jsv56/doPDC3h4rFdsD3Kl7L0nz8cd3s2zT6KpDdRfoLfEQv+8wnvYmdts1p62IFqWnQaa0zcBFxU0QcQvqiPwb8pIbydJbp+XUsU6fLgE8Dv8m1pddJegepz+koUrN5OKlvpPPsW0+3Kun1FiaSPkOq2c0n/TBqtdZ7kM8Cjmft96DW26f8kfR+jwG61irWEhHPkfqVdq8h31tJgWR8ZaKkfXJZf19j+TqdQaoBvy0ihgHv7Myys3hd9n+O1LQdXrEMjYhPFTxutyLiLxFxUkRsTaot/bDLWc7K1135mzk/l/VN+XV8tOI1PAds20PF4jlSc7zy9WySWxNNq08CWUS8QOrU/oGkI/JfvVZJh0v6f3m3K4GzJW0laVTev+pQgx48ALxT0raStgC+3LlB0hhJH5C0GamD+mVSB25XvwF2zkNGWiQdDexG6sdZZxHxZ1IV/6xuNm9O6gtcBLRI+irpLF2nhcCEImcmJe0MfIP0RT4O+KKkWps2VwPvlXSwpFbSj/xVUv9lIbn5+H7gA/lxZRm3lHSupB0lDcqf/wmkPtNq+d5KOnlxTR7CMVjSvqQm3I8iYk4vT2+VNKRiaSF9Bq8AyyWNIDVjKy0Etq9Y/zXpe3Jc/k63SnqrpF2rlb2H/NYi6UhJ2+TVZaTgVPl9/UJ+/8YDpwHTcvrmpO/2cknjgC9UPOceUrN7sqTN8ms/IG+7GPiypDfm428haZ2HNPWVPht+EREXAqeTOg8XkSL/qcCv8i7fAGaSzoA9DNyX09blWLeQPtCHSGf+KoPPINIPcj6p2vz3pBpS1zyWkPo/ziA1jb8IvC8iCjVVeijf9IjorrZ5E/BbUqftXFIttrLp0DnYd4mk+6odJ/8wLyf1ozyYf9RfAS6TtHEN5XycFAD/g9REez/w/oh4rdpze8hvVg/9ka+RTsjcSjoR8wgpYH6sxqz/kdTp/TvSj/dy4BLgs1We9xtS0OpcziH1M21Cer135zwrfQ/4cB7v9v3cj3Yoqe9vPqkZeQGpBlyLc4CpuSl3VDfb3wrMkPQyqW/xtPzHsNP1pO/4A6Qzo5fk9HNJJx5eyOmvj2GMiHbSZ7kj6UTRPFJ3CxFxXS7/VblJ+ghrD51pSuryx9HMSkJpQPFOEfFkf5elvw2IS5TMbMPmQGZmpeempZmVnmtkZlZ6DmRmVnoOZGZWeg5kZlZ6DmRmVnoOZGZWeg5kZlZ6DmRmVnoOZGZWeg5kZlZ6DmRmVnoOZGZWeg5kZlZ6DmRmVnq9zWrU51qGbRqto4f3dzGsgNanVlXfyZrGKlbwWryq6nv27N3v2iyWLO1umou/de9Dr94UEYf1tF3SacBJpIlRfhIR381zJUwj3f78GdKEx11npl9LUwWy1tHDmfjvJ/d3MayAcR/q7hb81qxmxG3rnceSpe3cc9O2Ne07eOycHqcylLQ7KYjtQ5q34XeSbsxpt0XEZElnAmeSZhfrkZuWZlZIAB01/qtiV+DuPBnyGuAPpFnkPwhMzftMpfdpJIEmq5GZWfMLgtVRW9OSNDH3zIr1KRExJT9+BDhP0kjSLFbvIc2kNiYiFgBExAJJo6sdxIHMzAqrobbVaXFE7N3dhoiYLekC4BbSNH4PkuZ1LcxNSzMrJAjao7alal4Rl0TEXhHxTtI8s3OAhZLGAuT/26rl40BmZoV1EDUt1XQ2GyVtC3wIuJI0EfHxeZfjSZMQ98pNSzMrJID2GoJUja7JfWSrgc9ExDJJk4GrJZ1Imgn9yGqZOJCZWWG11LZqERHv6CZtCXBwkXwcyMyskABWN9l8uA5kZlZIEPVsWtaFA5mZFRPQ3lxxzIHMzIpJI/ubiwOZmRUk2lmv687rzoHMzApJnf0OZGZWYmkcmQOZmZVch2tkZlZmrpGZWekFor3JLtN2IDOzwty0NLNSC8RrMbi/i7EWBzIzKyQNiHXT0sxKzp39ZlZqEaI9XCMzs5LrcI3MzMosdfY3V+hortKYWdNrxs7+5iqNmZVCe6impRpJ/yJplqRHJF0paYikiZJmSJojaZqkjarl40BmZoV0juyvZemNpHHA54C9I2J3YDBwDHAB8J2I2AlYBpxYrUwOZGZWWEcMqmmpQQuwiaQWYFNgAXAQ8Mu8fSpwRC2ZmJnVLF00XnMdaJSkmRXrUyJiCkBEPC/p30lTvr0C3AzcCyyPiM4Zx+cB46odxIHMzAoJxOraL1FaHBF7d7dB0pbAB4GJwHLgF8Dh3R6yCgcyMyskgnoNiJ0E/DkiFgFIuhbYHxguqSXXyrYB5lfLyH1kZlaQ6KhxqeJZYF9Jm0oSaVLeR4HbgQ/nfY4Hrq+WkQOZmRUSpBpZLUuv+UTMIHXq3wc8TIpHU4AvAadLehIYCVxSrUxuWppZYfW6sWJEfA34Wpfkp4F9iuTjQGZmhQTyjRXNrNzSdHDNFTqaqzRmVgKeoNfMSi6g1lH7fcaBzMwKc43MzEotQq6RmVm5pc5+z6JkZqXme/abWcmlzn73kZlZydVrZH+9OJCZWSEe2W9mA0KzTT7iQGZmhUTA6g4HMjMrsdS0dCAb0LSinS1/MJ+W51YBsPzUcQxaspph0xbRMu9VFl2wPat33KSfS2mdTr/wWd426SWWL27hlIN2AWDz4Wv4ysVzGbPNayyctxHnnbIdL7/gn0qlZhvZ37CwKuk/JbVJeqRRx2hGwy9ZwKo3D6XtP3ai7cIdWL3NxqzZdghLvzie13bbtL+LZ13cPG0EZx07ca20o05t4/7pQznh7bty//ShHH1qWz+Vrjl1Dr+oZekrjawfXgoc1sD8m45WtrPRoytZOWl4SmgdRGw2mDXbbMyacRv3b+GsW4/MGMpLy9aube337he59eoRANx69Qj2O+zF/ihaE1M9p4Ori4bVlyPiTkkTGpV/M2pZ+Bodw1oYftF8Wp9Zxerth/DCiWOJIc3Vn2C923LUapa2tQKwtK2V4SPXVHnGhqeG+/FXJWkXYFpF0vbAV4Gf5/QJwDPAURGxrLe8/Aurp3ZoffoVVrx7SxZ9ewdiyCCGXruov0tlVlfprOXgmpbe84nHI2LPiNgTeAuwErgOOBO4Lc80flte71W/BzJJJ0uaKWnmmhdX9ndx1kv7yBbaR7ayeufUF/bKfsPY6OlV/VwqK2rZ4lZGjF4NwIjRq1m+xB39lToHxNa5j+xg4KmImEua63JqTq9ppvF+D2QRMSUi9o6IvVuGlbszvGPLVtpHtdLy/KsAbPzQClaPd99Y2dx98zAmHbUUgElHLeWum4b1c4maT52mg6t0DHBlfjwmIhYA5P9HV3uy/9TU2Quf+Du2/O48tCZYM2Yjlp06jiF3v8jwny5g0IvtjDxvLqsnDmHJVyf0d1ENOPOHc3nTfi+zxYg1XD7zUS779himXTSasy6ey2HHLKXt+TT8wv6q4EXjoyTNrFifEhFTKneQtBHwAeDL61qmhgUySVcCB5JeyDzgaxFRdX66sls9cRMWfWuHtdJW7TuMv+zrv+rNaPKnuw9SZx69Q7fplhQ4I7k4Ivauss/hwH0RsTCvL5Q0NiIWSBoLVB3/0sizlh9pVN5m1n8ixJr6Dq34CH9tVgLcQJphfDI1zjTupqWZFVavwa6SNgUOAU6pSJ4MXC3pROBZ4Mhq+TiQmVkh9byxYkSsBEZ2SVtCOotZMwcyMyvM9yMzs1LzjRXNbECoxyVK9eRAZmaFRMAa31jRzMrOTUszKzX3kZnZgBAOZGZWdu7sN7NSi3AfmZmVnmj3WUszKzv3kZlZqdXzWst6cSAzs2Ii9ZM1EwcyMyvMZy3NrNTCnf1mNhC4aWlmpeezlmZWahHNF8iaq6FrZqVQrwl6JQ2X9EtJj0maLWk/SSMk3SJpTv5/y2r5OJCZWWERtS01+B7wu4h4A7AHMBs4E7gtInYCbsvrvXIgM7NCAtHRMaimpTeShgHvBC4BiIjXImI58EFgat5tKnBEtTI5kJlZYVHjUsX2wCLgZ5Lul/RTSZsBYyJiAUD+f3S1jBzIzKyY3NlfywKMkjSzYjm5IqcWYC/gRxHxZmAFNTQju+OzlmZWXO3jyBZHxN49bJsHzIuIGXn9l6RAtlDS2IhYIGks0FbtID3WyCQN622p+WWY2YBToEbWSx7xF+A5SbvkpIOBR4EbgONz2vHA9dXK01uNbBYp7laWpnM9gG2rZW5mA08AHR11G0f2WeAKSRsBTwMfJ1WwrpZ0IvAscGS1THoMZBExvk4FNbOBJIA6DYiNiAeA7pqeBxfJp6bOfknHSPpKfryNpLcUOYiZDSx1HEdWF1UDmaSLgHcBx+WklcDFjSyUmTW5Oo2/qJdazlruHxF7SbofICKW5vasmW2Qqnfk97VaAtlqSYPI8VXSSKCjoaUys+ZWwtv4/AC4BthK0rnAUcC5DS2VmTWvgKjfWcu6qBrIIuLnku4FJuWkIyPikcYWy8yaW8kCWTYYWE2qUPqyJrMNXZM1LWs5a3kWcCWwNbAN8P8lfbnRBTOzJlbCs5YfBd4SESsBJJ0H3Auc38iCmVmTquOA2HqpJZDN7bJfC+lSAjPbQJVm8hFJ3yHF3pXALEk35fVDgel9Uzwza0olOmvZeWZyFnBjRfrdjSuOmZWBylIji4hL+rIgZlYSfdyRX4uqfWSSdgDOA3YDhnSmR8TODSyXmTUtNV1nfy1jwi4FfkYaAXc4cDVwVQPLZGbNrsmGX9QSyDaNiJsAIuKpiDibdDcMM9tQddS49JFahl+8KknAU5I+CTxPDbOamNkAVdJxZP8CDAU+R+or2wI4oZGFMrPmVpqzlp0qZjh5ib/eXNHMNmR1CmSSniHFlnZgTUTsLWkEMA2YADwDHBURy3rLp7cBsdf1VtyI+FDhUpuZ/a13RcTiivUzgdsiYrKkM/P6l3rLoLca2UV1KGAhrU+tYtyHZvX1YW093DT/gf4ughWwz7tX1iWfBjctPwgcmB9PBe5gXQNZRNxWr1KZ2QASFLlEaZSkmRXrUyJiSpfcbpYUwI/ztjERsQAgT9Jb9eSiZxo3s+LqM9M4wAERMT8Hq1skPbYuxfFNEs2sMEVtSzURMT//3wZcB+wDLJQ0FiD/31Ytn5oDmaSNa93XzAa4Oozsl7SZpM07H5PurPMIcANwfN7teOD6asWp5Q6x+0h6GJiT1/eQ9B/VnmdmA1h9LlEaA0yX9CBwD3BjRPwOmAwcImkOcEhe71UtfWTfB94H/AogIh6U5EuUzDZQtTYbq4mIp4E9uklfAhxcJK9aAtmgiJibrlJ6XXuRg5jZAFOiGyt2ek7SPkBIGgx8FniiscUys2ZWukuUgE+RmpfbAguBW3OamW2oyhbI8mnRY/qgLGZWBnXqI6unWu4Q+xO6ib8RcXJDSmRmza9sgYzUlOw0BPgH4LnGFMfMykB9eNPEWtTStJxWuS7pMuCWhpXIzKygdbnWciKwXb0LYmYlUrampaRl/LXYg4ClpPsDmdmGqGyd/fle/XuQ7tMP0BHRbJOlm1mfa7Io0Ou1ljloXRcR7XlpsuKbWb8o4XRw90jaq+ElMbNSEOmsZS1LX+ntnv0tEbEGeDtwkqSngBWk1xER4eBmtiEqWR/ZPcBewBF9VBYzK4sSBTJBml28j8piZmVRokC2laTTe9oYERc2oDxmVgJlaloOJs0w3lw3HjKz/leiQLYgIr7eZyUxs3KI5rvWsrfhF66JmVn36jiOTNJgSfdL+nVenyhphqQ5kqZJ2qhaHr0FskL3zDazDUe9poPLTgNmV6xfAHwnInYClgEnVsugx0AWEUtrLoaZbVjqVCOTtA3wXuCneV3AQcAv8y5TqWEImGcaN7Niil1+NErSzIr1KRExpWL9u8AXgc3z+khgeR6MDzAPGFftIA5kZlaIKNRsXBwRe3ebj/Q+oC0i7pV0YEX2XVU9mgOZmRVWp3FkBwAfkPQe0t2nh5FqaMMrLpHcBphfLaNaLho3M1tbHfrIIuLLEbFNREwgTXD0+4g4Frgd+HDe7Xjg+mrFcSAzs+IaexufLwGnS3qS1Gd2SbUnuGlpZsU04O4XEXEHcEd+/DSwT5HnO5CZWXElukTJzKxbzXaJkgOZmRVWprtfmJn9rT6+H38tHMjMrDgHMjMrs4Ij+/uEA5mZFaaO5opkDmRmVoz7yMxsIHDT0szKz4HMzMrONTIzKz8HMjMrtSacRcmBzMwK8TgyMxsYorkimQOZmRXWbDUy3yG2zk6/8FmmPTSLH//+8dfTNh++hvOveor/nD6b8696iqFbrOklB+tr1/10FCe/axdOOnAXrv3JVgDc+V9bcNKBu3DYuD144sFN+rmETabWu8P2YbBrWCCTNF7S7ZJmS5ol6bRGHauZ3DxtBGcdO3GttKNObeP+6UM54e27cv/0oRx9als/lc66euaxIfz2ipF8/8YnuPjWx5lxyzCef3ojJrxhFV/96TP8n31X9HcRm5I6alv6SiNrZGuAMyJiV2Bf4DOSdmvg8ZrCIzOG8tKytVvs+737RW69egQAt149gv0Oe7E/imbdeHbOxuy610qGbBoMboE37fcyf/rtcLbd6VXG7/hqfxevadUjkEkaIukeSQ/mys65OX2ipBmS5kiaJmmjauVpWCCLiAURcV9+/BJpSvSqE20ORFuOWs3StlYAlra1Mnykm5bNYsIbVvHwjM14celgVq0U//P7YSya39rfxWpuQersr2Xp3avAQRGxB7AncJikfYELgO9ExE7AMuDEahn1SWe/pAnAm4EZ3Ww7GTgZYAib9kVxzF637U6vctSn2/jyMTswZLMOJu72CoNbmqwnuwnVo7M/IgJ4Oa+25iWAg4B/yulTgXOAH/WWV8M7+yUNBa4BPh8Rf9OmiogpEbF3ROzdysaNLk6/WLa4lRGjVwMwYvRqli/xyeJmctg/LeUHNz/Bt697ks2HtzNuopuUVdXe2T9K0syK5eTKbCQNlvQA0AbcAjwFLM+T8wLMo4aWXEMDmaRWUhC7IiKubeSxmtndNw9j0lFLAZh01FLuumlYP5fIKi1fnP6wtM1r5U+/2YIDj1jezyVqbp0DYmtZgMWdFZW8TKnMKyLaI2JP0ozi+wC7dnPIqvW/hlUNJIk0sebsiLiwUcdpNmf+cC5v2u9lthixhstnPspl3x7DtItGc9bFcznsmKW0Pb8R552yXX8X0yp8/RMTeGlZC4Nbg1O/OY/Nh7fzp99uwQ/PHscLS1r41+O2Z4c3vsI3r3y6v4vaHCLqfmPFiFgu6Q7SicHhklpyrWwbYH615zeyjXMAcBzwcK46AnwlIn7TwGP2u8mf7j5InXn0Dn1cEqvVhb968m/SDjj8BQ44/IV+KE1J1CGOSdoKWJ2D2CbAJFJH/+3Ah4GrgOOB66vl1bBAFhHTSbVQMxtg6jSyfywwVdJgUjfX1RHxa0mPAldJ+gZwP6ll1yv3OptZMQHUoWkZEQ+RRjN0TX+a1F9WMwcyMyuuyUaoOJCZWWHNdtG4A5mZFebp4Mys3DwdnJmVXRoQ21yRzIHMzIrzPfvNrOxcIzOzcnMfmZmVX/2vtVxfDmRmVpyblmZWap6g18wGBNfIzKz0miuOOZCZWXHqaK62pQOZmRUTeECsmZWbCA+INbMBwIHMzEqvyQJZw+e1NLMBprOPrJalF5LGS7pd0mxJsySdltNHSLpF0pz8/5bViuRAZmaFqaOjpqWKNcAZEbEraRq4z0jaDTgTuC0idgJuy+u9ciAzs4IiNS1rWXrLJWJBRNyXH78EzCbNKv5BYGrebSpwRLUSuY/MzIoJivSRjZI0s2J9StfZxgEkTSDNqDQDGBMRCyAFO0mjqx3EgczMiqt9HNniiNi7tx0kDQWuAT4fES9KxafDddPSzApTRE1L1XykVlIQuyIirs3JCyWNzdvHAm3V8nEgM7Pi6tBHplT1ugSYHREXVmy6ATg+Pz4euL5acdy0NLNiIqC9LtcoHQAcBzws6YGc9hVgMnC1pBOBZ4Ejq2XkQGZmxdVhQGxETCdNytSdg4vk5UBmZsU12ch+BzIzKyYA37PfzMotIJrrPj4OZGZWTFCvzv66cSAzs+LcR2ZmpedAZmblVn2wa19zIDOzYgLw5CNmVnqukZlZudXtEqW6cSAzs2ICwuPIzKz0PLLfzErPfWRmVmoRPmtpZgOAa2RmVm5BtLf3dyHW4kBmZsU04W18fM9+MysuOmpbqpD0n5LaJD1SkeaZxs2ssQKIjqhpqcGlwGFd0jzTuJk1WETdamQRcSewtEuyZxo3s8ZrcGd/4ZnGFU10GlXSImBuf5ejAUYBi/u7EFbIQP3MtouIrdYnA0m/I70/tRgCrKpYnxIRU7rkNwH4dUTsnteXR8Twiu3LIqLXfrKmqpGt7xvcrCTNrDZtvDUXf2Y9i4iufVr1tlDS2Fwb80zjZlZKhWcadyAzs34j6UrgLmAXSfPy7OKTgUMkzQEOyeu9aqqm5QA2pfou1mT8mfWBiPhID5sKzTTeVJ39Zmbrwk1LMys9B7IG6u7yC2teksZLul3SbEmzJJ3W32Wy2rhp2UCS3gm8DPy8c4yMNa98qn9sRNwnaXPgXuCIiHi0n4tmVbhG1kA9XH5hTSoiFkTEffnxS8BsYFz/lspq4UBm1o082vzNwIz+LYnVwoHMrAtJQ4FrgM9HxIv9XR6rzoHMrIKkVlIQu1U5GCYAAANmSURBVCIiru3v8lhtHMjMMkkCLgFmR8SF/V0eq50DWQP1cPmFNa8DgOOAgyQ9kJf39HehrDoPvzCz0nONzMxKz4HMzErPgczMSs+BzMxKz4HMzErPgaxEJLXnIQGPSPqFpE3XI68DJf06P/6ApB7nDpQ0XNKn1+EY50j6v7Wmd9nnUkkfLnCsCb7LyIbLgaxcXomIPfOdNF4DPlm5UUnhzzQiboiI3m4nPBwoHMjM+ooDWXn9Edgx10RmS/ohcB8wXtKhku6SdF+uuQ0FkHSYpMckTQc+1JmRpI9Juig/HiPpOkkP5mV/0j3Td8i1wW/l/b4g6X8kPSTp3Iq8zpL0uKRbgV2qvQhJJ+V8HpR0TZda5iRJf5T0hKT35f0HS/pWxbFPWd830srPgayEJLUAhwMP56RdSPc8ezOwAjgbmBQRewEzgdMlDQF+ArwfeAfwdz1k/33gDxGxB7AXMIs0Zf1TuTb4BUmHAjsB+wB7Am+R9E5JbwGOId014kPAW2t4OddGxFvz8WYDlVc/TAD+HngvcHF+DScCL0TEW3P+J0maWMNxbADz5CPlsomkB/LjP5KuC9wamBsRd+f0fYHdgD+lSwfZiHSZ1BuAP0fEHABJlwMnd3OMg4B/BoiIduAFSV0nRz00L/fn9aGkwLY5cF1ErMzHuKGG17S7pG+Qmq9DgZsqtl0dER3AHElP59dwKPCmiv6zLfKxn6jhWDZAOZCVyysRsWdlQg5WKyqTgFu6zk4jaU+gXtejCTg/In7c5RifX4djXEq6C+uDkj4GHFixrWtekY/92YioDHid9w+zDZSblgPP3cABknYEkLSppJ2Bx4CJknbI+/U0DddtwKfycwdLGga8RKptdboJOKGi722cpNHAncA/SNok3yr6/TWUd3NgQb59zrFdth0paVAu8/bA4/nYn8r7I2lnSZvVcBwbwFwjG2AiYlGu2VwpaeOcfHZEPCHpZOBGSYuB6UB38wicBkzJd+poBz4VEXdJ+lMe3vDb3E+2K3BXrhG+DHw03+t+GvAAMJfU/K3mX0l3YZ1L6vOrDJiPA38AxgCfjIhVkn5K6ju7L992ZxFwRG3vjg1UvvuFmZWem5ZmVnoOZGZWeg5kZlZ6DmRmVnoOZGZWeg5kZlZ6DmRmVnoOZGZWev8LRN+jsLMJNScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = (Total)\n",
    "y_train = (label)\n",
    "X_test = (LS_Aus_test)\n",
    "y_test = (y_test)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_im,random_state=1, test_size=0.1)\n",
    "sc_X = StandardScaler()\n",
    "mm_X = MinMaxScaler(feature_range=(-3.06,3.06))\n",
    "X_trainscaled= mm_X.fit_transform(X_train) #mm_X.fit_transform(X_train)  #sc_X.fit_transform(X_train)\n",
    "X_testscaled= mm_X.transform(X_test) #mm_X.transform(X_test)  #sc_X.transform(X_test)\n",
    "  \n",
    "clf = MLPClassifier(solver='adam',batch_size= 200,hidden_layer_sizes=\n",
    "                    (6,22,8,3,2),\n",
    "                    activation=\"relu\",random_state=1,max_iter = 5000,\n",
    "                    learning_rate= 'constant',warm_start = True,\n",
    "                    learning_rate_init =0.0014,\n",
    "                   alpha =0.0000999,beta_1=0.9,beta_2=0.999,)\n",
    "\n",
    "clf.fit(X_trainscaled, y_train)\n",
    "\n",
    "y_pred=clf.predict(X_testscaled)\n",
    "print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "fig=plot_confusion_matrix(clf, X_testscaled, y_test,display_labels=[\"1\",'2'])#,'5','6','7','8','9'])\n",
    "fig.figure_.suptitle(\"Confusion Matrix for MSPO Latent space\")\n",
    "#plt.savefig('ConfusionMatrixoforiginallatentspace.png')\n",
    "#plt.show()\n",
    "target_names = ['class 1', 'class 2']#,'class 5','class 6','class 7','class 8','class 9']\n",
    "print(classification_report(y_pred,y_test, target_names=target_names))\n",
    "\n",
    "# In[30]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:29:33.010737Z",
     "iopub.status.busy": "2021-09-11T14:29:33.010163Z",
     "iopub.status.idle": "2021-09-11T14:29:33.023062Z",
     "shell.execute_reply": "2021-09-11T14:29:33.022070Z",
     "shell.execute_reply.started": "2021-09-11T14:29:33.010691Z"
    }
   },
   "outputs": [],
   "source": [
    "def metricFn(y_test, y_pred):\n",
    "    \n",
    "    confMat=confusion_matrix(y_test, y_pred) \n",
    "    #print(confMat)\n",
    "    TP = confMat[0,0]\n",
    "    TN = confMat[1,1]\n",
    "    FP = confMat[1,0]\n",
    "    FN = confMat[0,1]\n",
    "    #print(TP,FP,TN,FN)\n",
    "    Eta = 1/2*((TP/np.sum(y_test==1))+(TN/np.sum(y_test==2)))\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    Gmean = np.sqrt(TPR*TNR)\n",
    "    return (TPR,TNR,Gmean,Eta)\n",
    "# print('TPR , TNR , GM ,Eta')\n",
    "# print(metricFn(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:29:43.775724Z",
     "iopub.status.busy": "2021-09-11T14:29:43.774924Z",
     "iopub.status.idle": "2021-09-11T14:29:43.861819Z",
     "shell.execute_reply": "2021-09-11T14:29:43.861016Z",
     "shell.execute_reply.started": "2021-09-11T14:29:43.775689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation\n",
      "TPR , TNR , GM ,Eta\n",
      "(0.9014084507042254, 0.900990099009901, 0.9011992505813359, 0.9011992748570632)\n",
      "(0.9014084507042254, 0.900990099009901, 0.9011992505813359, 0.9011992748570632)\n",
      "(0.9014084507042254, 0.900990099009901, 0.9011992505813359, 0.9011992748570632)\n",
      "(0.8450704225352113, 0.900990099009901, 0.8725824222790297, 0.8730302607725562)\n",
      "(0.9014084507042254, 0.900990099009901, 0.9011992505813359, 0.9011992748570632)\n",
      "(0.9014084507042254, 0.900990099009901, 0.9011992505813359, 0.9011992748570632)\n",
      "(0.9014084507042254, 0.900990099009901, 0.9011992505813359, 0.9011992748570632)\n",
      "(0.8450704225352113, 0.900990099009901, 0.8725824222790297, 0.8730302607725562)\n",
      "(0.8450704225352113, 0.900990099009901, 0.8725824222790297, 0.8730302607725562)\n",
      "(0.8873239436619719, 0.900990099009901, 0.8941309120334985, 0.8941570213359364)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10,shuffle = True)\n",
    "print(\"Cross Validation\")\n",
    "print('TPR , TNR , GM ,Eta')\n",
    "\n",
    "for train_indices, test_indices in kf.split(X_trainscaled):\n",
    "    clf.fit(X_trainscaled[train_indices], y_train[train_indices])\n",
    "    # print(clf.score(X_testscaled, y_test))\n",
    "\n",
    "    y_pred=clf.predict(X_testscaled)\n",
    "    print(metricFn(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T14:25:00.845574Z",
     "iopub.status.busy": "2021-09-11T14:25:00.844912Z",
     "iopub.status.idle": "2021-09-11T14:25:00.851955Z",
     "shell.execute_reply": "2021-09-11T14:25:00.850624Z",
     "shell.execute_reply.started": "2021-09-11T14:25:00.845515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 50.801310777664185\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken:\",time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
